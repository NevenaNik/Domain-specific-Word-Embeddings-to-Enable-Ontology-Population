Most user requirements for technical products can be formulated in terms of a
constrained optimization problem. For instance one may wish to develop an engine
with the highest fuel efﬁciency under the constraints of providing the desired
torque characteristics and limiting noise, emissions, weight, size, cost, etc., given
by the legislators or set by the customer expectations.

In the case of automotive systems, most requirements must be met not only in
special, well-deﬁned driving scenarios but also in a wide variety of environmental
and road conditions under the action of an unknown driver. Furthermore,
automotive systems exhibit signiﬁcant production and lifetime deviations, which
makes the ‘real’ parameters frequently unknown. All this means that optimization
in the automotive context must include in some way the uncertainty–roughly
speaking, we are dealing with the optimization of partly unknown systems under
greatly unknown conditions.

Traditionally, automotive systems have been optimized rather heuristically, and
the impressive results are more the consequence of an enormous effort than of a
systematic optimal design. While commercial aspects–ﬁrst of all the production
scale and the possibly catastrophic consequences of errors–have made this
approach viable and maybe even necessary, lately the interest in more systematic
approaches has been increasing driven by the need to reduce development time
and cost. This has led to two main directions: on one hand, tools for calibration
(tuning) support have been developed, based usually on local data-based models
and optimizations; on the other hand the academic work in the ﬁeld of model-
based control has been gaining additional momentum and has found some
applications in production.

Between 15 and 16 July 2013, a workshop on the subjects of optimization in
automotive systems took place in Linz to assess the status and discuss ways to
improve the availability of optimization methods in the industrial practice. Since
optimization can be exploited at different design stages, starting from the system
design level and the selection of an optimal topology, to the operation level, and
the development of an optimal control strategy, many relevant
topics were
addressed. Most attention, nevertheless, was given to the control-related optimi-
zation as it and the coupled problem of control and design optimization are
comparatively less studied and understood.

xvii

xviii

Introduction

The book begins with a discussion of dynamic optimization techniques and
methodologies for automotive applications, and includes a basic introduction into
dynamic and trajectory optimization techniques (Chap. 1), and three more speciﬁc
methods which are extremum seeking (Chap. 2), Model Predictive Control (Chap. 3)
and an optimal nonlinear feedback regulation technique based on the Hamilton–
Jacobi–Bellman equation (Chap. 4). The latter approach is an example of a theo-
retically advanced methodology that has been shown to be effective for automotive
systems once combined with a suitable system identiﬁcation method.

The book then proceeds to discuss automotive applications of dynamic
optimization and optimal control at various levels. At a very high level, signiﬁcant
beneﬁts are expected from its use to control the trafﬁc ﬂows and enforce their
ﬂuidity as discussed in Chap. 5. Much can also be gained at the level of single
vehicle operation and active safety as discussed in Chaps. 6–8. While these three
contributions are mainly centered on handling and safety, two other contributions
(Chaps. 9 and 10) examine applications of dynamic optimization in assistant
systems for vehicle speed control.

Demonstrating optimization potential at powertrain level is pursued next. This
topic addressed especially in the context of hybrid electrical vehicles (HEVs), in
terms of topology optimization in Chap. 11, optimal energy management (Chaps.
12 and 13) where the latter contribution includes battery ageing which is a sig-
niﬁcant consideration in view of battery ageing and cost.

Another application of dynamic optimization, now to coordinated control of
Diesel engine aftertreatment, is the topic of the contribution of Chap. 14. While
the use of dynamic optimization for HEV energy management is relatively well
understood, there is now a growing interest in the use of dynamic optimization to
achieve effective control of aftertreatment systems and emission reductions.

Finally the optimization of engine operation, a topic that has received many
theoretical but also industrial contributions is addressed. Speciﬁcally, Chap. 15
addresses the problem of optimal calibration of engine maps by learning methods
from an industrial point of view, and Chap. 16 presents development aspects of a
commercially available optimization tool for a similar task. Chapter 17 tackles the
problem of optimal control of homogeneous charge compression ignited (HCCI)
engines, while Chap. 18 in some sense closes the gap between the vehicle and
engine control addressing the optimal operation at vehicle level while taking into
account the engine operation.

Some general conclusions can be drawn from the discussion. Brieﬂy, there is a
gap between academic and industrial communities. This gap is due to legacy issues
which make it difﬁcult for industrial users to employ or test new optimization and
optimal control methods and the need of the academic community to address more
complex questions that incorporate more realistic models and system engineering
aspects and requirements.

Introduction

More in detail:

Scope

Models

Industrial priorities

Need of hand-on proof

Adaptive methods

xix

Optimization is important in many different ﬁelds, but it
must be seen as a part of the development process, i.e. it
must take into account system engineering aspects and
support a sequential process of design, modelling and
optimization.

Not surprisingly, different kinds of models greatly affect
the complexity of the optimization task. As a general
trend, simple ﬁrst principle-based models initially used
for design, are increasingly complex and accurate data-
tend to deliver better results for
based models that
optimization replaced by more. Still, ﬁrst principle
models tend to be used also for optimization and are in
fact preferred by some legacy users.

Optimal control and dynamic optimization are becoming
more important in industry, yet so are related tasks, like
optimal calibration and tuning,
that are frequently
overlooked by the academic community. Addressing
these related tasks can lead to immediate and direct
impact on industrial development processes. On the other
hand, the academic work is concentrating more on the
algorithmic solutions of the standard problems and these
solutions are of growing interest in new applications.

For the ﬁnal user, it is not easy to choose between
different approaches and to see the beneﬁts of a speciﬁc
optimization method, especially because many algo-
rithms are developed under simpliﬁed conditions which
would not be realistic in the normal product operation.
There is a need to establish evaluation methods that take
into account implementation elements, robustness and
certiﬁability.

Adaptive optimal methods are potentially an excellent
approach to improve the operation under real, changing
conditions, but methods are required to guarantee and/or
test their performance/convergence/safety under all con-
ditions. This is a critical point also in view of certiﬁcation.

xx

Human in the loop

Introduction

Human interaction is an important
the
operation of optimal control-based systems, metrics to
evaluate subjective criteria are needed. Human behav-
iour and reactions can also be embedded in the
optimization chain.

factor

for

Acknowledgments

The authors gratefully acknowledge the sponsoring of this work by the COMET
K2 Center ‘‘Austrian Center of Competence in Mechatronics (ACCM)’’. The
COMET Program is funded by the Austrian federal government, the Federal State
Upper Austria and the Scientiﬁc Partners of ACCM.

Part I
Optimization Methods

Chapter 1
Trajectory Optimization: A Survey

Anil V. Rao

Abstract A survey of numerical methods for trajectory optimization. The goal of
this survey is to describe typical methods that have been developed over the years
for optimal trajectory generation. In addition, this survey describes modern software
tools that have been developed for solving trajectory optimization problems. Finally,
a discussion is given on how to choose a method.

1.1 Introduction

Trajectory optimization is a process where it is desired to determine the path and the
corresponding input (control) to a dynamical system that meet speciﬁed constraints
on the system while optimizing a speciﬁed performance index. Typically, optimal tra-
jectory generation is performed off-line, that is, such problems are not solved in real
time nor in a closed-loop manner. Because of the complexity of most applications,
optimal trajectories are typically generated using numerical methods. Numerical for
trajectory optimization date back nearly ﬁve decades to the 1950s with the work
of Bellman [5–10]. Because complexity of modern applications has has increased
tremendously as compared to applications of the past, methods for trajectory opti-
mization continue to evolve and the discipline is becoming increasingly relevant in
a wide range of subject including virtually all branches of engineering, economics,
and medicine.

Numerical methods for trajectory optimization are divided into two major classes:
indirect methods and direct methods. In an indirect method, the ﬁrst-order optimality
conditions from variational calculus are employed. The trajectory optimization prob-
lem is then converted into a multiple-point Hamiltonian boundary-value problem.
The HBVP is then solved numerically to determine candidate optimal trajectories

A. V. Rao (B)
University of Florida, Gainesville, FL, USA
e-mail: anilvrao@uﬂ.edu

H. Waschl et al. (eds.), Optimization and Optimal Control in Automotive Systems,
Lecture Notes in Control and Information Sciences 455,
DOI: 10.1007/978-3-319-05371-4_1, © Springer International Publishing Switzerland 2014

3

4

A. V. Rao

called extremals. Each extremal solution of the HBVP is then examined to see if it
is a local minimum, maximum, or a saddle point, and the extremal with the lowest
cost is chosen. In a direct method, the state and/or control of the original trajectory
optimization problem is approximated by parameterizing the state and/or the con-
trol and the trajectory optimization problem is transcribed to a ﬁnite-dimensional
nonlinear programming problem (NLP). The NLP is then solved using well known
optimization techniques.

It is seen that indirect methods and direct method emanate from two different
philosophies. On the one hand, the indirect approach solves the problem indirectly
(thus the name, indirect) by converting the trajectory optimization problem to a
boundary-value problem. As a result, in an indirect method the optimal solution is
found by solving a system of differential equations that satisﬁes endpoint and/or
interior point conditions. On the other hand, in a direct method the optimal solution
is found by transcribing an inﬁnite-dimensional optimization problem to a ﬁnite-
dimensional optimization problem.

The two different philosophies of indirect and direct methods have led to a di-
chotomy in the trajectory optimization community. Researchers who focus on indi-
rect methods are interested largely in the numerical solution of differential equations,
while researchers who focus on direct methods are interested primarily in the numer-
ical solution of optimization problems. While at ﬁrst glance these two approaches
may seem completely unrelated, they have a great deal in common. As will be de-
scribed in the survey, recent years researchers have delved quite deeply into the
connections between the indirect and direct forms. This research has uncovered that
the optimality conditions from many direct methods have a well-deﬁned meaningful
relationship. Thus, these two classes of methods are merging as time goes by.

1.2 Trajectory Optimization Problem

A fairly general trajectory optimization problem is posed formally as follows. Typ-
ically, the problem is divided into P phases [15] and the phases are connected in
some meaningful way. A multiple-phase trajectory optimization problem is posed as
follows. Optimize the cost functional

J =

Φ(k)

y(k)(t0), t0, y(k)

t f

, t f ; s

+

(cid:2)

(cid:3)

(cid:5)

(cid:6)

(k)
f

t

(cid:4)
y(k) (t) , u(k) (t) , t; s(k)

(cid:5)

dt

L

(cid:3)

P(cid:2)

(cid:4)

k=1

(k)
0

t

subject to the dynamic constraints

(cid:4)

(cid:5)

˙y(k) (t) = f

y(k) (t) , u(k) (t) , t; s(k)

,

the boundary conditions,

(cid:7)

(1.1)

(1.2)

1 Trajectory Optimization: A Survey

5

Indirect Methods

Systems of
Nonlinear Equations

Numerical Solution of
Diﬀerential Equations

Nonlinear Optimization

Direct Methods

Fig. 1.1 The three major components of trajectory optimization and the class of methods that uses
each component

(cid:4)

(cid:5)

φ(k)
min

≤ φ(k)

y(k)(t

(k)
0

), t

(k)
0

, y(k)(t

(k)
f

), s(k), t

(k)
f

≤ φ(k)
max

,

(1.3)

the algebraic path constraints

(cid:4)

(k)
c
min

≤ c(k)

y(k) (t) , u(k) (t) , s(k), t

(cid:5)

≤ c(k)
max

and the linkage constraints (also known as phase continuity constraints)

(cid:4)

L

(s)
min

≤ L

(ls )

y

(cid:4)

(cid:5)

(ls )
f

t

(cid:4)

(cid:5)

(ls )

, u

(ls )
f

t

, s

(ls ), t

(ls )
f

, y

(rs )(t

(rs )
f

(rs )

), u

(rs )
f

t

, s

(rs ), t

(rs )
f

≤ L

(cid:4)

(cid:5)

(cid:5)

(1.4)

(s)
max,
(1.5)

where s ∈ [1, . . . , S] and S is the number of pairs of phases that are being linked. In
Eq. (1.5) the parameter S is the number of pairs of phases to be linked, rs ∈ [1, . . . , S]
and ls ∈ [1, . . . , S] are the right phases and left phases, respectively, of the linkage
pairs, rs ∞= ls (implying that a phase cannot be linked to itself), and s ∈ [1, . . . , S].

1.3 Numerical Methods for Trajectory Optimization

At the heart of a well-founded method for solving trajectory optimization problems
are the following three fundamental components: (1) a method for solving differ-
ential equations and integrating functions; (2) a method for solving a system of
nonlinear algebraic equations; and (3) a method for solving a nonlinear optimization
problem. Methods for solving differential equations and integrating functions are
required for all numerical methods in trajectory optimization optimal control. In an
indirect method, the numerical solution of differential equations is combined with
the numerical solution of systems of nonlinear equations while in a direct method the
numerical solution of differential equations is combined with nonlinear optimization.
A schematic with the breakdown of the components used by each class of optimal
control methods is shown in Fig. 1.1.

6

A. V. Rao

1.4 Numerical Solution of Differential Equations

Consider the initial-value problem [30, 42, 92] (IVP)

˙y = f(y(t), t),

y(t0) = y0.

(1.6)

Next, let [ti , ti+1] be a time interval over which the solution to Eq. (1.6) is desired.
Integrating Eq. (1.6), we can write

yi+1 = yi +

˙x(s)ds = yi +

f(y(s), s)ds.

(1.7)

(cid:6)

ti+1

ti

(cid:6)

ti+1

ti

The two most common approaches for solving differential equations are time march-
ing and collocation. In a time-marching method, the solution of the differential
equation at each time step tk is obtained sequentially using current and/or previ-
ous information about the solution. In a multiple-step time marching method, the
solution at time tk+1 is obtained from a deﬁned set of previous values tk− j , . . . , tk
where j is the number of steps. The simplest multiple-step method is a single-step
method (where j = 1). The most common single-step methods are Euler methods,
while most commonly used multiple-step methods are the Adams-Bashforth and
Adams-Moulton multiple-step methods [30]. Euler backward and Crank-Nicolson
are examples of implicit methods whereas Euler forward is an example of an explicit
method. When employing implicit method, the solution at tk+1 is obtained using
a predictor-corrector where the predictor is typically an explicit method (that is,
Euler-forward) while the corrector is the implicit formula. Implicit methods meth-
ods are more stable than explicit methods [42], but an implicit method requires more
computation at each step due to the need to implement a predictor-corrector.

An alternative to a multiple-step time marching method is a multiple-stage method.
In a multiple-stage method, the interval [ti , ti+1] into K subintervals [τ j , τ j+1] where

τ j = ti + hi α j ,

( j = 1, . . . , K ), hi = ti+1 − ti ,

(1.8)

and 0 ≤ α j ≤ 1, ( j = 1, . . . , K ). Each value τ j is called a stage . The integral from
ti to ti+1 can be approximated via quadrature as

(cid:6)

ti+1

ti

K(cid:2)

j=1

f(y(s), s)ds ≈ hi

β j f(y j , τ j )

(1.9)

where y j ≡ y(τ j ). It is seen in Eq. (1.9) that the values of the state at each stage
are required in order to evaluate the quadrature approximation. These intermediate
values are obtained as

1 Trajectory Optimization: A Survey

7

y(τ j ) − y(ti ) =

f(y(s), s)ds ≈ hi

γ jl f(yl , τl )

(1.10)

(cid:6) τ j

ti

K(cid:2)

l=1

The combination of Eqs. (1.9) and (1.10) leads to the family of K −stage Runge-
Kutta methods [15, 24, 25, 30, 50, 51, 92]. A Runge-Kutta method is called explicit
if γ jl = 0 for all l ≥ j and is called implicit otherwise. In an explicit Runge-
Kutta method, the approximation at tk+1 is computed using information prior to tk+1
whereas in an implicit Runge-Kutta method y(tk+1) is required in order to determine
the solution at tk+1. In the latter case, the solution is updated using a predictor-
corrector approach.

1.4.1 Collocation

Another way to solve differential equations is as follows. Suppose over a subin-
terval [ti , ti+1] we choose to approximate the state using the following K th-degree
piecewise polynomial:

Y(t) ≈

ai (t − ti )k,

t ∈ [ti , ti+1].

(1.11)

K(cid:2)

k=0

Suppose further that the coefﬁcients (a0, . . . , aK ) of the piecewise polynomial

are chosen to match the value of the function at the beginning of the step, that is,

Y(ti ) = yi .

(1.12)

Finally, suppose we choose to match the derivative of the state at the points deﬁned

in Eq. (1.8), that is,

˙y(τ j ) = f(y(τ j ), τ j ),

( j = 1, . . . , K ).

(1.13)

Equation (1.13) is called a collocation condition because the approximation to
the derivative is set equal to the right-hand side of the differential equation evaluated
at each of the intermediate points (τ1, . . . , τK ). Collocation methods fall into three
general categories [15]: Gauss methods, Radau methods, and Lobatto methods. In a
Gauss method, neither of the endpoints tk or tk+1 are collocation points. In a Radau
method, at most one of the endpoints tk or tk+1 is a collocation point. In a Lobatto
method, both of the endpoints tk and tk+1 are collocation points.

As it turns out, Euler and Runge-Kutta methods can be thought of equivalently
as either time-marching or collocation methods. When an Euler or a Runge-Kutta
method is employed in the form of collocation, the differential equation is said to
be solved simultaneously because all of the unknown parameters are determined at

8

A. V. Rao

the same time. Furthermore, collocation methods are said to simulate the dynamics
of the system implicitly because the values of the state at each collocation point
are obtained at the same time (as opposed to solving for the state sequentially as
in a time-marching method). In order to implement simultaneous simulation, the
discretized dynamics are written as defect constraints of the form

As an example, the defect constraints for the Crank-Nicolson method are given as

ζ

j

= ˙y(τ j ) − f(y(τ j ), τ j ).

ζ

k

= yk+1 − yk − hk
2

(fk + fk+1) .

(1.14)

(1.15)

In collocation (that is, implicit simulation) it is desired to ﬁnd a solution such
that all of the defect constraints are zero. Finally, one of the key differences between
collocation and time-marching is that in collocation it is not necessary to use a
predictor-corrector because the values of the state at each discretization point are
being solve for simultaneously.

1.4.2 Integration of Functions

Because the objective is to solve a trajectory optimization problem, it is necessary
to approximate the cost function of Eq. (1.1). Typically, the cost is approximated
using a quadrature that is consistent with the numerical method for solving the
differential equation (for example, if one is using an Euler-forward rule for solving
the differential equation, the cost would also be approximated using Euler-forward
integration). The requirement for consistency in the approximation of the differential
equations and the cost can be thought of in another manner. Consider a one-phase
trajectory optimization problem. The cost functional

J = Φ(y(t0), t0, y(t f ), t f ) +

L [y(t), u(t), t; s]dt

(1.16)

(cid:6)

t f

t0

can be converted to a Mayer problem by adding a state yn+1 and adding the differential
equation

˙yn+1 = g[y(t), u(t), t; s]

with the initial condition

yn+1(t0) = 0.

The cost functional of Eq. (1.16) would be given as

(1.17)

(1.18)

J = Φ[y(t0), t0, y(t f ), t f ; s] + yn+1(t f )

(1.19)

1 Trajectory Optimization: A Survey

9

and the resulting augmented system of differential equations would then be written
as

˙y(t) = f[y(t), u(t), t; s],
˙yn+1 = L [x(t), u(t), t; s].

(1.20)

Equation (1.20) could then be solved using any well established numerical integration
method. Using this approach, is it seen that the method used to integrate Eq. (1.17)
must be the same method that is used to integrate

L [y(t), u(t), t; s].

1.5 Nonlinear Optimization

A key ingredient to solving trajectory optimization problems is the ability to solve
nonlinear optimization or nonlinear programming problems [4, 11, 21, 44] (NLPs).
An NLP takes the following general mathematical form. Determine the decision
vector z ∈ Rn that minimizes the cost function

subject to the algebraic constraints

f (z)

g(z) = 0,
h(z) ≤ 0,

(1.21)

(1.22)
(1.23)

where g(z) ∈ Rm and h(z) ∈ R p. The NLP may either be dense (that is, a large
percentage of the derivatives of the objective function and the constraint functions
with respect to the components of z are nonzero) or may be sparse (that is, a large
percentage of the derivatives of the objective function and the constraint functions
with respect to the components of z are zero). Dense NLPs typically are small (con-
sisting of at most a few hundred variables and constraints) while sparse NLPs are
often extremely large (ranging anywhere from thousands of variables and constraints
to millions of variables and constraints).

1.6 Methods for Solving Trajectory Optimization Problems

With the exception of simple problems, trajectory optimization problems must be
solved numerically. The need for solving optimal control problems numerically has
given rise to a wide range of numerical approaches. These numerical approaches are

10

A. V. Rao

divided into two broad categories: (1) indirect methods and (2) direct methods. The
major methods that fall into each of these two broad categories are described in the
next two sections.

1.6.1 Indirect Methods

In an indirect method, the calculus of variations [3, 20, 23, 40, 56, 62, 67, 68, 91,
94, 97] is used to determine the ﬁrst-order optimality conditions of the trajectory
optimization problem given in Eqs. (1.1)–(1.5). Unlike ordinary calculus (where
the objective is to determine points that optimize a function), the calculus of varia-
tions is the subject of determining functions that optimize a function of a function
(also known as functional optimization). Applying the calculus of variations to the
functional optimization problem given in Eqs. (1.1)–(1.5) leads to the ﬁrst-order
necessary conditions for an extremal trajectory. The ﬁrst-order optimality condi-
tions for a single-phase continuous-time trajectory optimization problem with no
static parameters are given as

˙y = H T
λ ,

˙λ = −H T
y

,

u∗ = arg min
u∈U

H ,

φ(y(t0), t0, y(t f ), t f ) = 0,

λ(t0) = −Φy(t0) + νTφy(t0), λ(t f ) = Φy(t f ) − νTφy(t f ),

H (t0) = Φt0

− νTφt0

, H (t f ) = −Φt f

+ νTφt f

,

μ j (t) = 0, when C j (x, u, t) < 0,
μ j (t) ≤ 0, when C j (x, u, t) = 0,

j = 1, . . . , c,
j = 1, . . . , c,

(1.24)

(1.25)

(1.26)

(1.27)

(1.28)

(1.29)

where H = L + λTf − μTC is the augmented Hamiltonian, U is the feasible
control set and ν ∈ Rq is the Lagrange multiplier associated with the boundary
condition φ. Finally, it is noted that the solution to the optimal control problem may
lie along a singular arc [23] where the control cannot be determined from the ﬁrst-
order optimality conditions. If a singular arc is a possibility, additional conditions
must be derived to determine the control along the singular arc.

Because the dynamics of Eq. (1.24) arise from differentiation a Hamiltonian,
Eq. (1.24) is called a Hamiltonian system [3, 66, 67]. Furthermore, Eq. (1.25) is
known as Pontryagin’s Minimum Principle [75] (PMP) and is a classical result to
determine theoptimal control. Finally, the conditions on the initial and ﬁnal costate

1 Trajectory Optimization: A Survey

11

given in Eq. (1.27) are called transversality conditions [3, 23, 40, 62, 66, 68, 91, 93,
94] while the conditions on the Lagrange multipliers of the path constraints given in
Eq. (1.29) are called complementary slackness conditions [4, 11, 21]. The Hamil-
tonian system, together with the boundary conditions, transversality conditions, and
complementary slackness conditions, is called a Hamiltonian boundary-value prob-
lem (HBVP) [2, 3, 66]. Any solution (y(t), u(t), λ(t), μ(t), ν) is called an extremal
solution and consists of the state, costate, and any Lagrange multipliers that satisfy
the boundary conditions and any interior-point constraints on the state and costate.
In an indirect method extremal trajectories (that is, solutions of the HBVP) are de-
termined numerically. Because an indirect method requires solving a multiple-point
boundary-value problem, the original trajectory optimization problem is turned into
the problem of solving a system of nonlinear equations of the form

f(z) = 0,
gmin ≤ g(z) ≤ gmax.

(1.30)

The three two most common indirect methods are the shooting method, the
multiple-shooting method, and collocation methods. Each of these approaches is
now described.

1.6.1.1 Indirect Shooting Method

Perhaps the most basic indirect method is the shooting method [65]. In a typical
shooting method, an initial guess is made of the unknown boundary conditions at
one end of the interval. Using this guess, together with the known initial conditions,
the Hamiltonian system Eq. (1.24) is integrated to the other end (that is, either forward
from t0 to t f or backward from t f to t0). Upon reaching t f , the terminal conditions
obtained from the numerical integration are compared to the known terminal condi-
tions given in Eqs. (1.26) and (1.27). If the integrated terminal conditions differ from
the known terminal conditions by more than a speciﬁed tolerance ε, the unknown
initial conditions are adjusted and the process is repeated until the difference between
the integrated terminal conditions and the required terminal conditions is less than
some speciﬁed threshold.

1.6.1.2 Indirect Multiple-Shooting Method

While a simple shooting method is appealing due to its simplicity, it presents sig-
niﬁcant numerical difﬁculties due to ill-conditioning of the Hamiltonian dynamics.
The reason for this ill-conditioning is that Hamiltonian systems have the property
that the divergence of the ﬂow of trajectories must be zero, that is

12

(cid:8)

n(cid:2)

i=1

(cid:6)

(cid:7)

(cid:6)

(cid:7)(cid:9)

∂
∂ xi

∂H
∂λi

+

∂
∂λi

−

∂H
∂ xi

≡ 0.

A. V. Rao

(1.31)

Equation (1.31) implies that, in a neighborhood of the optimal solution, there exist
an equal number of directions along which the solution will contract and expand and
this expansion and contraction takes place at the same rate (the simultaneous expand-
ing and contracting behavior is due to the fact that many Hamiltonian systems admit
an exponential dichotomy [2]). As a result, errors made in the unknown boundary
conditions will amplify as the dynamics are integrated in either direction of time.
The shooting method poses particularly poor characteristics when the trajectory op-
timization problem is hyper-sensitive [76, 78, 79, 81, 82] (that is, when time interval
of interest is long in comparison with the time-scales of the Hamiltonian system in
a neighborhood of the optimal solution).

In order to overcome the numerical difﬁculties of the simple shooting method, a
modiﬁed method, called the multiple-shooting method [92], has been developed. In a
multiple-shooting method, the time interval [t0, t f ] is divided into M +1 subintervals.
The shooting method is then applied over each subinterval [ti , ti+1] with the initial
values of the state and adjoint of the interior intervals being the unknowns that need to
be determined. In order to enforce continuity, the following conditions are enforced
at the interface of each subinterval:

−
p(t
i

+
) = p(t
i

−
) ⇐⇒ p(t
i

+
) − p(t
i

) = 0,

(1.32)

where p(t) is the combined state-costate vector, that is,

p(t) =

(cid:8)

(cid:9)

.

x(t)
λ(t)

The continuity conditions of Eq. (1.32) result in vector root-ﬁnding problem where
−
) to zero. It
it is desired to drive the values of the difference between p(t
i
is seen that the multiple-shooting method requires extra variables be introduced into
the problem (that is, the values of the state and adjoint at the interface points). Despite
the increased size of the problem due to these extra variables, the multiple-shooting
method is an improvement over the shooting method because the sensitivity to errors
in the unknown initial conditions is reduced by integrating over subintervals of the
original time domain t ∈ [t0, t f ]. Nevertheless, even multiple-shooting can present
issues if a sufﬁciently good guess of the costate is not used [48].

+
) − p(t
i

1.6.1.3 Indirect Collocation Methods

In an indirect collocation method, the state and costate are parameterized using
piecewise polynomials as described in Sect. 1.4.1. The collocation procedure leads
to a root-ﬁnding problem where the vector of unknown coefﬁcients z consists of the

1 Trajectory Optimization: A Survey

13

coefﬁcients of the piecewise polynomial. This system of nonlinear equations is then
solved using a root-ﬁnding technique (for example, Newton’s method).

1.6.2 Direct Methods

Direct methods are fundamentally different from indirect methods. In a direct method,
the state and/or control of the original optimal control problem are approximated in
some appropriate manner. In the case where only the control is approximated, the
method is called a control parameterization method [46]. When both the state and
control are approximated the method is called a state and control parameterization
method. In either a control parameterization method or a state and control parameteri-
zation method, the optimal control problem is transcribed to a nonlinear optimization
problem or nonlinear programming problem [4, 11, 15, 21, 44] (NLP).

1.6.2.1 Direct Shooting Method

The most basic direct method for solving trajectory optimization problems is the
direct shooting method. The direct shooting method is a control parameterization
method where the control is parameterized using a speciﬁed functional form. For
example, the control could be parameterized as

u(t) ≈

ai ψi (t),

m(cid:2)

i=1

(1.33)

where ψi (t), (i = 1, . . . , m) are known functions and ai , (i = 1, . . . , m) are the
parameters to be determined from the optimization. The dynamics are then satisﬁed
by integrating the differential equations using a time-marching algorithm. Similarly,
the cost function of Eq. (1.1) is determined using a quadrature approximation that is
consistent with the numerical integrator used to solve the differential equations. The
NLP that arises from direct shooting then minimizes the cost subject to any path and
interior-point constraints.

1.6.2.2 Direct Multiple-Shooting Method

In a manner similar to that for indirect methods, in a direct multiple-shooting method,
the time interval [t0, t f ] is divided into M +1 subintervals. The aforementioned direct
shooting method is then used over each subinterval [ti , ti+1] with the values of the
state at the beginning of each subinterval and the unknown coefﬁcients in the control
parameterization being unknowns in the optimization. In order to enforce continuity,
the following conditions are enforced at the interface of each subinterval:

14

−
x(t
i

+
) = x(t
i

−
) ⇐⇒ x(t
i

+
) − x(t
i

) = 0.

A. V. Rao

(1.34)

The continuity conditions of Eq. (1.34) result in vector root-ﬁnding problem where
−
) to zero. It is
it is desired to drive the values of the difference between x(t
i
seen that the direct multiple-shooting method increases the size of the optimization
problem because the values of the state at the beginning of each subinterval are pa-
rameters in the optimization. As with indirect multiple-shooting, the direct multiple-
shooting method is an improvement over the direct shooting method because the
sensitivity to errors in the unknown initial conditions is reduced by integrating over
subintervals of the original time domain t ∈ [t0, t f ].

+
) − x(t
i

1.6.2.3 Direct Collocation Methods

Arguably the most powerful methods for solving general trajectory optimization
problems are direct collocation methods. A direct collocation method is a state and
control parameterization method where the state and control are approximated using
a speciﬁed functional form. The two most common forms of collocation are local
collocation and global collocation. A local collocation method follows a procedure
similar to that of Sect. 1.4.1 in that the time interval [t0, t f ] is divided into S subin-
tervals [ts−1, ts], (s = 1, . . . , S) where tS = t f . In order to ensure continuity in the
state across subintervals, the following compatibility constraint is enforced at the
interface of each subinterval:

−
y(t
i

+
) = y(t
i

),

(s = 2, . . . , S − 1).

(1.35)

In the context of trajectory optimization, local collocation has been employed
using one of two categories of discretization: Runge-Kutta methods and orthogonal
collocation methods. Nearly all Runge-Kutta methods used are implicit [31–36, 49,
69, 88, 89] because the stability properties of implicit Runge-Kutta methods are
better than those of explicit methods. The seminal work on orthogonal collocation
methods in trajectory optimization is due to Reddien [84], where Legendre-Gauss
points were used together with cubic splines. Following on Reddien’s work, Cuthrell
and Biegler used LG points together with Lagrange polynomials [28, 29]. Interest-
ingly, Cuthrell [29] showed mathematically that the indirect transcription using LG
points was equivalent to the KKT conditions obtained from the NLP of the direct
formulation. In the 1990s, orthogonal collocation methods were developed using
higher-order Gauss-Lobatto collocation methods [38, 39, 54, 55]. Finally, the con-
vergence rates of an orthogonal collocation method using Legendre-Gauss-Radau
(LGR) points was studied [64].

Generally, employing direct local collocation leads to a large sparse NLP, where
the NLP contains potentially thousands to hundreds of thousands of variables and
constraints. Moreover, such large NLPs arise from trajectory optimization problems
that consist of hundreds of of states and controls. Because the NLP is sparse, however,
many of the derivatives of the constraint Jacobian are zero. This feature of local direct

1 Trajectory Optimization: A Survey

15

collocation makes it possible to solve such problem efﬁciently using appropriate NLP
solvers such as SNOPT [43, 45], SPRNLP [17], and KNITRO [26].

1.7 Software for Solving Trajectory Optimization Problems

A wide variety of software tools have been developed for solving trajectory optimiza-
tion problems. Most of these software programs use direct methods. One well known
software program employing indirect methods is BNDSCO [71] which employs a
multiple-shooting method. Perhaps the oldest software tool that employs direct meth-
ods is the Program to Simulate and Optimize Trajectories [22] (POST). POST was
originally developed to solve problems in launch vehicle trajectory optimization and
it still in use today for such applications.

The late 1980s saw a transformation in the available tools for solving trajectory
optimization problems. This transformation was coincident with the observation
of the power of direct collocation methods. The ﬁrst well-known direct colloca-
tion software was Optimal Trajectories by Implicit Simulation [95] (OTIS). OTIS is
a FORTRAN software that has general-purpose capabilities for problems in aero-
nautics and astronautics. OTIS has been used widely in the aerospace and defense
industries and its theoretical foundations are found in Ref. [52]. Following shortly
after the development of OTIS is the program Sparse Optimal Control Software [18]
(SOCS). SOCS is a highly powerful FORTRAN software that is capable of solving
many highly challenging trajectory optimization problems (see Ref. [15] for highly
complex optimal control problems solved with SOCS). Some of the applications
solved using SOCS are found in Refs. [12–14, 16, 77]. Finally, three other direct col-
location FORTRAN programs are MISER [47], Direct Collocation [96] (DIRCOL),
Graphical Environment for Simulation and Optimization [1] (GESOP), and Nonlin-
ear Trajectory Generation [70] (NTG). Like OTIS and SOCS, DIRCOL and GESOP
use local direct collocation techniques while NTG is designed for rapid trajectory
generation of differentially ﬂat systems.

In recent years, interest in the particular application of optimal control to space
ﬂight has led to the development of several useful programs. One such program
is Mission Design and Analysis Software [87] (MIDAS) which is designed to solve
complex ballistic heliocentric transfer trajectories for interplanetary space ﬂight mis-
sions. Another tool that has been recently developed is the NASA Generalized Mis-
sion Analysis Tool [61] (GMAT). Another tool that has been widely used in the last
several years is COPERNICUS [72, 73]. Both GMAT and COPERNICUS are de-
signed to solve trajectory optimization problems where the maneuvers can be treated
as either impulsive or ﬁnite-thrust burns.

While earlier software programs used compiled languages such as FORTRAN, in
recent years, MATLAB® has become increasingly popular for solving optimization
problems. The increased appeal for MATLAB emanates from the fact that MATLAB
is an extremely easy environment in which to program along with the fact that many
of today’s most powerful NLP solvers are now available for use in MATLAB® (for

16

A. V. Rao

example, standalone MATLAB mex versions are now available for the NLP solvers
SNOPT [43, 45] and KNITRO [26]). In addition, the TOMLAB [19, 37, 57–60] pack-
age has facilitated additional solvers for use in MATLAB. In addition, because of
major computational improvements, the computational efﬁciency between MATLAB
and compiled languages is growing ever closer. Examples of MATLAB-based trajec-
tory optimization software programs include RIOTS_95 [90], DIDO [85], DIRECT
[98], PROPT [86], OPTCONTROLCENTRE [63], GPOPS [80], and GPOPS-II [74].
It is important to note that all of the trajectory optimization software programs
described above incorporate gradient methods for solving the NLP. In a less formal
manner, heuristic methods have also been used to solve trajectory optimization prob-
lems. For example, interplanetary trajectory optimization problems using a genetic
algorithm have been considered in Refs. [41, 53] while low-thrust orbit transfers
using a genetic algorithm have been studied in Refs. [27] and [83]. In addition, a
calculus of variations technique has been used together with a genetic algorithm to
optimize low-thrust Mars-to-Earth trajectories for the Mars Sample Return Mission
[99]. Thus, while gradient methods are somewhat the de facto standard for trajectory
optimization, the aforementioned research demonstrates that genetic algorithms may
be well-suited for some applications.

1.8 Choosing a Method

Choosing a method for solving a trajectory optimization problem is based largely
on the type of problem to be solved and the amount of time that can be invested
in coding. An indirect shooting method has the advantage that it is simple to un-
derstand and produces highly accurate solutions when it converges. Unfortunately,
indirect shooting is extremely sensitive to the unknown boundary conditions. In addi-
tion, indirect shooting requires the derivation of the ﬁrst-order optimality conditions
of the trajectory optimization problem [see Eqs. (1.24)–(1.29]! While for simple
problems it may be possible to derive the ﬁrst-order optimality conditions, deriv-
ing such conditions for complex optimal control problems is tedious, error-prone,
and sometimes impossible (for example, problem with table lookups). Furthermore,
the need to derive the optimality conditions makes implementing indirect shooting
difﬁcult in a general-purpose software program. For example, if it was required to
derive ﬁrst-order optimality conditions, a program such as POST would become
nearly impossible to use because every new problem would require the derivation
of these conditions! A multiple-shooting method overcomes some of the numerical
difﬁculties of standard shooting, but does not avoid the issue of having to derive the
optimality conditions.

The accuracy and robustness of a direct method is highly dependent upon the form
of direct method used. Direct shooting methods are very good for problems where
the control can be parameterized in a simple manner (for example, piecewise linear
functions of time) and the problem can be characterized accurately using a small
number optimization parameters. Software programs such as POST perform well

1 Trajectory Optimization: A Survey

17

on launch vehicle ascent trajectories because these problems can be approximated
accurately using simple control parameterizations. As the complexity of the problem
increases, it becomes more and more apparent that the workhorse for solving trajec-
tory optimization problems is the direct collocation method. The two main reasons
that direct collocation methods work so well is because highly complex problems
can be formulated and solved with today’s NLP solvers. The reason that the NLP
solvers can handle such complex problems is because they are designed to converge
with poor initial guesses (for example, straight line guesses in the state and control)
and are extremely computationally efﬁcient because they exploit the sparsity of the
derivatives in the constraints and objective function.

In many cases, the solution of a trajectory optimization problem is a means to an
end, that is, the user does not want to know all of the details about a method, but
simply wants to use a software program to provide results so that a particular problem
of interest can be solved. If one does not wish to become an expert in the technologies
associated with trajectory optimization, it is advisable to obtain a canned software
package that allows a user to input the problem in an intuitive manner. Then the
software can simply be run on the problem of interest. It is always important to
understand, however, that canned software can have its issues when things go wrong
because the user may often not understand why.

1.9 Applications to Automotive Systems

The numerical methods provided in this survey are designed to generate reference tra-
jectories and corresponding reference controls for systems that have well developed
deterministic models. In the context of automotive systems, the methods described in
this paper would be of relevance to optimal control in systems where performance is
important. For example, state-of-the-art direct collocation software such as GPOPS-
II or SOCS could be employed to generate highly accurate trajectories to determine
the minimum lap time required in a in high-speed race car problem (for example, For-
mula One racing). In addition, the indirect methods described in this paper could be
the starting point for developing near-optimal feedback controllers for use in engine
design or in autonomous ground vehicles. Thus, the numerical methods described
in this survey could be used to generate solutions to a wide variety of problems in
automotive systems, and the particular numerical method employed would depend
upon the intended use of the solution.

1.10 Conclusions

A survey of numerical methods for solving trajectory optimization problems has been
given. The problem of solving optimal control problems has been decomposed into
the three key components of solving differential equations and integrating functions,

18

A. V. Rao

solving nonlinear optimization problems, and solving systems of nonlinear algebraic
equations. Using these components, the two classes of indirect and direct methods
for solving optimal control problems have been described. Subsequently, important
computational issues have been discussed and several different software tools for
solving optimal control problems have been described. Finally, a brief discussion
has been given on how to choose a method.

Abstract The automotive calibration process is becoming increasingly difﬁcult as
the degrees of freedom in modern engines rises with the number of actuators. This
is coupled with the desire to utilise alternative fuels to gasoline and diesel for the
promise of lower CO2 levels in transportation. However, the range of fuel blends
also leads to variability in the combustion properties, requiring additional sensing
and calibration effort for the engine control unit (ECU). Shifting some of the calibra-
tion effort online whereby the engine controller adjusts its operation to account for
the current operating conditions may be an effective alternative if the performance
of the controller can be guaranteed within some performance characteristics. This
tutorial chapter summarises recent developments in extremum seeking control, and
investigates the potential of these methods to address some of the complexity in
developing fuel-ﬂexible controllers for automotive powertrains.

2.1 Introduction

Reciprocating engines are used in transportation and stationary power generation,
with diesel and gasoline representing the vast majority of the fuels used. Their envi-
ronmental impact is observable in the fact that the Australian transport sector con-
tributes approximately 15 % of national CO2 equivalent emissions [20], while this
ratio is slightly higher in the EU and US at 17.5 and 22 % respectively. Meanwhile,
over the period 1990–2007 the relative cost of oil has also risen nearly 300 % [33].
The environmental impact of petroleum fuels has led to substantial consideration
and investigation of lower CO2 emitting alternatives. Regional dependencies dictate
that the best option from a fuel security and cost perspective are not unique with
the possible options including liquiﬁed petroleum gas, compressed natural gas and
various levels of ethanol blending with gasoline.

While the concern over the environmental ramiﬁcations of exhaust emissions
has been well publicised, the public health implications of emissions are only just
coming to light. A study by the Californian Air Resources Board [5] estimated 9,000
premature deaths during 2007 in California alone are attributable to particulate matter
of diameter less that 2.5 microns. By way of comparison, natural gas has less than
half the particulate matter of diesel [23], and liqueﬁed petroleum gas (LPG) has 70 %
fewer particulate emissions than gasoline [4].

The downside of both these and other alternative fuels, however, is that in unreﬁned
form their composition is variable. Consequently, subsequent operation can vary
markedly, for example a 20 % change in fuel consumption was observed across a
range of typical CNG blends in [10], while LPG can vary from propane-butane ratios
of 25:75–100:1, with emissions performance signiﬁcantly impacted [24].

From the engine control systems perspective, the challenge of changing compo-
sition is reﬂected in Fig. 2.1. In this ﬁgure, the torque produced from an internal
combustion engine for spark sweeps on two CNG blends at a close to idle operating
condition are presented. Here, an incorrect (ﬁxed) assumption on fuel composition
would lead to an incorrect MBT estimate used by the engine controller—leading
to efﬁciency degradation and possible increased coefﬁcient of variation of indicated
mean effective pressure. The same scenario of lost optimality applies for other engine
inputs.

While this approach focuses on the immediate penalty associated with changing
fuel composition, the presence of hierarchical control algorithms in many of the
more complex powertrains can also lead to performance and efﬁciency degradation
if the composition is incorrectly modelled. One such example is investigated in [13],
where a turbocharged ﬂex fuel engine is used in a hybrid power train with an optimal
Equivalent fuel Consumption Minimisation Strategy (ECMS) controller based on
Pontryagin’s Minimum Principle.

Figure 2.2 shows the fuel consumption maps mapped using E5 and E85 fuels for
the test engine. In this instance, it was found that incorrect assumptions of the fuel
consumption could lead to fuel efﬁciency degradation of the hybrid vehicle of up
to 30 % relative to the best possible performance obtained when the fuel map was
known perfectly and available to the ECMS-based hybrid power train controller.

For ﬁxed fuel operation, the traditional approach to engine control is to apply a look
up table approach whereby the inputs are predetermined for each engine operating
point using a lengthy calibration procedure. While many proposed engine control
approaches use dynamic engine models in the controller [22, 27], they typically
maintain look up tables to capture properties relating to in-cylinder dynamics such as
indicated efﬁciency. These multidimensional surfaces are obtained during a separate
calibration procedure. In both situations, if the fuel composition varies from that

2 Extremum Seeking Methods for Online Automotive Calibration

25

Gas A
fitted curve
Gas B
fitted curve

35

34

33

32

31

30

29

28

)

m
N

(
 

e
u
q
r
o
T

30

35

40

45

50

Spark Advance [CAD BTDC]

Fig. 2.1 Result of open loop spark sweeps with Gas A (pure methane) and Gas B (80 % methane,
9 % CO2, 8.5 % N2, 2 % ethane and 0.5 % propane) at 1,500 rpm and low load

5000

4000

3000

)

m
p
r
(
 
d
e
e
p
S

2000

0.3

1000

0.2

0.3

0.4

0.3

0.25

0.35

0.3

5500

5000

4500

4000

3500

3000

2500

2000

1500

1000

)

m
p
r
(
 
d
e
e
p
S

0.25
0.2

0.15

0.1

0.2

0.35

0.35

50

100

150

200
Torque (Nm)

250

300

50

100

150

200
Torque (Nm)

250

300

Fig. 2.2 Engine efﬁciency maps for a ﬂex fuel engine running with (left) E05 and (right) E85 fuel

0.4

0.4

used during the calibration, the engine controller performs suboptimally and overall
engine performance may degrade.

As a consequence, it would appear there is a need to implement some form of
online optimisation to maximise the beneﬁts promised by alternative fuels. However,
the inclusion of any such adaptive capability must be in conjunction with rigorous
guarantees on the performance of the closed loop system. With this in mind, recent
developments in extremum seeking methods appear a good potential solution candi-
date, and three main categories of extremum seeking algorithms are reviewed in the
subsequent section.

26

C. Manzie et al.

Fig. 2.3 Basic SISO extremum seeking scheme exhibiting sinusoidal perturbation to plant input,
with high and low pass ﬁlters either side of demodulation step

This is then followed by a discussion of some of the automotive implementations
of extremum seeking algorithms currently reported in the literature, as well as an
outline of future possibilities for future research directions from both a theoretical
and application based perspective.

2.2 Review of Extremum Seeking

The ﬁrst known examples of extremum seeking techniques date back to 1922 [12],
with several practical examples seen up until the 1950s, however the lack of formal
proofs and performance guarantees led to the approach being largely set aside of
several decades. This changed around the turn of the century with the development
of local stability results in [11] for the basic extremum seeker shown in Fig. 2.3.

This approach essentially uses a sinusoidal perturbation to perturb the input to
a dynamic plant with output y. The output is high pass ﬁltered to remove any DC
offset, before being multiplied by the dither to demodulate the gradient estimate.
The gradient information can now be isolated by low pass ﬁltering to remove all
components of the plant output that are harmonics of the dither frequency. The
resulting gradient estimate is then used in a gradient descent algorithm to push the
plant towards its minimum. Provided the plant has a smooth output function h(x) to
which the output converges uniquely then semi-global practical stability is achieved
with appropriate tuning of the parameters a, b, c, k and ω.

Following these initial results, many implementations of extremum seeking tech-
niques have followed and further reﬁnements of the theoretical foundations have been
made. A comprehensive review of both the theoretical developments and applications
of extremum seeking over the period 1922–2010 is provided in [30].

The extremum seeking literature can now be broadly classiﬁed into three groups:
black-box approaches; grey-box approaches; and sampled data approaches. These

2 Extremum Seeking Methods for Online Automotive Calibration

27

Fig. 2.4 Generalised black box extremum seeking framework

have different implementations and subsystem requirements which will be discussed
in the following sections.

2.2.1 Black-Box Extremum Seeking

A guiding principle of the basic extremum seeking algorithm outlined above is that
no model information about the plant is required, leading to it often being referred to
as a black box scheme. Other approaches reported in the literature have considered
alternative components in place of the ﬁlters and gradient descent in Fig. 2.3, with
the essence of the majority of these black box approaches captured in Fig. 2.4, which
shows the dynamic plant connected to a gradient estimator, and ﬁnally the input to
the plant updated through an appropriate optimisation algorithm.

Although more formally stated in [18], the following requirements are placed on

the components of Fig. 2.4 in a general setting.

Plant: The plant dynamics,

f (x, u) have an asymptotically stable equilibrium
described for each plant input u by the surface x = l(u). The input–output map
of the plant at equilibrium Q(u) := h(l(u)) is continuous and has a unique global
maximum, u∗.

Gradient estimator: Consider the ﬁrst N -derivatives of Q(u) as represented in

the vector DN (Q), i.e.:

DN (Q) :=

(cid:2)

d Q
du

, . . . , d N Q
du N

(cid:3)T

(2.1)

The gradient estimator and dither signal must contains sufﬁcient excitation of the
plant to provide sufﬁciently accurate estimation of DN (Q) over a ﬁnite time interval.
The dynamics of the gradient estimator may be represented as:

28

˙ˆDN (Q) = ε1 F1( ˆDN (Q), P, y)
˙P = ε1 F2(P, y)

C. Manzie et al.

(2.2)
(2.3)

Here P represents the presence of potential auxiliary states in the estimator.

Unlike in the extremum seeking scheme of Fig. 2.3, the dither need not be sinu-
soidal, and is only necessary to ensure the ﬁrst N gradients of the input–output
plant map can be estimated (assuming the chosen optimiser requires N derivatives).
Consequently, various dither alternatives such as square wave, triangular wave and
stochastic signals have been used. As with the dither signal, numerous gradient
derivative estimators have been proposed and successfully deployed, ranging from
combinations of ﬁrst order ﬁlters [3, 19], through to Luenberger observers [15] and
Kalman ﬁlters [32]. The dynamics of the gradient estimator are controlled through the
tuning parameter ε1, representing for example the cut-off frequency of the high pass
ﬁlter or the gain used by a Luenberger observer. The suitable choice of ε1 typically
delivers time scale separation of the plant and estimator dynamics.

Optimiser: Consider the continuous optimisation algorithm operating on known

derivatives DN (Q) of a static map Q(z):

˙z = ε2 F3(z, DN (Q(z)))

(2.4)

The chosen optimisation algorithm ensures that the output of the static map Q(z)
converges to the optimum value, Q(z∗), with some degree of robustness. Again
there are many possible choices for the optimiser, ranging from the gradient descent
approach shown in Fig. 2.3, to higher order optimisers such as Newton step [15] and
other variants, although all typically have tunable dynamics represented by ε2. As
with the gradient estimator, the choice of ε2 is used to ensure time scale separation,
this time between the gradient estimator and the optimiser.

This decomposition of the closed loop extremum seeking scheme enables the prac-
titioner to independently select the optimiser and gradient estimator from families of
possible options satisfying the requirements stated above. The overall convergence
of the system is then guaranteed by ensuring that the plant, gradient estimator and
optimiser occupy different time scales (formally stated in Theorem 1 of [18]). This is
achieved by selecting the gains such that the gradient estimator is sufﬁciently slower
than the plant, and the optimiser is sufﬁciently slower than the gradient estimator
to ensure time scale separation—therefore enabling the plant to be ‘seen’ as a static
map by the gradient estimator, and both components to be ‘seen’ as static by the
optimiser.

There is a tradeoff to be balanced in selecting the gains and dither, as smaller
values yield slower convergence but guarantee the convergence of the output will be
to a smaller vicinity of the optimum of the static map, Q(u).

The generality of the framework presented above is useful in guaranteeing conver-
gence and developing tuning rules despite very little knowledge of the plant. How-
ever, one potential drawback of this generality is the conservativeness of the result
particularly in terms of convergence rate, to ensure time scale separation between

2 Extremum Seeking Methods for Online Automotive Calibration

29

Fig. 2.5 Generalised it grey box extremum seeking framework

the major system elements. With greater speciﬁcity about the plant structure, and by
utilising particular schemes for gradient estimation and optimisation, faster conver-
gence properties can be obtained. Such approaches have been described for Wiener-
Hammerstein plants [14], and principally rely on plant input and output ﬁlters to
remove the need to wait for plant dynamics to settle before updating the extremum
seeking output. This allows for high frequency dithers to be employed and arbitrarily
fast (in the absence of noise) convergence to be achieved.

2.2.2 Grey-Box Extremum Seeking

The fast extremum seeking approaches of the previous section utilise knowledge
about the plant dynamics in the design of the input and output ﬁlters. In many prac-
tical applications however, there is knowledge of the basic form of the optimisation
surface, Q(u), to which the dynamics converge. The utilisation of this knowledge in
an extremum seeking context falls largely in the domain of the so-called grey box
approaches. Here, the surface Q(u), is parameterised in terms of a vector of unknown
parameters, θ, i.e.:

Q(u, θ) = Ψ (u)T θ

(2.5)

Thus, by estimating θ potentially non-local information about the surface can be
obtained. In [1, 2], this approach was explored for speciﬁc instances of the parameter
estimator and optimiser, and then further generalised in [16] leading to a description
of the closed loop system in the form shown in Fig. 2.5.

The parallels with the generalised black box framework of Fig. 2.4 are clear, and
there exist similar requirements on the plant and optimiser in the grey box scheme,
although the following requirement for the parameter estimator replaces that for the
gradient estimator given above.

Parameter estimator: The parameter estimator can be represented in the general
form as states directly relevant to the parameter estimates and additional states within
the parameter estimator, i.e.:

30

˙ˆθ = ε1G1( ˆθ, P, y, u)
˙P = ε1G2(P, y, u)

C. Manzie et al.

(2.6)
(2.7)

The parameter estimator and dither signal combination needs to contains sufﬁcient
excitation of the plant to provide estimation of the parameters within a ﬁnite time
interval. A thorough analysis of a number of different parameter estimation schemes
was conducted in [16], with possibilities for deployment including gradient algo-
rithms with and without integral costs along with least squares estimation variants.
By incorporating the parameter estimator in place of the gradient estimator, the
optimiser can potentially utilise differently structured optimisers that may take advan-
tage of the estimated map, while still satisfying the time scale separation of the black
box scheme. This reliance on time scale separation implies that substantial increases
in convergence rates over the black box approach are not necessarily forthcoming.
With this in mind, preliminary research has been made into algorithm speciﬁc
grey box approaches that lack the generality of the framework described above but
may have potential along the lines of the fast black box approaches described in the
previous section [26].

2.2.3 Sampled Data Approaches

The previous two categories of extremum seeking algorithms use continuous time
optimisation algorithms, and consequently only draw upon the discrete time opti-
misation ﬁeld indirectly through the time scale separation providing the optimiser
can satisfy the requirements. An alternative viewpoint, drawing more directly on
nonlinear programming techniques, was ﬁrst presented in [31], and is illustrated in
Fig. 2.6.

In this approach, the dynamic plant is treated as a system to be sampled, with
a ﬁnite number of sampled plant outputs used to estimate derivatives of the static
map before the control input is updated, and enabled the use of many discrete time
optimisation algorithms such as Finite Differencing and Simultaneous Perturbation
Stochastic Approximation (SPSA) [29]. The work was generalised further in [9],
where a different style of proof was used and required the discrete time optimisation
algorithm to be uniformly attractive with respect to small additive disturbances, rather
than asymptotically stable as in [31]. The later approach also opens the possibility
for non-gradient based global optimisation algorithms such as Piyavskii-Shubert and
DIRECT to be rigorously deployed [8, 17] thereby reducing the requirement that the
plant have only one global optimum—albeit at signiﬁcant convergence time penalties
relative to the local optimisation techniques.

As seen with the continuous extremum seeking approaches, there may be advan-
tages in forsaking generality of the sampled data approach and focusing on a speciﬁc
combination of discrete time optimiser and plant. In [28], a discrete time Hammer-
stien plant is subjected to an algorithm using a square wave dither with a two step

2 Extremum Seeking Methods for Online Automotive Calibration

31

Fig. 2.6 Generalised sampled data extremum seeking framework

averaging ﬁlter with the speciﬁc nature of the system enabling LPV techniques to be
used to generate an exponential stability result.

2.3 Application to Automotive Engine Calibration

One of the earliest applications of extremum seeking in the automotive calibration
context was in [25], where a grey box extremum seeking architecture was designed
and implemented for spark control on a gasoline spark ignition engine. The approach
assumed a quadratic map between the spark angle and indicated torque, similar to
Fig. 2.1. The parameters of the quadratic were then estimated using a recursive least
squares estimator, although the optimiser used attempted to immediately drive the
control input to the optimum level as calculated by the estimated parameters, and
consequently the time scale separation required for convergence guarantees in the
grey-box schemes of Sect. 2.2.2 was not present. Thus while successful results were
reported, the initial conditions of the parameter estimator need to be sufﬁciently close
to the true values for convergence to occur.

Addressing the multi-variable calibration problem from an extremum seeking
perspective was explored in [21]. This approach considered a sampled data imple-
mentation of extremum seeking (as in Sect. 2.2.3), with the actuation variables of
intake and exhaust valve timing along with the spark timing. From arbitrary initial
conditions, the calibration process using extremum seeking was found to take around
15 min to locate the optimum, largely impacted by the multivariable nature of the
problem and the noise associated with torque measurements requiring long averages
of measured data.

In-service alternative fuelled engines may experience regular fuel composition
changes, yet the opportunity to undertake manual recalibration is not present. The
growing interest in these engines has renewed interest in online calibration. One
recent implementation considered the situation for ﬂex-fuelled engines [6] considers
a ES implementation in the class of black box systems described in Sect. 2.2.1 to
maximise fuel economy by adjusting the spark. This approach utilises a discrete
time version of the black box approach of the form given in Fig. 2.3, with a square

32

C. Manzie et al.

wave perturbation. Unlike in [21], only the spark is changed and this single variable
nature of the optimisation coupled with the fact that the optimisation problem is
effectively ‘hot-started’ as the optimal spark will not vary signiﬁcantly between
different ethanol-gasoline blends means the outcome is more positive in terms of
real world deployability.

In a similar vein, but with compressed natural gas blends as the fuel source, differ-
ent implementations of the grey box extremum seeking framework falling under the
framework of [16] were investigated as possible spark optimisation strategies. Exper-
iments are carried out for two blended pure methane and a blended gas consisting of
80 % methane, 9 % carbon dioxide, 8.5 % nitrogen, 2 % ethane and 0.5 % propane.
As with [25] and shown in Fig. 2.1, open loop tests demonstrate that a quadratic
polynomial approximation seems a good representation of the data, allowing the
following model to be used relating torque, τ , and spark α:

τ (α) = λ1α2 + λ2α + λ3

(2.8)

Deﬁning the regressor vector φ = [α2 α 1]T , the grey box approach then involves
the selection and tuning of appropriate parameter estimator for θ := [λ1 λ2 λ3]T ,
and an optimiser to drive τ towards τ ∗.

To demonstrate the ﬂexibility afforded by the framework approach, experiments
were conducted using two different estimator-optimiser combinations. The ﬁrst con-
sisted of recursive least squares parameter estimator and gradient based optimiser,
while the second consisted of a gradient based parameter estimator and a Jacobian-
matrix transpose optimisation metric. All parameter estimators and optimisers had
previously been shown to satisfy the theoretical requirements of the grey box frame-
work in [16], and the tuned algorithms are repeated below in (2.9)–(2.13). The dis-
crete nature of the presented algorithms reﬂects an emulation of the continuous time
versions of (2.6)–(2.7) and (2.4).

Gradient-based parameter estimator after tuning:

ˆθk+1 = ˆθk − [0.002 0.05 1]T (τk − φT

ˆθk)

k

Recursive least squares parameter estimator after tuning:

ˆθk+1 = ˆθk + Pkφk(τk − φT
Pk+1 = Pk + (0.9Pk − PkφT
k

ˆθk)
φk Pk)

k

Gradient based optimiser after tuning:

ˆα∗

k+1

= ˆα∗
k

+ 10(2 ˆak ˆα∗
k

+ ˆbk)

Jacobian matrix transpose optimiser after tuning:

ˆα∗

k+1

= ˆα∗
k

− 75 ˆak(2 ˆak ˆα∗
k

+ ˆbk)

(2.9)

(2.10)

(2.11)

(2.12)

(2.13)

2 Extremum Seeking Methods for Online Automotive Calibration

33

The applied spark advance is then the current estimate of the optimal spark
k , perturbed by a sinusoidal dither of amplitude one crank angle degree,

advance, ˆα∗
i.e.:

αk = ˆα∗
k

+ sin(0.1kT )

(2.14)

All experiments to test these algorithms were conducted in the test cell of the
ACART Laboratory at the University of Melbourne. The engine tested a six cylinder
4L Ford Falcon BF MY2006 gasoline engine which is converted to operate with
natural gas.

In order to keep the speed and load of the engine constant, an eddy current
dynamometer is used which can only work as a brake and is not capable of motoring
the engine. The air-fuel ratio was maintained at an approximately stoichiometric con-
dition by adjusting the injection duration with feedback from a wide-band exhaust
oxygen gas sensor. The proposed algorithms were implemented in MATLAB. The
output of the MATLAB program were sent in realtime directly to the engine control
unit (ECU) via ATI Vision software, thereby adapting the stored calibration. The
delays in communication between the different software programs were measured
at approximately 6 ms, which was considered negligible in the context of this appli-
cation. Feedback torque was obtained through measurements from a load cell on
the dynamometer, although in the future could be replaced by in-cylinder pressure
sensors and appropriate combustion analysis. The torque measurement was averaged
over a period of three seconds to minimize the effects of combustion variability and
measurement noise. The sample rate used by the controller was set nominally to 5 s
so as to be longer than the torque measurement time.

The engine control unit was initially calibrated using the blended methane gas,
leading to an initial estimate of MBT at approximately 40◦ BTDC. The actual fuel
used in the engine was pure methane, and consequently the extremum seeking con-
trollers were required to adapt the spark to ﬁnd the new MBT spark, which lies at
approximately 33◦ BTDC, although may vary slightly with engine temperature. The
adapted spark and resulting engine torque for each of the two extremum seeking
combinations are shown in Figs. 2.7 and 2.8.

In both instances, (although not shown) the parameter estimates also converge
to a vicinity of the ‘true’ values, and the spark converges to a close vicinity of the
optimum. To quantify the gains in efﬁciency the incorporation of these extremum
seeking approaches strategies may provide, the fuel ﬂow rate of the engine running
with the initial spark advance at the speciﬁed operating point was compared to fuel
ﬂow rate after convergence of the spark to the optimal value. This latter value was
corrected to allow for the torque difference although in practice this could be achieved
through modiﬁcation to the throttle angle. Consequently it was found that the fuel
economy improved by approximately 3 % at this static operating condition.

To further demonstrate the ﬂexibility of viewing extremum seeking as a framework
approach, a sampled data approach is also presented for the same engine. In this
approach, an ES scheme using a simple alternating dither signal a(−1)k is added
to the current estimate for the optimising value of the system input, and used as the
applied spark in place of (2.14). The resulting torque (after the two second averaging)

34

C. Manzie et al.

]

C
D
T
B
D
A
C

 

[
 

l

e
g
n
A
 
k
r
a
p
S

)

m
N

(
 
e
u
q
r
o
T

50

45

40

35

30

25

20

35

34

33

32

31

30

29

0

50

100

150

200

250

0

50

100

150

200

250

Time (sec)

Fig. 2.7 Grey box convergence for a recursive least squares parameter estimator and gradient based
optimiser (top) spark advance (bottom) measured and 2 s averaged engine torques

is multiplied by the signal (−1)k and passed through a two-step moving-average
FIR ﬁlter and discrete-time integrator. This advances the estimate for the optimising
value according to an approximate gradient ascent law, based on a two-point central
difference approximation applied to the engine spark-to-torque mapping. The entire
closed loop scheme is represented by the block diagram shown in Fig. 2.9.

Implementing this sampled data extremum seeking approach on the same engine
set up as described previously, with an initial estimate of MBT spark of 22◦ leads to
the results shown in Fig. 2.10. As previously observed for the grey box approaches,
convergence to the vicinity of the optimum spark and torque occurs and there is a
subsequent improvement in fuel economy of approximately 3 % at this operating
point relative to the case of no adaptation of the spark.

The convergence speed of the algorithms tested in this section warrants discussion.
As shown in Figs. 2.7–2.10, the schemes take of order 100 s to converge to the
optimum at a ﬁxed operating condition. On its own, this convergence time is not of
signiﬁcant concern as the rate of change of fuel composition is much slower thereby
allowing even a 100 s transient to be deemed negligible if steady state operation is
considered.

During transient engine operation, such as might be considered during urban
driving, it is however unlikely that the engine will remain at a constant, non-idle
operating condition for periods of this duration. The convergence rate is a conse-
quence of the nature of the time scale separation requirement of the plant, esti-
mator and optimiser for the extremum seeking framework-based theory, which is

2 Extremum Seeking Methods for Online Automotive Calibration

35

]

C
D
T
B
D
A
C

 

l

[
 
e
g
n
A
 
k
r
a
p
S

)

m
N

(
 
e
u
q
r
o
T

50

45

40

35

30

25

20

35

34

33

32

31

30

29

0

50

100

150

200

250

0

50

100

150

200

250

Time (sec)

Fig. 2.8 Grey box convergence for a gradient based parameter estimator and Jacobian matrix
transpose (top) spark advance (bottom) measured and 2 s averaged engine torques

Fig. 2.9 Proposed sampled data extremum seeking approach for optimal spark estimation on CNG
engine

principally centred on guaranteeing convergence using very relaxed requirements on
the components of the closed loop scheme. By being more restrictive in the selection
of these components, the tuning requirements can be modiﬁed and the convergence
rate can potentially be sped up using the faster extremum seeking approaches in the
vein of [14].

Finally, for the purposes of demonstration of the extremum seeking techniques,
brake torque has been directly measured and used as the feedback to be optimised
in these experiments. Such a measurement is clearly not directly available in an

36

C. Manzie et al.

34

32

30

28

26

24

22

Torque (Nm)

Spark Advance (degrees)

0

100

200

300

400

Time (s)

Fig. 2.10 Spark and torque progression under the proposed sampled data extremum seeking
approach with a = 1◦

on-road application, and so surrogate measurements must be employed depending
on the available sensor set.

2.4 Incorporation of Constraints

Not discussed in the methodology so far is the issue of constraint management.
For input constraints, if the plant inputs, ¯u, are required to lie within a set, Uc, the
optimiser can explicitly take this into account by projecting the new optimiser output,
¯u pr oj onto the Pontryagin difference of the constraint set and the dither set, D i.e.:

Uc (cid:2) D (cid:3) { ¯u ∈ Rn | ¯u + d ∈ Uc, ∀d ∈ D}

¯u pr oj = proj( ¯u, Uc (cid:2) D)

(2.15)

(2.16)

This ensures the dither is still able to persistently excite the system, even approach-
ing the constraint boundary, and the gradient or parameter estimates in the black or
grey box schemes are maintained.

In the context of the engine calibration problem, this might mean for example the
physical actuator limits are captured so that, for example, the spark is constrained to
occur within the compression stroke of that cylinder. These types of constraints are
rigorously enforceable.

On the other hand, state constraints are not so easily dealt with as generally there
is no concept of ‘state’ in the model used in an extremum seeking controller. In

2 Extremum Seeking Methods for Online Automotive Calibration

37

this case, an approximate solution is that the state constraints must be mapped to
input constraints, so that Uc in (2.15)–(2.16) becomes time varying and most likely
requires online estimation.

Again in the context of the online calibration problem, the spark timing in a
natural gas engine is often constrained by knock limitations. The occurrence of
knock is related to the fuel composition, which can be viewed as an internal state and
is clearly unknown from the problem deﬁnition. Knock detection algorithms (see e.g.
[7] and the references within) can be used to continually estimate the knock limit on
spark advance, which may then be used to update the constraint set Uc.

2.5 Summary and Future Opportunities

The recent development of extremum seeking frameworks has delivered consider-
able ﬂexibility into the deployment of different algorithms to achieve convergence
to optimal performance in many applications. To the automotive community, this
appears to be highly relevant as the industry continues a progression towards alter-
native fuels exhibiting variable composition, thereby necessitating some form of
closed loop calibration being conducted during regular vehicle operation.

There remain a number of theoretical challenges and opportunities for research
in extremum seeking algorithms. These include research into increasing the conver-
gence rate without unduly compromising the region of attraction; dealing with map
uncertainty in grey box frameworks; handling state constraints within the various
frameworks; and identifying when certain frameworks might lead to better closed
loop performance.

Similarly, there are also application-centric issues for automotive calibration
including the deployment of the algorithms in transient driving conditions; imple-
menting some of the novel theoretical developments promising faster convergence for
online multivariable calibration; consideration of emissions in the cost function; and
the integration with model based techniques for faster ofﬂine calibration particularly
in highly actuated engines.

Abstract The control of autonomous vehicles is a challenging task that requires
advanced control schemes. Nonlinear Model Predictive Control (NMPC) and Moving
Horizon Estimation (MHE) are optimization-based control and estimation techniques
that are able to deal with highly nonlinear, constrained, unstable and fast dynamic
systems. In this chapter, these techniques are detailed, a descriptive nonlinear model
is derived and the performance of the proposed control scheme is demonstrated in
simulations of an obstacle avoidance scenario on a low-fricion icy road.

3.1 Introduction

Due to the well known vehicle-road dynamics, Model Predictive Control (MPC) is
an excellent tool for precise trajectory planning in autonomous vehicle guidance,
which can be of great importance in dangerous driving situations. High sampling
rates (i.e., in the range of tenths of Hertz) and long prediction horizons however,
which are required for a safe operation, pose a computational challenge, particularly
in combination with the involved nonlinear vehicle dynamics. Many recent chapter
chose a two-level MPC approach to overcome this computational challenge, being
composed of a coarse path planning algorithm with a long prediction horizon, and
a higher-ﬁdelity path following algorithm on a shorter horizon, cf. [1–4]. Only very
recently the computational feasibility of a challenging, realistic scenario using a
single MPC controller with a detailed nonlinear model was demonstrated in [5],
using auto-generated tailored C code based on the real-time iteration scheme [6] for
Bock’s multiple shooting method [7].

In the following, the results from [5] are extended and combined with the corre-
sponding Moving Horizon Estimation (MHE) scheme [8] for full state and paramter
observation in an realistic context. In particular we yet extend the vehicle model
used in [5, 8] by introducing a suspension model for a more realistic representation
of the driving behavior even in extreme situations. The MHE scheme has also been
modiﬁed to detect sudden changes in the road friction condition fast and reliably.

The description of the mathematical problem formulation is given in Sect. 3.2.
Section 3.3 provides a presentation of the real-time feasible algorithmic framework.
In Sect. 3.4, the vehicle model is derived, and simulation results are presented in
Sect. 3.5. Conclusions are drawn in Sect. 3.6.

3.2 Control and Estimation Problems

In order to formulate the control and estimation schemes let the system dynamics be
described by ordinary differential equations (ODE)

˙x = f(x, u).

(3.1)

where x(t) denotes the differential states and u(t) denotes the controls. The formu-
lations proposed in the following of the chapter can straightforwardly be extended
to systems governed by differential-algebraic equations DAE [9]. Parameters xp can
be considered as states with zero time derivative, i.e. ˙xp = 0.

3.2.1 Nonlinear Model Predictive Control

Nonlinear Model Predictive Control (NMPC) is an advanced control technique that
relies on the system model to predict the system trajectory and minimize its deviation
from a given reference. The full nonlinearity of the model can be taken into account by
NMPC and constraints depending on both states and controls can be easily enforced
in the problem formulation.

NMPC consists of solving the following dynamic optimization problem at every

time instant

3 Model Predictive Control of Autonomous Vehicles

≤x(t) − xr(t)≤2

+ ≤u(t) − ur(t)≤2
RC

dt

QC

minimize
x,u
⎧

+

Tc

0

subject to

≤x(Tc) − xr(Tc)≤2
PC

˙x(t) = f(x(t), u(t)),
x(0) = ˆx(0),
q(x(t), u(t)) ∈ 0,
x(Tc) ∞ XTc

,

t ∞ [0, Tc],

43

(3.2a)

(3.2b)
(3.2c)

(3.2d)
(3.2e)

where Tc is the prediction horizon. The objective function is usually formulated as a
least-squares (LSQ) objective (3.2a) penalizing the deviation from a given reference
xr(·), ur(·), where QC, PC ≈ 0 and RC ≡ 0 are weighting matrices, to be selected as
tuning parameters. The constraint (3.2b) enforces the system dynamics. The initial
condition (3.2c) imposes that the initial state coincides with the current estimate
ˆx(0) and additional path constraints (3.2d) can be enforced. Finally, a terminal con-
straint (3.2e) can also be enforced.

The stability of MPC has been ﬁrst proven for a steady-state reference under the
condition that Xt = {xr (Tc)}. In this context, the terminal cost ≤x(Tc) − xr(Tc)≤2
PC
does not appear in the formulation. In many practical cases, this formulation can
be too restrictive and lead to infeasibility of the optimization problem, especially
when the control horizon Tc becomes short. To increase feasibility, the terminal
constraint can be relaxed to an ellipsoidal constraint centered around the reference
and a terminal cost needs to be added to the problem formulation. Stability can be
proven under some conditions on the choice of the weighting matrix PC and the
ellipsoidal terminal constraint XTc . An excellent survey on stability of MPC is given
in [10].

In practice, MPC is often implemented without terminal constraint (3.2e) and, in
many cases, also without terminal cost. In this case, stability has been proved in [11],
provided that the prediction horizon Tc is long enough.

3.2.2 Moving Horizon Estimation

The problem of estimating the current state given a set of measurements can be
formulated as an optimization problem. This idea is at the basis of the Kalman ﬁlter.
Moving Horizon Estimation (MHE) can be seen as an extension of the Kalman ﬁlter
that can take into account the full model nonlinearities and gives the opportunity to
enforce constraints. It is important to stress though, that MHE relies on a deterministic
model and it does not need any speciﬁc assumption on the probability distribution
of the noise.

MHE consists in minimizing the mismatch between the measurements ˜y(t) com-
ing from the sensors and the ones predicted by the model measurement function
y(x(t), u(t)). This corresponds to the dynamic optimization problem

44

M. Zanon et al.

minimize
x,u

⎪
⎪x(−Te) − ˆx(−Te)

⎪
⎪2
PE

+

subject to ˙x(t) = f(x(t), u(t)),

⎧

0

−Te

q(x(t), u(t)) ∈ 0,

t ∞ [−Te, 0],

≤y(x(t), u(t)) − ˜y(t)≤2

dt

QE

(3.3a)

(3.3b)
(3.3c)

where Te is the estimation horizon. The cost function (3.3a) is usually formulated as
a least-squares term with the weighting matrix QE. Though MHE is a deterministic
observer, the probabilistic insight is very valuable for the choice of QE. In a sim-
ilar manner as for NMPC, the constraints (3.3b) enforce the system dynamics and
additional path constraints (3.3c) can be enforced.

Because of actuator noise and inaccuracy, the control inputs computed by the
controller ¯u may not be perfectly implemented by the system. Thus, in the proposed
formulation, the control inputs u are included as decision variables and their deviation
from ¯u is penalized, i.e. ≤u− ¯u≤2
is added to the cost function. This can be achieved
Qu
E
by adding pseudo-measurements to the measurement function y(x(t), u(t)).

The so-called arrival cost [(ﬁrst term in Eq. (3.3a)] has the important role of
summarizing past information in a quadratic term which depends on the initial state
x(−Te). For more details on the arrival cost see [12, 13].

3.3 Efﬁcient Algorithms for fast NMPC and MHE

The nature of the NMPC and MHE problems (3.2a)–(3.2e) and (3.3a)–(3.3c) is a
dynamic optimization problem. The complexity of such problems makes it hard for
general-purpose solvers to compute solutions fast enough for a real-time implemen-
tation. Tailored numerical algorithms are thus needed to overcome these challenges
in a real-time application.

3.3.1 Online Solution of the Dynamic Optimization Problem

A variety of methods has been proposed for the efﬁcient online (i.e., time-critical)
solution of dynamic optimization problems [6, 14–16]. While most methods are
targeted at problems from areas like chemical engineering with rather slow sam-
pling rates, one algorithm that has shown to be effective also for applications with
fast system dynamics, is the so called real-time iteration scheme [6]. This algo-
rithm is based on Bock’s direct multiple shooting method which was originally in-
troduced for the ofﬂine solution of optimal control problems [7]. Parametrizing the
control input functions by suitably chosen basis functions on a ﬁnite grid, the inﬁnite-
dimensional optimization problem is discretized yielding a ﬁnite-dimensional non-
linear programming problem (NLP). Initial value problems are solved on each of
these so called shooting intervals by appropriate numerical integration routines. The

3 Model Predictive Control of Autonomous Vehicles

45

resulting NLPs are highly structured and are originally solved using a sequential
quadratic programming (SQP) approach including a condensing step for projection
of the high-dimensional quadratic program (QP) on a signiﬁcantly lower dimen-
sional problem. Alternatively, structure exploiting QP solvers have been proposed
recently [17]. In contrast to Bock’s original multiple shooting method, the real-time
iteration scheme performs only one linearization and one QP solution per sampling
time. Thus, signiﬁcantly higher sampling rates can be achieved, yet contractivity
can still be guaranteed [18]. Furthermore, by performing the linearization based on
the previous iterate even before observing the new system state/measurement (initial
value embedding), feedback delays can be drastically reduced to simply the solution
time of a parametric QP [17, 19]. Still, the feedback law is a guaranteed ﬁrst order
approximation of its converged optimal solution, even in the presence of an active
set change. More details on the real-time iteration scheme are provided in [6, 18].

3.3.2 Fast Solvers Based on Automatic Code Generation

Automatic code generation of tailored solvers has recently shown to signiﬁcantly
reduce the computational times [20]. The ACADO Code Generation tool [21]
is part of the open-source software package ACADO Toolkit [22]—a toolkit for
automatic control and dynamic optimization. It implements the real-time iteration
scheme. The user interface allows one to specify nonlinear dynamic model equations
as well as general nonlinear objective and constraint functions. The code-generator
exports a generalized Gauss-Newton method for nonlinear MPC [20], and nonlinear
MHE [23].

The tool exploits problem structure and dimensions together with sparsity patterns
to remove all unnecessary computations and remove the need for dynamic memory
allocation. The tool generates self-contained ANSI-C compliant code, which can
be deployed on any platform supporting the standard C library. Branching in the
exported code is minimized leading to improved code locality, thus faster execution
times.

Recent extensions of the ACADO Code Generation tool include support for
implicit integrators for ODEs and differential algebraic equations (DAEs) [24, 25].
One of the inherent properties of the multiple shooting algorithm is that model
simulation and sensitivity generation can be performed on each shooting interval
independently. In other words, integration can be easily parallelized, by applying the
so called shared memory model. The toolkit can export the code which uses OpenMP
framework for parallelization.

46

3.4 Vehicle Model

M. Zanon et al.

Both NMPC and MHE strongly rely on a mathematical model of the vehicle. Having
a descriptive model is hence fundamental to ensure good control and estimation
performance. In this chapter, a multibody model is proposed in which the chassis is
modeled as a rigid mass connected to the four wheels by suspensions. This model
extends the model previously proposed in [8].

The chassis position and orientation are deﬁned in the X–Y plane of an absolute
reference frame E, while the velocities are given in the local x − y − z frame
e. The heave motion of the chassis is neglected and the four wheels are modeled
as independent bodies with only spinning inertia. Throughout the chapter, when
referring to quantities related to the wheels, subscripts ﬂ, fr, rl, rr denote quantities
corresponding respectively to the front left, front right, rear left and rear right wheel.
For ease of notation, let F := {f, r}, S := {l, r} and W := F × S = {ﬂ, fr, rl, rr}.
The control inputs are the steering rate ˙δ, the accelerating torque T a and the four

braking torques of each wheel T b

≥Φ, ∗ ≥ Φ ∞ W .

3.4.1 Chassis Dynamics

The equations of motion are written with respect to the vehicle’s center of gravity
(CoG). Reference frames E and e are chosen orthonormal, right-handed with the
z-axis pointing up, and the y-axis pointing left. The chassis equations of motion thus
are

+ F x
rr
+ F y
rr
+ F y
rr

+ FD,
,

+ F x
rl
+ F y
rl
) + c(F x
fr

− F x
ﬂ

+ F x
rr

− F x
rl

),

+ F y
fr

m ˙vx = mv y ˙ψ + F x
+ F x
ﬂ
fr
m ˙v y = −mvx ˙ψ + F y
+ F y
ﬂ
fr
I z ¨ψ = a(F y
) − b(F y
rl
ﬂ
I y ¨p = T y
,
s
I x ¨r = T x
,
s
˙X = vx cos ψ − v y sin ψ,
˙Y = vx sin ψ + v y cos ψ,

(3.4a)

(3.4b)

(3.4c)

(3.4d)
(3.4e)

(3.4f)

(3.4g)

where m denotes the mass and I x , I y, I z the moments of inertia of the chassis. The
distances of the tires from the vehicle’s CoG are characterized by a, b and c, cf.
Fig. 3.1. The CoG is assumed to be located halfway between the left and right side
of the car. The vehicle’s yaw angle ψ is obtained by direct integration of ˙ψ as is the
steering angle δ from input ˙δ. The drag force due to air resistance is denoted by FD,
while F x
·· denote the components of the tire contact forces along the vehicle’s
local x and y axis. The suspension torques are deﬁned as T x

·· , F y

s and T y
s .

The considered vehicle has front steering, thus

3 Model Predictive Control of Autonomous Vehicles

47

Fig. 3.1 Tire forces and slip angles of the 4-wheel vehicle model in inertial coordinates. The tires’
directions of movement are indicated by green vectors

fΦ = Fl
F x
fΦ cos δ − F c
rΦ = Fl
F x
rΦ,

fΦ sin δ,

F y
fΦ = Fl
fΦ sin δ − F c
F y
rΦ = F c
rΦ,

fΦ cos δ,

∗ Φ ∞ S ,

∗ Φ ∞ S ,

where Fl

··, F c

·· denote the longitudinal and cornering tire forces respectively.

3.4.2 Tire Contact Forces: Pacejka’s Magic Formula

In this chapter it is proposed to compute the tire forces using Pacejka’s Magic For-
mula: a very accurate semi-empirical nonlinear tire model that is commonly used for
automotive applications. The Magic Formula allows to compute the longitudinal and
cornering forces as a function of the longitudinal slip and slip angle, while taking into
account the effect of combined slip. The self-aligning torque M z
·· has a signiﬁcant
contribution only at low speeds [26] and is assumed to be negligible in this chapter.
Longitudinal and cornering forces are thus computed as

⎨

⎢

≥Φ, F c
Fl
≥Φ

= fP(α≥Φ, κ≥Φ, μ, F z

≥Φ), ∗ ≥ Φ ∞ W ,

where fP(·) denotes Pacejka’s tire model. The inputs to the Magic formula are: (a)
the side slip angle α··, deﬁned, as displayed in Fig. 3.1, as the angle between the
wheel’s orientation and it’s velocity, (b) the longitudinal slip κ··, (c) the tire-road
friction coefﬁcient μ and (d) the vertical load on the wheel F z
·· . The longitudinal slip
is deﬁned as

48

M. Zanon et al.

κ≥Φ =

ω≥Φ Re − v≥Φ
v≥Φ

,

where v≥Φ is deﬁned as the wheel velocity, ω≥Φ as the wheel rotational speed and Re
as the effective tire radius.

More details on the computation of slip angles and Pacejka forces can be found
in [26–28]; the precise model implementation used for this chapter, including all
parameters, can be found in [29].

3.4.3 Wheel Dynamics

The wheels being modeled as separate bodies with only one rotational degree of
freedom, the dynamic equations only depend on the accelerating and breaking torques
T a
·· and T b
··. The rotational accelerations are given
by

·· and on the longitudinal force Fl

˙ω≥Φ = 1

I w (T a

≥Φ + T b

≥Φ − Re Fl

≥Φ), ∗ ≥ Φ ∞ W ,

where individual wheel braking is considered. For the acceleration torque a model
of the differential is considered, which, assuming rear-wheel drive, yields

T a
fΦ = 0, ∗ Φ ∞ S ,
(cid:2)
ωrΦ
ωrl + ωrr

rΦ = T a
T a

1 −

(cid:3)

, ∗ Φ ∞ S .

3.4.4 Vertical Forces and Suspension Model

In this chapter, the suspension of the vehicle is assumed to only act on the roll and
pitch motions of the chassis. The rotation of the chassis is deﬁned as

R = Ry( p)Rx (r ) =

⎡

⎣

cos p
0
− sin p

⎤

⎡

⎦

⎣

1
0
0

sin p
0
cos p

0
1
0

⎤

⎦,

0
0
cos r
cos r
sin r − sin r

where r and p denote the roll and pitch angles respectively.

The forces of the suspension due to the spring elasticity and damping are deﬁned

respectively as

F el
≥Φ = −k≥φ≥Φ,

≥Φ = −D≥ ˙φ≥Φ, ∗ ≥ Φ ∞ W ,
F d

3 Model Predictive Control of Autonomous Vehicles

49

where k· and D· denote the elastic and damping constants of the suspension spring.
The suspension displacement is deﬁned as φ≥Φ = Rζ≥Φ − ζ≥Φ, ∗ ≥ Φ ∞ W , where ζ··
denotes the wheel position in the body reference frame e.

Denoting the rest vertical forces by ¯F z

·· , the vertical forces F z

·· are given by

≥Φ = ¯F z
F z

≥Φ + F el

≥Φ + F d

≥Φ, ∗ ≥ Φ ∞ W .

The torques acting on the chassis are given by

(cid:4)

(cid:4)

T y
s

T x
s

= −2

(kf + kr)c2 sin r + c2(Df + Dr )wx

= −2

(kf a2 + krb2) sin p + (Df a2 + Drb2)wy

.

(cid:5)

,

(cid:5)

3.4.5 Spatial Reformulation of the Dynamics

For a natural formulation of obstacles and general road bounds under varying ve-
hicle speed one can reformulate the model dynamics in the curvilinear coordinate
deﬁned by the track centerline σ(s) = [X σ(s), Y σ(s)]T , where s ∞ [s0, sf ] is a curve
parameterization of constant speed ≤ dσ
≤ := 1. In particular, the global vehicle coor-
⎪
ds
⎪
dinates X, Y , and τ are replaced by offset coordinates ey :=
2
and eψ := ψ − ψσ in distance and orientation from σ, with
(cid:7)

⎪
⎪[X, Y ]T − [X σ, Y σ]T

(cid:6)

ψσ(s) = atan2

dY σ(s)
ds

, d X σ(s)
ds

.

Instead of time t, the independent variable of the dynamic system is taken to be the
parametrization s ∞ [s0, sf ] of the reference curve σ.

The coordinate transformation mapping s: [t0, tf ] ⇐ [s0, sf ] is implicitly deﬁned
by the vehicle’s velocity along σ. From geometric considerations, for the vehicle
velocity in σ-direction vσ = vx cos(eψ) − v y sin(eψ) and its projection onto the
ρσ−ey , where ρσ is the radius of local curvature
reference curve ˙σ, it holds that
of σ at s. From dσ
= ˙s, and therefore the coordinate
ds
transformation is deﬁned by

= 1, it follows ˙σ = dσ
ds

vσ = ρσ

· ds
dt

˙σ

˙s =

ρσ
ρσ − ey

(vx cos(eψ) − v y sin(eψ)).

For sufﬁciently small deviations ey from the centerline (more precisely, ey(s) <
ρσ(s)) the coordinate mapping is monotonous if vσ > 0, i.e. if the vehicle is driving
forward, and the vehicle state ξ is uniquely determined in the spatial coordinate
system for each s ∞ [s0, sf ]. The spatial dynamics of the state vector ξ can be

50

M. Zanon et al.

expressed in relation to the time dependent dynamics through

ξ⇒ := dξ
ds

= dξ
dt

· dt
ds

= ˙ξ · 1
˙s

,

The last equality holds by the inverse function theorem, which can be applied due to
monotonicity of the coordinate mapping s(t).

More details of the spatial coordinate transformation are provided in [5]. Note
˙s along σ, and inertial

that time information may be recovered by integrating dt
ds
coordinates are given by:

= 1

X = X σ − ey sin(ψσ)
Y = Y σ + ey cos(ψσ)
ψ = ψσ + eψ.

3.5 Control of Autonomous Vehicles

In this section, the MHE and NPMPC schemes used for the simulations are presented.
Both schemes are based on a piecewise constant control parametrization and the
system dynamics f(x, u) are discretized over the shooting intervals using an implicit
Runge-Kutta method of order 2 [25].

3.5.1 MHE Formulation

The estimation horizon for MHE has been selected as SE = 10 m, divided into
N = 10 control intervals of uniform duration Sc = SE/N .

The available measurements come from an inertial measurement unit (IMU), a
GPS, force sensors on the suspensions, and encoders on the wheels and the steering
wheel. They are summarized in Table 3.1, together with their standard deviation σ.
The weighting matrix QE was chosen diagonal, with all diagonal elements matching
the square of the inverse of the standard deviation σi they correspond to, i.e. QEi,i =
(σi )−2.

The arrival cost has been computed in a similar way as in [13], where the Kalman
update is computed in an efﬁcient way and it is ensured that the norm of the arrival
cost weighting matrix PE is bounded from above.

3 Model Predictive Control of Autonomous Vehicles

Table 3.1 Available
measurements

Sensor

Measurements

IMU
IMU
GPS
Force sensor
Encoder
Encoder

Linear acceleration
Angular velocity
Position
Vertical forces
Wheel rotational velocity
Steering angle

51

Standard de-
viation σ
10−2 m/s2
0.1 rad/s
10−2 m
5 × 102 N
10−3 rad/s
10−3 rad

3.5.1.1 Friction Coefﬁcient Estimation

In order to accurately estimate the friction coefﬁcient μ, the model needs to account
for sudden changes in the road friction. This can be achieved by making the friction
coefﬁcient time varying, using a ﬁrst order model ˙μ = uμ.

Penalization of the variable uμ is needed in order to ensure that the estimate of μ
is not strongly affected by sensor noise. Penalizing uμ in a quadratic (L 2) norm has
the effect of ﬁltering out noise, but does not allow for fast detection of large jumps
in the friction coefﬁcient. Jumps are better detected when penalizing the absolute
value of uμ (L 1 norm), as large changes are penalized less than with a L 2 penalty. In
this case, though, small variations of μ are ﬁltered out together with the noise. The
Huber penalty combines the beneﬁts of the L 1 and the L 2 penalty. It is deﬁned by

(cid:10)

H (x) =

1
2 x 2
ρ(|x| − 1
2

ρ)

|x| ≤ ρ
|x| ∈ ρ

.

(3.5)

We refer to [30] for an algorithmically differentiable implementation using slack
variables.

3.5.2 MPC Formulation

The control horizon for NMPC has been selected as SC = 20 m, divided into
N = 20 control intervals of uniform duration Sc = SC/N . This longer horizon has
been chosen, to guarantee that the obstacles are seen sufﬁciently in advance to allow
for avoidance maneuvers, including stopping the vehicle in extreme conditions.

The weights Q and R have been chosen as diagonal matrices, with each element
selected in accordance with Table 3.2. The units of measure of the weights are selected
so as to yield a dimensionless cost. The terminal cost matrix PC has been taken as
the solution to the discrete algebraic Riccati equation using the proposed weighting
matrices Q and R.

52

M. Zanon et al.

Table 3.2 Weights for NMPC

State or control
Associated weight

ey, eψ
1

vx , vy, ˙ψ
10

r , p
1

ωx , ωy
1

ω··
1

T a, T b
··
10−4

˙δ
1e2

3.5.2.1 Constraints with Feasibility Guarantee

For the inputs, the following constraints have been selected

0 ≤ T a ≤ T

a,

T b ≤ T b

≥Φ ≤ 0

∗ ≥ Φ ∞ W .

By using the spatial reformulation of the model, the obstacle avoidance constraints

become simple bounds, deﬁned as

ey

≤ ey ≤ ey.

(3.6)

As this obstacle avoidance constraint drives the trajectory away from the reference,
the NMPC scheme avoids the obstacle by steering the vehicle as close to it as possible.
Bounds (3.6) thus become active. For a real system, the state estimate will always
be noisy due to measurement noise or model inaccuracy. Even the smallest violation
of constraint (3.6) might yield an infeasible NLP and make the controller unreliable.
Feasibility of the NLP can be guaranteed by reformulating the obstacle avoidance
constraints (3.6) using non-negative slack variables as

ey ≤ ey + uU
ey
− u L
ey ∈ ey
ey

, uU
ey
, u L
ey

∈ 0,

∈ 0 .

(cid:11)

(cid:12)

=

u L
ey
uU
ey

In the proposed formulation, the slack variables uey

are introduced on each

interval. They can be seen as a measure of the constraint violation corresponding to
each interval.

To penalize the constraint violation, two terms are added to the cost function

JNMPC, which becomes

JNMPC = ≤x(Tc) − xr(Tc)≤2
PC
(t) + ≤uey

+ w1

T uey

⎧

Tc

+

0
(t)≤W2 dt .

≤x(t) − xr(t)≤2

+ ≤u(t) − ur(t)≤2
RC

QC

The proposed penalty on the slack variables implements the sum of an L 1 and
an L 2 norm, using positive (deﬁnite) weights w1 and W2, respectively. This choice
allows to add a stronger penalty for large constraint violations (effect of the L 2 norm)

3 Model Predictive Control of Autonomous Vehicles

53

−4

x 10

−3

x 10

−3

x 10

]

N

[

z·

Δ

5

0
−5

]
s
/
d
a
r
[

·
·

ω

]
d
a
r
[

δ

0

0

0

5

0
−5

1

0
−1

0.2

0

]

m

[

y
e

−0.2

0

0.01

]
d
a
r
[

ψ
e

−0.01

0

−3

x 10

0

2

0

]
s
/
m

[

y
v
,
x
v

50

100

150

200

50

100

150

200

50

100

150

200

50

100

150

200

50

100
X [m]

150

200

−2

0

50

100
X [m]

150

200

Fig. 3.2 Vehicle trajectory for a straight reference (thin line) and obstacles (thick line). The MHE
estimates are shown in circles. The estimated friction coefﬁcient is displayed in the bottom ﬁgure
(thick line), together with the actual friction coefﬁcient (thin line)

while always having a nonzero gradient even when the constraints are not violated
(effect of the L 1 norm).

3.5.3 Simulation Results

An obstacle avoidance simulation has been run to demonstrate the performance of
the proposed control scheme. The NMPC and MHE schemes have been implemented
using the code generation tool of ACADO [20].

As displayed in Fig. 3.2, the vehicle is required to travel at a reference speed
vx = 10 m/s while avoiding two 6 m long obstacles positioned at s = 43 m and
s = 123 m on a 200 m long straight road. The ﬁrst obstacle has to be avoided on the
left and is 2 m wide, while the second one needs to be avoided on the right and is 0.8 m
wide. The road surface has a very low friction coefﬁcient μ = 0.3, corresponding to
a snow-covered or icy road. After 80 m, the friction coefﬁcient increases to μ = 0.5.
The trajectory obtained by applying the proposed control scheme to this scenario
is displayed in Fig. 3.2, top graph, where it can be seen that the controller is able
to avoid the obstacles. In Fig. 3.2, bottom graph, the estimated friction coefﬁcient
is displayed. It can be noted that the Huber penalty (3.5) successfully rejects the
measurement noise, but still allows to detect the jump in the friction coefﬁcient.
The jump is detected in an approximate way immediately after it occurs. After this
detection, MHE slowly corrects the inaccuracy. The MHE estimation error for the
state vector is displayed in Fig. 3.3, where it can be noted that all quantities are well
estimated. The greatest error is relative to ey, as the selected GPS noise is relatively
high.

All simulations have been run on an Intel Xeon CPU E5520 at 2.27 GHz. The

computational times are reported in Table 3.3.

M. Zanon et al.

54

−4

x 10

−3

x 10

−3

x 10

]

N

[

z·

Δ

5

0
−5

]
s
/
d
a
r
[

·
·

ω

]
d
a
r
[

δ

0

0

0

5

0
−5

1

0
−1

0.2

0

]

m

[

y
e

−0.2

0

0.01

]
d
a
r
[

ψ
e

−0.01

0

−3

x 10

0

2

0

]
s
/
m

[

y
v
,
x
v

50

100

150

200

50

100

150

200

50

100

150

200

50

100

150

200

50

100
X [m]

150

200

−2

0

50

100
X [m]

150

200

Fig. 3.3 Left ﬁgure estimation error for the load transfer φz
· , the rotational velocities ω·· and the
steering angle δ. Right ﬁgure estimation error for the distance from the reference ey and eψ, and the
longitudinal and lateral velocities vx and v y

Table 3.3 Computational
times of preparation and
feedback phase

Preparation (ms)

Feedback (ms)

MPC
MHE

15.2
16.6

5.8
5.0

3.5.4 Treating Gear Shifts

An important control in autonomous driving is the gear choice. It implies the in-
troduction of an integer valued control function η(s) ∞ {1, 2, . . . , ngears} and cor-
respodingly a switched dynamic system f (x(s), u(s), η(s)), usually involving gear
speciﬁc transmission ratios or degrees of efﬁciency. From the variety of approaches
that has been proposed to solve ofﬂine control problems with gear choices [31–33]
the one that is best suited in this online setting is described in [34]. It builds on a
partial outer convexiﬁcation of the dynamics [35], i.e., the introduction of convex
multiplier controls ωi (s) ∞ {0, 1},

ωi (s) = 1 and new dynamics

(cid:13)ngears
i=1

˙x(s) =

ωi (s) f (x(s), u(s), i).

ngears(cid:14)

i=1

This reformulation allows to relax integral gear choices to continuous inputs ωi (s) ∞
[0, 1] which can be treated by the presented software framework. Although ωi (s) can
take any value in the interval [0, 1], the optimal relaxed solution is often of bang-bang
type and hence a feasible input. The reason is the outer convexiﬁcation which favors
the most efﬁicent gear with respect to acceleration both in an energy-optimal as in
a time-optimal setting, as explained in [32]. A possible exception are intervals with
a mismatch between the actuator time grid and optimal switching points, where a
rounding approach can be applied. For sufﬁciently fast actuators both ε-optimal [36]
and stable behavior [34] have been shown.

3 Model Predictive Control of Autonomous Vehicles

55

If engine speed constraints need to be incorporated, a more elaborated approach

is necessary, see [37] for a survey of possible problem formulations and methods.

3.6 Conclusions and Outlook

This chapter proposed a framework for combined state and parameter estimation and
control of autonomous vehicles based on NMPC and MHE. The proposed schemes
have been tested in simulations and have shown to effectively control a stiff, highly
nonlinear model with 15 states and 6 controls on a low-friction road in an obstacle-
avoidance scenario.

Recent algorithmic developments made it possible to run those advanced control
and estimation techniques in real-time, with computational times in the order of
20 ms on a standard CPU.

The road-tire friction coefﬁcient has been estimated by penalizing its variation
with a Huber norm and feasibility of path constraints subject to noise has been
guaranteed through a slack reformulation.

Future research will aim at extending the proposed framework to more complex

vehicle models that include gear shifts.
Abstract Optimal control problems naturally arise in several kinds of applications,
including automotive systems. Unfortunately, the solution of such problems—which
hinges upon a partial differential differential equation, the so-called Hamilton-Jacobi-
Bellman (HJB) pde—might be hard or even impossible to determine in practice.
Herein, introducing the notion of Dynamic Value function, we propose a novel tech-
nique that consists in the immersion of the given model into an extended state-space in
which the solution may be deﬁned in a constructive manner. This leads to a dynamic
control law that approximates the optimal policy. The proposed approach is vali-
dated by means of a case study arising from the ﬁeld of combustion engines, namely
optimal control of the torque and the speed of a test bench.

4.1 Introduction

Optimal control consists in steering the state of a dynamical system towards a desired
conﬁguration while simultaneously minimizing a given criterion of optimality [3, 8].
Since the resulting control law allows to stabilize a desired equilibrium of the closed-
loop system—a task of paramount importance per se in the nonlinear context—as
well as to consider optimization objectives, such problems are rather pervasive in
control design applications, obviously including mechanical and automotive sys-
tems among the others [5]. It is well-known that the optimal control action is
typically provided in terms of the solution of a partial differential equation, to so-
called Hamilton-Jacobi-Bellman (HJB) pde [2]. The analytic solution of such a (non-
linear) pde might be difﬁcult or even impossible to determine outside classes of rather
simple academic models. Therefore, several methods have been proposed in the lit-
erature to approximate, at least in a neighborhood of the desired equilibrium, the
optimal policy [1, 6, 9].

The main contribution of the chapter consists in the deﬁnition of the notion of
Dynamic Value function. These functions, similarly to the classical value functions,
are shown to be strongly related to the solution of an auxiliary optimal control prob-
lem, which approximates that of the original problem. Interestingly, the construction
makes use of a dynamic extension to the state of the system, hence yielding a dynamic
control law in place of the classical static optimal feedback.

The rest of the chapter is organized as follows. In Sect. 4.2 some basic deﬁnitions
and results concerning optimal control and its solution are reviewed. The notion of
Dynamic Value function is introduced in Sect. 4.3 together with some motivations for
its deﬁnition. The concept of (matrix) algebraic ¯P solution—which is instrumental
to the construction of a class of canonical Dynamic Value functions without involving
the solution of any pde—is discussed in the same section. Finally, the performances of
the proposed control law are assessed by means of a practically motivated application
within the automotive framework. In particular, we consider the optimal control
problem for the torque and the speed of an internal combustion engine test bench
driven by an electric dynamometer.

4.2 Hamilton-Jacobi-Bellman Equation and Optimal Control

To provide the reader—who might not be familiar with the standard deﬁnitions and
notation of the classical optimal control problem—with a comprehensive framework,
we brieﬂy review the basic ideas and results concerning the aforementioned optimal
control problem. Towards this end, consider a nonlinear dynamical system described
by equations of the form

˙x = f (x) + g(x)u,

(4.1)

with f : Rn ≤ Rn and g: Rn ≤ Rn×m smooth mappings, where x(t) ∈ Rn denotes
the state of the system and u(t) ∈ Rm the input. The inﬁnite horizon optimal control
problem with stability consists in ﬁnding a control action u that minimizes the cost
functional

(q(x(t)) + u(t)≈u(t))dt,

(4.2)

(cid:2) ∞

J (u) = 1
2

0

where q : Rn ≤ R+ is a positive semi-deﬁnite function, subject to the dynamical
constraint (4.1), the initial condition x(0) = x0 and the requirement that the zero
equilibrium of the closed-loop system be locally asymptotically stable. Assuming
that q is at least twice continuously differentiable guarantees the existence of a,

4 Approximate Solution of HJBE and Optimal Control

61

possibly not unique, matrix-valued function Q : Rn ≤ Rn×n, Q(x) = Q(x)≈ ≡ 0
for all x ∈ Rn, such that q(x) = x ≈ Q(x)x for all x ∈ Rn.
Assumption 1 The vector ﬁeld f is such that f (0) = 0, i.e.x = 0 is an equilibrium
point for the system (4.1) when u(t) = 0 for all t ≡ 0.
Assumption 2 The nonlinear system (4.1) with output y = q(x) is zero-state
detectable, i.e. y(t) = 0 and u(t) = 0 for all t ≡ 0 imply that the state x(t)
converges to zero as time tends to inﬁnity.

As a consequence of Assumption 1, there exists a, possibly not unique, continuous
matrix-valued function F : Rn ≤ Rn×n such that f (x) = F(x)x, for all x ∈ Rn. The
classical optimal control design methodology for system (4.1) relies on the solution
of the well-known Hamilton-Jacobi-Bellman (HJB) partial differential equation [2,
3, 8]

∂V
∂x

(x) f (x) − 1
2

∂V
∂x

(x)g(x)g(x)≈ ∂V
∂x

(x)≈ + 1
2

q(x) = 0,

(4.3)

for all x ∈ Rn, together with the boundary condition V (0) = 0. The solution of the
HJB Eq. (4.3), if it exists, is the value function of the optimal control problem, i.e. it
is a function which associates to every point in the state space, x0, the optimal cost of
the trajectory of system (4.1) with x(0) = x0. The knowledge of the value function
on the entire state space permits the construction of the minimizing input, which is
deﬁned in terms of the static state feedback uo = −g(x)≈(∂V (x)/∂x)≈.

Finally, it appears useful at this preliminary stage to recall that in the linearized
setting the solution of the optimal control problem is provided by a linear static state
feedback control law of the form uo = − B≈ ¯P x, where ¯P ∈ Rn×n denotes the
symmetric positive deﬁnite solution of the algebraic Riccati equation ¯P A + A≈ ¯P −
¯P B B≈ ¯P + ¯Q = 0, where the matrices A ∈ Rn×n, B ∈ Rn×m and Q ∈ Rn×n are
deﬁned as

A (cid:2)

(cid:3)
(cid:3)
(cid:3)

∂ f
∂x

= F(0), B (cid:2) g(0), ¯Q (cid:2) 1
2

x=0

(cid:3)
(cid:3)
(cid:3)

∂2q
∂x 2

x=0

= Q(0).

(4.4)

4.3 Dynamic Value Function and Algebraic ¯P Solution

In this chapter we consider a modiﬁed deﬁnition of optimal control problem and
therefore an alternative notion of its solution, as detailed in the following statements.

Problem 1 Consider system (4.1), with Assumptions 1 and 2, together with the
cost functional (4.2). The regional dynamic optimal control problem with stability
consists in determining an integer ˜n ≡ 0, a dynamic control law of the form

˙ξ = α(x, ξ),
u = β(x, ξ),

(4.5)

62

M. Sassano and A. Astolﬁ

with ξ(t) ∈ R ˜n, α : Rn × R ˜n ≤ R ˜n, β : Rn × R ˜n ≤ Rm, α(0, 0) = 0, β(0, 0) = 0,
¯Φ ≥ Rn × R ˜n containing the origin of Rn × R ˜n such
smooth mappings and a set
that the closed-loop system

˙x = f (x) + g(x)β(x, ξ),
˙ξ = α(x, ξ),

has the following properties.

attraction containing ¯Φ.

(i) The zero equilibrium of the system (4.6) is asymptotically stable with region of

(ii) For any ¯u and any initial condition (x0, ξ0) such that the trajectory of the sys-
tem (4.6) remain in ¯Φ the inequality J (β) ∗ J ( ¯u) holds, where β is deﬁned
in (4.5).

Note that Problem 1 may be interpreted as an auxiliary optimal control problem
associated to the extended system (4.1)–(4.5), with state (x, ξ), with respect to the
cost functional (4.2). Herein, we consider an approximate solution to the above
auxiliary optimal control problem.

Problem 2 Consider system (4.1), with Assumptions 1 and 2. The approximate
regional dynamic optimal control problem with stability consists in determining an
¯Φ ≥ Rn × R ˜n
integer ˜n ≡ 0, a dynamic control law described by (4.5), a set
containing the origin of Rn × R ˜n and a function c : Rn × R ˜n ≤ R+ such that the
regional dynamic optimal control problem is solved with respect to the modiﬁed cost
functional

(cid:2) ∞

J (u) = 1
2

0

(q(x(t)) + u(t)≈u(t) + c(x(t), ξ(t)))dt.

(4.6)

⇐

(4.7)

⇐

4.3.1 Deﬁnition of Dynamic Value Function

From the above statements it appears evident that the approximation is twofold.
On one hand, we introduce a dynamic extension ξ, which leads to a dynamic state
feedback in place of the classical static state feedback, while on the other hand we
allow for an additional cost c in (4.7), which imposes a penalty on the state of the
dynamic extension as well as the state of system (4.1). A straightforward consequence
of the latter relaxation is that partial differential inequalities may be solved in place of
equations. Therefore, an alternative notion of value function is deﬁned accordingly.

Deﬁnition 1 Consider system (4.1), with Assumptions 1 and 2, together with the
cost functional (4.2). A Dynamic Value Function V is a pair (Dα, V ) deﬁned as
follows.

4 Approximate Solution of HJBE and Optimal Control

63

i) Dα is the dynamical system

˙ξ = α(x, ξ) ,
u = −g(x)≈ ∂V
∂x

(x, ξ)≈,

(4.8)

∗ 0,

(4.9)

with ξ(t) ∈ Rn, α : Rn × Rn ≤ Rn, α(0, 0) = 0, sufﬁciently smooth mapping
and such that the zero equilibrium of α(0, ξ) is locally asymptotically stable.
ii) V : Φ ⇒ Rn × Rn is positive deﬁnite around the origin of Rn × Rn and such

that

H (x, ξ) (cid:2)

f (x) +

∂V
∂x

∂V
∂ξ

α(x, ξ) + 1
2

q(x) − 1
2

∂V
∂x

g(x)g(x)≈ ∂V
∂x

≈

for all (x, ξ) ∈ Φ.

To put the above deﬁnitions into perspective, in the following lemma we investi-
gate and characterize the relation between a Dynamic Value function and the solution
of the approximate regional dynamic optimal control problem.

Lemma 1 Consider system (4.1), with Assumptions 1 and 2, together with the cost
functional (4.2). Let V = (Dα, V ) be a Dynamic Value function for the system (4.1)
with respect to some non-empty open set Φ containing the origin of Rn × Rn. Then
the dynamical system (4.8) solves the approximate regional dynamic optimal control
problem with stability, namely Problem 2, for all (x, ξ) ∈ ˜Φ, where ˜Φ is the largest
(cid:11)
level set of the function V contained in Φ.

Proof The claim follows straightforwardly by noting that, by (4.9), V is a con-
tinuously differentiable value function for the closed-loop system (4.1)–(4.8), with
respect to the cost functional (4.7). The additional cost c : Rn ×Rn ≤ R+ is deﬁned,
by (4.9), as c(x, ξ) = −2H (x, ξ) ≡ 0 for all (x, ξ) ∈ Φ. Moreover, asymptotic
stability of the zero equilibrium of the closed-loop system (4.1)–(4.8) is proved by
letting V be a candidate Lyapunov function. In fact, the time derivative of the function
V along the trajectories of the system (4.1)–(4.8) yields

d V
dt

∗ − 1
2

q(x) − 1
2

∂V
∂x

(x, ξ)g(x)g(x)≈ ∂V
∂x

(x, ξ)≈ ∗ 0 ,

(4.10)

where the ﬁrst inequality is obtained by (4.9), which shows that all the trajectories
of the closed-loop system (4.1)–(4.8) remain bounded for all t ≡ 0. Moreover, by
LaSalle’s invariance principle the latter trajectories converge to a set, containing the
origin, such that

{(x, ξ) ∈ Rn × Rn : g(x)≈ ∂V
∂x

(x, ξ)≈ = 0} ,

(4.11)

64

M. Sassano and A. Astolﬁ

in which the system (4.1) reduces to ˙x = f (x). It can be shown now that x(t)
asymptotically converges to zero by combining (4.11) with Assumption 2. The proof
is concluded by showing that ξ(t) tends to zero by the stability properties of the
(cid:3)
vector ﬁeld α(0, ξ) and by standard arguments on interconnected systems.

Remark 1 Lemma 1 entails that the knowledge of a dynamic value function provides
a solution, i.e. the control law (4.8), to Problem 2, which is strongly related to the
original optimal control problem. Interestingly, the structure of the control law (4.8)
sheds a different light on the notion of solution of an optimal control problem by
allowing for dynamic state feedbacks which approximate or, in some cases, provide
the optimal solutions.

4.3.2 A Class of Canonical Dynamic Value Functions

While the interpretation of the concept of Dynamic Value function has already been
provided to the reader in the previous section, the motivation of the above discussions
will become clear in the rest of the chapter. This is, in fact, achieved by showing that a
class of canonical Dynamic Value functions may be constructively deﬁned without
relying on the analytic solution of any partial differential equation or inequality.
Towards this end, we now formally introduce the notion of (matrix) algebraic ¯P
solution, which is instrumental for the above construction.

Deﬁnition 2 Consider system (4.1) together with the cost functional (4.2). Let φ :
Rn ≤ Rn×n, φ(x) = φ(x)≈ ≡ 0 for all x ∈ Rn. A continuous matrix-valued
function P : Rn ≤ Rn×n, P(x) = P(x)≈ for all x ∈ Rn, is said to be a matrix
X -algebraic ¯P solution of Eq. (4.3) if

P(x)F(x) + F(x)≈ P(x) + Q(x) − P(x)g(x)g(x)≈ P(x) + φ(x) = 0 ,

(4.12)

for all x ∈ X ⇒ Rn, and P(0) = ¯P. If Eq. (4.12) holds for all x ∈ Rn, i.e. X = Rn,
then P is a matrix algebraic ¯P solution.

Despite the fact that (4.12) follows the spirit of the so-called State Dependent Ric-
cati Equation, see [4] for a complete survey, the use that it is made of the resulting
solution P is signiﬁcantly different from that of the SDRE approach. Nonetheless,
the Eq. (4.12) and its solution enjoy the desirable properties usually associated to
a state dependent solution of the Riccati equation. For instance, the solution P(x)
can be shown to be a positive deﬁnite matrix for all x ∈ Rn provided that the
pairs (F(x), Q(x)1/2) and (F(x), g(x)) are point-wise observable and controllable,
respectively, namely for each ﬁxed value of the state x ∈ Rn. Note that the matrix
Acl (x) = F(x) − g(x)g(x)≈ P(x) denotes the state dependent representation of the
closed-loop system when only the algebraic input u = −g(x)≈ P(x)x is imple-
mented.

4 Approximate Solution of HJBE and Optimal Control

65

Consider a matrix algebraic ¯P solution P introduced in Deﬁnition 2. It appears
evident that the mapping x ∧≤ P(x)x may not be integrable in the standard sense.
In fact, its Jacobian, which is different in general from the matrix P(x), may not
be a symmetric matrix. Therefore, exploiting the degree-of-freedom provided by
the dynamic extension in Deﬁnition 1, we consider herein an alternative notion of
integration of the above mapping, yielding

V (x, ξ) (cid:2) 1
2

x ≈ P(ξ)x + 1
2

(cid:13)x − ξ(cid:13)2
R

,

(4.13)

with R = R≈ > 0 and ξ ∈ Rn. Note that a simple Schur complement argument shows
that the function V in (4.13) is, at least locally, positive deﬁnite around the origin,
for any matrix R > 0. Moreover, the function is indeed globally positive deﬁnite
provided that the matrix P(x) is positive deﬁnite for all x ∈ Rn, as discussed in the
above comment.

The following result characterizes a class of canonical Dynamic Value functions,
whose construction relies on the notion of (matrix) algebraic ¯P solution. To provide
a concise statement, let τ : Rn × Rn ≤ Rn×n denote the jacobian matrix of the
mapping (x, ξ) ∧≤ 1/2P(ξ)x with respect to ξ whereas the matrix-valued function
α : Rn × Rn ≤ Rn×n is such that (x − ξ)≈α(x, ξ)≈ = x ≈ (P(x) − P(ξ)), for all
(x, ξ) ∈ Rn ×Rn. Finally, consider the matrix-valued function β : Rn ×Rn ≤ Rn×n
deﬁned as β(x, ξ) = (R − α(x, ξ))R−1τ(x, ξ).
Theorem 1 Consider system (4.1), with Assumptions 1 and 2, together with the cost
functional (4.2). Let1 P be a matrix algebraic ¯P solution of (4.1). Let the matrix
R = R≈ > 0 be such that

1
2

Acl (x)≈β(x, ξ) + 1
2

β(x, ξ)≈ Acl (x) < φ(x) + 1
2

β(x, ξ)≈g(x)g(x)≈β(x, ξ) ,
(4.14)
for all (x, ξ) ∈ Φ \ {0}, where Φ ⇒ Rn × Rn is a non-empty open set containing
the origin. Then, there exists ¯k ≡ 0 such that V in (4.13) satisﬁes the Hamilton-
Jacobi-Bellman inequality (4.9) for all (x, ξ) ∈ Φ and for all k > ¯k, with ˙ξ =
−k(∂V (x, ξ)/∂ξ)≈. Hence V = (Dα, V ), with Dα deﬁned as

˙ξ = −k (τ(x, ξ)x − R(x − ξ)) ,
u = −g(x)≈ (P(x)x + (R − α(x, ξ))(x − ξ)) ,

(4.15)

and V as in (4.13), is a Dynamic Value function for the system (4.1) and, by Lemma
1, (4.15) solves the approximate regional dynamic optimal control problem for all
(x, ξ) ∈ ¯Φ, where ¯Φ is the largest level set of V contained in Φ.
(cid:11)
Proof A detailed proof of Theorem 1 may be obtained by directly adapting the
(cid:3)
arguments of the proof of Theorem 3 in [7].

1 Without loss of generality we suppose that P is a matrix algebraic ¯P solution. In fact, if the
Eq. (4.12) holds for some X ≥ Rn the statement may be straightforwardly modiﬁed accordingly.

66

M. Sassano and A. Astolﬁ

Remark 2 The control law u in (4.15) is given by the sum of the algebraic input
discussed above and a dynamic compensation term, which deals with the mismatch
between the desired partial derivative P(x) and the actual partial derivative with
(cid:4)
respect to x of the function V in (4.13).
Remark 3 Let R = α(0, 0) = ¯P, then clearly β(0, 0) = 0. Note that the above
choice of the matrix R is such that V is, at least locally, positive deﬁnite. Provided
that φ(0) > 0, since β(0, 0) = 0 and by continuity of the functions in the inequality
(4.14), there exists a non-empty open neighborhood of the origin ˆΦ such that (4.14)
holds for all (x, ξ) ∈ ˆΦ.
(cid:4)

Remark 4 An alternative deﬁnition of the algebraic Eq. (4.12) may be given, which
allows to consider a single scalar algebraic inequality, in n unknowns, in place of the
matrix algebraic Eq. (4.12), in n(n + 1)/2 independent unknowns. More precisely,
we may consider the nonlinear system (4.1) and let σ : Rn ≤ Rn×n, σ(0) > 0,
x ≈σ(x)x ≡ 0 for all x ∈ Rn. Then, a continuously differentiable mapping p :
Rn ≤ Rn×n is said to be an algebraic ¯P solution of Eq. (4.3) if

p(x) f (x) + 1
2

q(x) − 1
2

p(x)g(x)g(x)≈ p(x)≈ + 1
2

x ≈σ(x)x ∗ 0 ,

(4.16)

together with the tangency condition ∂ p(x)/∂x|x=0 = ¯P. The corresponding
Dynamic Value function must be adapted to the alternative deﬁnition, yielding the
function Vs(x, ξ) (cid:2) p(ξ)x + (1/2)(cid:13)x − ξ(cid:13)2

R, and the dynamical system
(cid:3)

(cid:2)

∂ p
∂ξ

˙ξ = −k
u = −g(x)≈ ( p(ξ) + R(x − ξ)) .

(ξ)x − R(x − ξ)

,

(4.17)

Interestingly, the results of Theorem 1 may be equivalently proved by replacing
(cid:4)
(4.13) with Vs and (4.15) with (4.17), respectively.

4.3.3 Minimization of the Extended Cost

Two different—and in some respect alternative—ways to reduce the approximation
error of the dynamic solution (4.15) with respect to the optimal control law are
explored in this section. In particular, these two directions may be explored by con-
sidering the actual value of the cost paid by the optimal solution, on one hand, and
the structure of the cost which is minimized along the trajectories of the system, on
the other hand.

To begin with, note that, by deﬁnition of value function, V (x0, ξ0), where the
function V is deﬁned in (4.13), provides the minimum value of the cost functional
(4.7) evaluated along the trajectories of the closed-loop system (4.1)–(4.15), initial-
ized at (x(0), ξ(0)) = (x0, ξ0). If, on one hand, the initial condition x0 of the original

4 Approximate Solution of HJBE and Optimal Control

67

plant (4.1) is typically given a priori in practical applications, the initial condition ξ0
of the dynamic extension, on the other hand, may be arbitrarily selected. Therefore,
in order to minimize the actual cost paid by the dynamic solution (4.15), for a ﬁxed
initial condition x0 of system (4.1), the initial condition ξ0 should be selected as
ξ∗
0

= arg minξ V (x0, ξ).
The implications of the above considerations deserve particular attention, since
they provide the motivations for the second approach to reduce the approximation
error. As a matter of fact, the deﬁnition of value function entails that all the possible
trajectories for ξ(t), obtained for instance by modifying the gain k, yield the same
minimum value of the cost functional (4.7) provided that they share the same initial
condition ξ∗
0 . Nevertheless, it might be desirable to select one of these trajectories
according to some speciﬁc criterion. In particular, the following result explains how
the additional cost c can be minimized by letting the gain k in (4.15) be a function
of the states, i.e. k(x, ξ). Towards this end, deﬁne, for ε > 0, the open set Mε (cid:2)
{(x, ξ) ∈ Rn × Rn : (cid:13)τ(x, ξ) − R(x − ξ)(cid:13) < ε} and consider the continuous
function

(cid:4)

satδ(x) =

x,
sign(x)δ,

0 ∗ |x| ∗ δ
|x| > δ

(4.18)

with x ∈ R and δ > 0.
Theorem 2 Consider system (4.1), with Assumptions 1 and 2, together with the cost
functional (4.2). Suppose that P is a (matrix) algebraic ¯P solution of the Eq. (4.3)
and let R be such that (4.14) holds in some non-empty open set Φ ⇒ Rn × Rn.
Consider the function V as in (4.13) with ξ obtained as the solution of (4.15) for
some constant ˆk > ¯k. Let ε > 0 and k(x, ξ) in (4.15) be deﬁned as

k(x, ξ) = sat ˆk

(m(x, ξ)) ,

with

m(x, ξ) (cid:2)

(cid:5)−1

(cid:4)

≈

(cid:4)

∂V
∂ξ

∂V
∂ξ

∂V
∂x

f (x) + 1
2

q(x) − 1
2

∂V
∂x

g(x)g(x)≈ ∂V
∂x

Then the Dynamic Value function2 V ε = (Dε
(cid:4)

α, V ε) is such that

cε(x, ξ) = 0
cε(x, ξ) ∗ c(x, ξ) (x, ξ) ∈ Mε.

(x, ξ) ∈ Φ \ Mε,

(4.19)

(cid:5)

≈

.

(4.20)

(4.21)

Proof. The claim is proved in two steps. First it is shown that the function m is
not saturated for all (x, ξ) ∈ Φ \ Mε, then that (4.21) holds. To begin with, rewrite
the function (4.19) as

2 The notation (Dε
α, V ε) and cε(x, ξ) describes the differential Eq. (4.15) and the function V (x, ξ)
in (4.13) with ξ obtained as the solution of (4.15)–(4.19) and the corresponding approximation error
deﬁned as in Lemma 1, respectively.

68

M. Sassano and A. Astolﬁ

(cid:4)

k(x, ξ) =

m(x, ξ),
sat ˆk

(m(x, ξ)) ,

(x, ξ) ∈ Φ \ Mε
(x, ξ) ∈ Mε

(4.22)

and note that the function m is smaller than or equal to ˆk for all (x, ξ) ∈ Φ \ Mε. In
fact in this set V is such that (cid:13)∂V (x, ξ)/∂ξ(cid:13)2 ≡ ε2 and

∂V
∂x

f (x) + 1
2

q(x) −

∂V
∂x

g(x)g(x)≈ ∂V
∂x

− m(x, ξ)

= 0 ,

(4.23)

≈

∂V
∂ξ

∂V
∂ξ

where the equality is obtained by substitution of the function m as in (4.19). Moreover,
by Theorem 1,

∂V
∂x

f (x) + 1
2

q(x) −

∂V
∂x

g(x)g(x)≈ ∂V
∂x

− ˆk

∂V
∂ξ

∂V
∂ξ

≈

∗ 0 ,

(4.24)

for all (x, ξ) ∈ Φ. Therefore, subtracting (4.23) from (4.24) yields, in Φ \ Mε,
−( ˆk − m(x, ξ))(cid:13)∂V (x, ξ)/∂ξ(cid:13)2 ∗ −( ˆk − m(x, ξ))ε2 ∗ 0, hence m(x, ξ) ∗ ˆk
and k(x, ξ) is not saturated outside the set Mε. To show that (4.21) holds note that,
by (4.23), the function V satisﬁes the partial differential inequality (4.9) with the
equality sign for all (x, ξ) ∈ Φ \ Mε, hence cε = 0. Moreover, by the deﬁnition of
k(x, ξ) as in (4.19), k(x, ξ) ∗ ˆk for all (x, ξ) ∈ Mε. Finally, the proof is concluded
α, V ε)
noting that since 0 ∗ cε(x, ξ) ∗ c(x, ξ) for all (x, ξ) ∈ Φ, then V ε = (Dε
(cid:3)
is indeed a Dynamic Value function.
As a ﬁnal remark, it is interesting to point out that the solution resulting from the
choice of k as in (4.19) minimizes the desired cost functional (4.2) for all the values
of (x, ξ) ∈ Rn × Rn such that c(x, ξ) = 0, hence recovering the optimal solution to
the original problem.

4.4 Optimal Control in Internal Combustion Engine Test

Benches

Combustion engines are operated at test benches in the same way as in a passenger car
or a heavy-duty truck, since the former allow to generate the same load a combustion
engine would undergo in normal operations. The crucial advantage in the use of a
test bench resides in the possibility of reproducing desired conditions in terms of
temperature and pressure, and, consequently, of drastically reducing the cost and
time required for development and conﬁguration. In a vehicle the velocity and, by
means of the transmission, the rotational speed ωE result from the engine and the
load torques. For this reason the engine torque TE as well as the engine speed ωE
need to be controlled to operate a combustion engine on a test bench. In industrial
practice a test bench is usually controlled by means of two separate control loops:

4 Approximate Solution of HJBE and Optimal Control

69

the torque is often inﬂuenced by the accelerator pedal position α of the engine under
test, while the speed is controlled by the loading machine.

In the standard setting of a test bench, the combustion engine is connected via a
single shaft to a different main power unit. The latter may either be a purely passive
brake or an electric machine, which offers the possibility of an active operation.
In this situation, the accelerator pedal position α of the combustion engine and the
set value TD, set of the dynamometer torque provide the inputs to the test bench. A
simpliﬁed model of the entire mechanical system can be described by Gruenbacher [5]

c0 + c1ωE + c2ωE

2

TE + τ (ωE , TE , α) ,

(cid:7)

(cid:6)

˙TE = −
γ ˙ϕ = ωE − ωD,

θE ˙ωE = E − cγϕ − d (ωE − ωD) ,
θD ˙ωD = cγϕ + d (ωE − ωD) − TD,

(4.25)

(4.26)

(4.27)
(4.28)

where γϕ is the torsion of the connection shaft while θE and θD denotes the inertias
of the combustion engine and the dynamometer, respectively. The contributions due
to the inertias of the adapter ﬂanges, the damping element, the shaft torque measure-
ment device and the ﬂywheel are already included in these values. The parameter c
characterizes the stiffness of the connection shaft, whereas d describes its damping.
Moreover, ci > 0, i = 1, . . . , 3 are constant parameters and τ : R × R × R ≤ R is
a nonlinear static function.

The employed electric dynamometer is modeled as a second order low-pass ﬁlter,
with dynamics signiﬁcantly faster than those of the other components of the test
bench, hence they can be neglected in the design. Within the range of maximum torque
and maximum rate of change, the torque of the dynamometer can be described by
TD = TD, set . Letting v = τ (ωE , TE , α), the system (4.25)–(4.28) can be rewritten
as

˙x = Ax + f (x) + Bu

(4.29)

with

A =

⎛

⎜
⎜
⎝

(cid:6)

−c0
0
1
θE
0
(cid:6)

0
0
− c
θE
c
θD
c1 x3 + c2 x3

0
1
− d
θE
d
θD
(cid:7)

f (x) =

−

2

x10 0 0

,

⎞

⎛

⎟
⎟
⎠ , B =

⎜
⎜
⎝

1
0
0
0

0
−1
d
θE
− d
θD
(cid:7)≈

⎞

⎟
⎟
⎠

0
0
0
1
θD

(cid:14)

x1 x2 x3 x4

TE γϕ ωE ωD
where x(t) ∈ R4, x =
the system and u(t) ∈ R2, u =
, the input. The actual control input to
apply in order to generate the desired signal v, namely α, is then obtained in practice
by an approximate inversion of the nonlinear function τ .

, denotes the state of

(cid:14)

(cid:15)≈ =
v TD, set

(cid:14)
(cid:15)≈

(cid:15)≈

70

M. Sassano and A. Astolﬁ

(cid:14)

(cid:15)≈ =

Towards the construction of the dynamic control law (4.17), we preliminary
let ei denote the regulation error of the component xi with respect to the corre-
sponding reference value, namely ei = xi − x ∗
i , i = 1, . . . , 4, where x(t) ∈ R4,
(cid:15)≈
(cid:14)
x =
, describes the state of the system. To
motivate the inﬁnite-horizon scenario we suppose that the transient response of
system (4.25)–(4.28) in closed-loop with the dynamic control law to be designed
is signiﬁcantly faster than the occurrence of step-changes in the desired reference
values.

TE γϕ ωE ωD

x1 x2 x3 x4

Then, in the error coordinates, let q(e) = e≈ Qe in the cost functional (4.2),
where the positive deﬁnite matrix Q ∈ R4×4 weights the relative regulation errors.
Without loss of generality, let the algebraic ¯P solution of (4.16) be of the form
p(e) = e≈ ¯P + P(e), where P : R4 ≤ R1×4 contains higher-order polynomials
of the error variable e. The matrix ¯P is the symmetric and positive deﬁnite solution
of the algebraic Riccati equation associated to the error system linearized around
the desired working point and the quadratic cost q(e). The proposed structure of the
algebraic ¯P solution P intuitively suggests that the linear solution e≈ ¯P is modiﬁed,
by the addition of the term P, in order to compensate for the nonlinear terms in
(4.25)–(4.28).

Exploiting the speciﬁc structure of the vector ﬁeld f in system (4.29), we let P be
deﬁned as P = (P1, 0, 0, 0). It is worth noting that this speciﬁc choice is arbitrary
and alternative choices may be explored. Then, the inequality (4.16) is solved with
respect to the unknown P1 obtaining a solution of the form P1(e) = N (e)D(e)−1,
with the function D : R4 ≤ R strictly positive for all the values of interest, namely
around the desired operating range, of the state variable x. Finally the control law
(4.17), with the matrix R selected according to the arguments of Remark 3, is vali-
dated on a high quality test bench simulator developed by the Institute for Design and
Control of Mechatronical Systems, Kepler University, Linz. In addition to the dynam-
ics of the entire mechanical description the simulator also includes a more accurate,
genuinely nonlinear, data-based model of the combustion engine, limitations of the
dynamometer as well as disturbance effects. The combustion engine model takes
for instance the dynamics of the accelerator pedal and combustion oscillations into
account. Measurement noise similar to the one observed on an actual combustion
engine test bench is superimposed to all relevant values.

(cid:5)

Since (4.17) has been designed for a rather simpliﬁed model, the control action
needs to be modiﬁed in order to cope with some of the nonlinearities of the com-
bustion engine. Thus, letting νi , i = 1, 2, denote the i-th component of (4.17) we
deﬁne the actual control inputs implemented on the combustion engine test bench as
νi (e(τ ), ξ(τ ))dτ , for i = 1, 2. Additionally we let the gain k2
ui = νi (e, ξ) + ki
s
δs+1 , with δ (cid:15) 0—of the
be a function of the derivative—which is implemented as
regulation error for the speed of the engine, namely k2( ˙e3). In particular, the gain is
deﬁned such that, when the regulation error of the engine speed changes too fast, the
integral action is negligible compared to the other components of the control signal.
This choice is reasonable, as shown in the simulations, and needed in order to avoid
an excessively aggressive reference proﬁle for the torque of the dynamometer. Large

t
0

4 Approximate Solution of HJBE and Optimal Control

71

10.5

11

11.5

12

12.5

13

13.5

14

14.5

15

)

m
N

(
E
T

)
s
/
d
a
r
(
E
ω

50

10

250

200

150

100

24 0

230

220

210

200

190

10

10.5

11

11.5

12

13

13.5

14

14.5

15

12.5
time(s)

Fig. 4.1 Top graph time histories of the engine torque TE determined by the control law (4.17)
(solid line) and with the control law in [5] (dashed line), together with the desired reference value
(dash-dotted line). Bottom graph time histories of the engine speed ωE determined by the control
law (4.17) (dark line) and with the control law in [5] (grey line)

errors between the desired and the measured engine speed and torque, due to changes
in the references, are mainly, and relatively rapidly, compensated by the action pro-
vided by the dynamic control law (4.17). Note that, locally around the origin, the
linear part of the dynamic control law is dominant with respect to higher-order terms,
hence the integrals provide a standard integral action.

In the simulations the control law (4.17) is compared with the control law devel-
oped in [5], which already shows signiﬁcantly improved performances with respect
to existing standard implementations based on two separate control loops. The top
graph of Fig. 4.1 shows the time histories of the engine torque TE determined by
(4.17) (solid line) and by the control law in [5] (dashed line). The bottom graph of
Fig. 4.1 displays the time histories of the engine speed ωE determined by (4.17) (solid
line) and by the control law in [5] (dashed line). Employing the controller developed
herein leads to a signiﬁcant reduced overshooting of the engine torque TE when a
change of the operation point is required. Although the engine torque TE shows a
slightly increased rise time, the ﬁnal value is reached approximately four times faster.
The coupling effect is also improved by the dynamic control law proposed, as it can
be appreciated from the bottom graph of Fig. 4.1. Note that the speed is corrupted by
additive disturbance caused by the resolution of the shaft encoders and by combustion

72

M. Sassano and A. Astolﬁ

10.5

11

11.5

12

12.5

13

13.5

14

14.5

15

)

%
(
α

60

50

40

30

20

10

250

200

150

100

50

)

m
N

(
D
T

0
10

10.5

11

11.5

12

13

13.5

14

14.5

15

12.5
time(s)

Fig. 4.2 Top graph time histories of the accelerator pedal position α determined by the control law
(4.17) (solid line) and by the control law in [5] (dashed line). Bottom graph time histories of the
torque of the dynamometer TD determined by the control (4.17) (dark line) and by the control law
in [5] (grey line)

oscillations. Differences are also visible in the input signals generated by the control
laws, see Fig. 4.2. In fact at time t = 12s, the control (4.17) avoids an overshoot in
the accelerator pedal position α, which is an advantage from the polluting emissions
point of view, while requiring, on the other side, a more demanding behavior to the
electric dynamometer.

4.5 Conclusions

In this chapter we have approached the optimal control problem for nonlinear sys-
tems, the classical solution of which is provided in terms of the well-known Hamilton-
Jacobi-Bellman partial differential equation. We have introduced and discussed the
notion of Dynamic Value function which permits the construction of a dynamic
control law that approximates the optimal policy. The approximation error may be
minimized by initializing opportunely the internal state of the dynamic control law,
on one hand, and by steering the evolution of the dynamic extension in such a way
that the actual minimized cost resembles the desired cost. Interestingly, a class of
such functions may be constructed without involving the solution of any pde. Finally,
the applicability of the proposed dynamic control law has been tested and validated
on an interesting control problem within the automotive framework.

Abstract A novel system for safe speed recommendation, based on a cooperative
method for vehicular density estimation and on the intelligent determination of the
trafﬁc scenario, is presented.

5.1 Introduction

At present, Intelligent Speed Adaptation (ISA) systems, as a part of Advanced Driver
Assistance Systems (ADASs), have become a fundamental part in the designing of
safe vehicle operation systems, with the aim of improving driver/pedestrian safety
using environmentally friendly applications [1]. Statistically, ISA systems always
represent an improvement in the reduction of CO2 emissions and fuel consumption,
and on saving/prediction of accidents (fatal, serious and slight) [1]. Advisory sys-
tems rely on the calculation of safe recommended parameters to be presented to
the driver using an appropriate display system [2]. Thus, in general, advisory ISA
methodology involves less algorithmic and analytical complexity, and constitutes
the ﬁrst step towards more comprehensive (mandatory) systems, and the enhance-
ment of Adaptive Cruise Control (ACC) algorithms [3]. ISA systems can be greatly
improved by including relevant information from different sources such as envi-
ronmental (weather, visibility, etc) and road (vehicular density, speed limits, etc)
information, thus resulting in more reliable systems [4]. A recent application based
on weather information can be found in [5]. Regarding road information, vehicu-
lar density represents a very important factor in designing systems for safe speed
advising, because from it, it is possible to obtain a more realistic awareness of the
general trafﬁc situation [6]. In this sense, most ADASs involving vehicular den-
sity estimation techniques are based on the use of loop detectors [7, 8]. However,
there are many drawbacks in using this kind of dedicated infrastructure device: (1)
vehicular density is computed only for ﬁxed road sections (between two consecutive
loop stations), i.e. the available information is space-discontinuous; and (2) density
variations cannot be properly detected at each location with a low density of loop
detector stations (but a high density of them is not desirable from the monetary point
of view) [7]. Moreover, if we think in terms of a decentralisd scheme, then vehicular
density should be estimated for each node belonging to the vehicular ad-hoc network
(VANET), making even less feasible the use of loop detectors. Thus, more practical
ways to estimate vehicular (trafﬁc) density are required, such as the one presented
in [6]. With the above in mind, we propose a two-stage methodology for intelligent
speed advising: the ﬁrst stage concerns trafﬁc scenario determination based on a
cooperative methodology using vehicle-to-vehicle (V2V) communication for vehic-
ular density estimation, and a rule-based system (Sect. 5.4), and the second stage
concerns the calculation of safe parameters based on the proposed trafﬁc scenario
determination (Sect. 5.5). Experimental validation is presented in Sect. 5.6, and we
conclude the chapter with Sect. 5.7.

5.2 Intelligent Speed Adaptation System

ISA systems can be classiﬁed as either static or dynamic. A static ISA system is a
system where the recommender is supported only on ﬁxed/localised speed limits,
whereas a dynamic ISA system also uses environmental information to update the
recommended speed. ISA systems can also work in advisory, voluntary or mandatory
modes. In an advisory mode, the function of the ISA is to recommend a speed to the
driver, and in mandatory mode a control action is used to enforce the advised speed.
For dynamic-mandatory cases it has been shown that ISA systems are able to provide
safety beneﬁts in terms of a reduction of up to 44 % in fatality [5]. Recent develop-
ments in ITS infrastructure have made possible the development of more advanced
ISA systems. In this chapter we describe one such a system. Our system allows the
inclusion of relevant available information using current trafﬁc information and road
speed limits for calculating the recommended speed. We propose to use V2V com-
munication as a main tool for vehicular density calculation rather than loop detectors,
with the aim of obtaining space-continuous information through a cheaper approach
(as opposed to using dedicated infrastructure devices). Consequently vehicular den-
sity is used as one of the inputs of a rule-base reasoning engine designed to determine

5 Intelligent Speed Advising Based on Cooperative Trafﬁc Scenario Determination

79

the current trafﬁc scenario; the scenario that will be used to dynamically calculate
the ﬁnal recommended speed. The main advantage of using such an inference engine
is the possibility of including expert knowledge in an easy and intuitive way via
IF-THEN rules. Finally, we assess our speed adaptation scheme using a traditional
safe policy applied to the resulting inter-vehicle distances.

5.3 Procedure

We are proposing a two-stage methodology for intelligent speed advising: (a) the
ﬁrst stage focuses on trafﬁc scenario determination, and (b) the second stage regards
safe parameters calculation. In the ﬁrst stage we consider the problem from a spatial-
temporal perspective. We begin this process by deﬁning a point of reference that
represents a point along the future trajectory of the vehicle for which the recom-
mender is being constructed. Thus, the following concepts arise:
• the Host Vehicle (HV) is the vehicle for which the recommendation is being con-

• the Next Point of Interest (NPI) is a coordinate in the near future of the Host
Vehicle’s evolution, i.e. a point located in the future trajectory of the Host Vehicle.
• the Next Vehicle (NV) is the (potentially virtual) vehicle that is currently closest

structed.

to the NPI.

Once the Next Vehicle has been selected, the calculation of the vehicular density
is obtained as the vehicle density in some prespeciﬁed area around the NPI. Due to
the spatial-temporal nature of the problem, vehicular density is calculated for both
the Host Vehicle and the NPI.

The current trafﬁc scenario is determined by using the calculated vehicular density
and speed for both the Host and Next Vehicles, and the variation of the Host Vehicle
speed as the inputs of an inference engine. Our inference engine is made up by a set
of 28 IF-THEN rules.

For the second stage of the procedure, we propose to calculate the recommended
speed using a weighted formula that combines both the Host and Next Vehicle speeds,
as well as density information.

Finally, once the recommended speed is obtained, we use a widely known policy

for safe recommended distance.

For ease of exposition, we make the following assumptions:

• our road setup is as depicted in Fig. 5.1:

– a ﬁve-section (S1–S5), two-lane (L1–L2), one traveling direction straight road;
– a 2D Cartesian system for spatial representation of the road (top view) where

the x axis is the direction of travel;

– a stationary bottleneck represented by the narrowing of the road (S3), emulating

a closed lane e.g. due to an on-road accident;

80

R. H. Ordóñez-Hurtado et al.

Fig. 5.1 Road setup used

• and

A1 all vehicles belonging to the VANET have a compatible V2V system;
A2 all required information can be acquired using suitable devices/techniques, and

then transmitted using such a V2V system;

A3 processing times for V2V communication and outputs calculation are greatly

shorter than intervals between instants for speed recommendation.

5.4 Methodology: First Stage

In the ﬁrst stage of the proposed ISA methodology, the basic idea is to use V2V com-
munication to obtain an estimation of the vehicular density. With such information,
in addition to speed values and other relevant data, we determine the current trafﬁc
scenario using a rule-based system.

However, as the trafﬁc scenario determination is a spacial-temporal problem,
other sources of information must be considered in addition to the Host Vehicle
information. This demands the selection of a vehicle placed at a point in the ahead
road-section in which the Host Vehicle is traveling on, in order to represent a point
along the future trajectory of the Host Vehicle. Hereafter, such a point is the NPI,
and the vehicle representing the NPI will be referred to as the Next Vehicle (which
is not necessarily the vehicle immediately preceding the Host Vehicle).

5.4.1 Selection of the Next Point of Interest and the Next Vehicle

The NPI is a reference placed at a distance xahead in front of the Host Vehicle.
As we are considering a straight road collinear to the x axis, we deﬁne the NPI at
(x H + xahead , yH ), where (x H , yH ) is the position of the Host Vehicle.

In order to select the Next Vehicle to represent the NPI, we look inside a circle
with radius rN centered at (x H + xahead , yH ) as shown in Fig. 5.2. If no vehicles
are inside the circle (see Fig. 5.2b), then we let the Next Vehicle be a virtual vehicle
located at (x N , yN ) = (x H + xahead , yH ); otherwise the closest vehicle to the NPI
is selected (see Fig. 5.2a).

5 Intelligent Speed Advising Based on Cooperative Trafﬁc Scenario Determination

81

Fig. 5.2 NPI location: a the next vehicle is the nearest vehicle to (x H + xahead , yH ), i.e. the blue
one, and b the next vehicle is a virtual vehicle located at (x H + xahead , yH )

5.4.2 Vehicular Density Estimation

The vehicular density estimation for any sampling node in the VANET can be carried
out based on [7], as follows: (1) the sampling node broadcasts a poll message, (2) all
nodes receiving the poll message respond to the sampling node with a reply message,
and (3) vehicular density δ for the sampling node is given by

δ (t) = nr + 1

,

A

(cid:2)

A =

πr 2
,
D
2r D WL NL ,

if 2r D ≤ WR = WL NL .
otherwise.

,

where nr is the number of returned replies inside the polling area A, WR is the road’s
width, WL is the lane’s width, and NL the total amount of lanes. Note that the factor
+1 is added to the factor nr to include the sampling node into the density equation.
However, if the sampling node is a virtual vehicle, then the vehicular density is not
1
A but rather zero (see Fig. 5.2b).

5.4.3 Trafﬁc Scenario Determination

Once the vehicular density for both Host/Next Vehicles is calculated, we can use
that information in addition to the Host/Next Vehicle speeds in order to determine
the trafﬁc scenario. In this chapter we proposed to use an inference engine for that
purpose, as explained in the following subsections.

5.4.3.1 Inference Engine Design

The inference engine consists of a (user-deﬁned) knowledge base for assigning values
to the outputs according to the values of the inputs. Let us deﬁne the inputs/outputs
variables, to latter deﬁne the base of rules that relates them.

82

Type

Input

Table 5.1 Membership functions

Variable
¯VH,N , ¯δH,V

ΔVH (t)

Output

FT, AC, CT, PB, LC

R. H. Ordóñez-Hurtado et al.

Set

Membership function

L
H
N
Z
P
N
Y

[0 0 0.1 0.8]
[0.1 0.8 1 1]
[−100 − 100 − 7.5 − 2.5]
[−7.507.5]
[2.5 7.5 100 100]
[0 0 1]
[0 0.8 1 1]

Inputs/Outputs Deﬁnition

Five variables are chosen as inputs: the normalised Host Vehicle’s velocity ( ¯VH );
the normalised Next Vehicle’s velocity ( ¯VN ); the normalised vehicular density for
the Host Vehicle ( ¯δH ); the normalised vehicular density for the Next Vehicle ( ¯δN );
and the variation on the Host Vehicle’s velocity ΔVH (t) = VH (t) − VH (t − 1).
In addition, ﬁve variables are chosen as outputs: Free Trafﬁc (FT); Approaching
Congestion (AC); Congested Trafﬁc (CT); Passing Bottleneck (PB); and Leaving
Congestion (LC).

The sets Low (L) and High (H) are for the inputs ¯VH,N and ¯δH,V , the sets Negative
(N), Zero (Z) and Positive (P) are for the input ΔVH (t), and the sets Not (N) and
Yes (Y) are for all the outputs. Membership functions are shown in Table 5.1.

Finally, the trafﬁc scenario is classiﬁed according to the following equation:

T (t) = argmax(FT(t), AC(t), CT(t), PB(t), LC(t)).

Base of Rules

The rules Rk for relating the ﬁve inputs to the ﬁve outputs are of the form

Rk : IF input1 = • AND . . . inputi = •, THEN

out put1 = • AND . . . out put j

(cid:2)

= •) ∗ wk,

according to values in Table 5.2, which are supported by applying both trafﬁc ﬂow
theory [9] and common sense to each particular case, and considering the values
taken for each input.

5.4.3.2 Normalisation of Variables

In order to provide a general interpretation of the rules, we use normalised values
instead of raw ones. Such a normalisation process depends on each kind of input, as
presented in the following subsections.

5 Intelligent Speed Advising Based on Cooperative Trafﬁc Scenario Determination

83

Table 5.2 Base of rules for trafﬁc scenario determination

Rule

(cid:4)

Inputs
(cid:3)
¯VH , ¯δH , ¯VN , ¯δN
[L, L, L, L]

ΔV H

Outputs
[FT, AC, CT, PB, LC]

Weight

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28

[L,L,L,H]
[L, L, H, L]

[L, L, H, H]
[L, H, L, L]

[L, H, L, H]
[L, H, H, L]
[L, H, H, H]
[H, L, L, L]

[H, L, L, H]
[H, L, H, L]

[H, L, H, H]
[H, H, L, L]

[H, H, L, H]
[H, H, H, L]
[H, H, H, H]

N
Z
P
–
N
Z
P
–
N
Z
P
–
–
–
N
Z
P
–
N
Z
P
–
N
Z
P
–
–
–

[Y, N, N, N, N]
[Y, N, N, N, N]
[N, N, N, N, Y]
[N, Y, N, N, N]
[Y, N, N, N, N]
[N, N, N, N, Y]
[N, N, N, N, Y]
[N, Y, N, N, N]
[N, N, Y, N, N]
[N, N, N, Y, N]
[N, N, N, Y, N]
[N, N, Y, N, N]
[N, N, N, Y, N]
[N, N, Y, N, N]
[N, Y, N, N, N]
[Y, N, N, N, N]
[Y, N, N, N, N]
[N, Y, N, N, N]
[Y, N, N, N, N]
[Y, N, N, N, N]
[N, Y, N, N, N]
[N, Y, N, N, N]
[N, N, Y, N, N]
[N, N, Y, N, N]
[N, N, N, Y, N]
[N, N, Y, N, N]
[N, N, N, Y, N]
[N, N, Y, N, N]

0.6
0.6
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.8
0.8
1.0
1.0
1.0
1.0

Velocity Normalisation

This normalisation depends on the raw value of the velocity, the Maximum Individual
Speed (MIS) of the vehicle, and the Road Speed Limit (RSL) of the road section in
which the vehicle is traveling on. The normalised velocity is given by

¯VH,N (t) = min

(cid:3)

(cid:4)
αspeed ∗ ˜VH,N (t) , 1

,

αspeed =

1

(cid:2)

(cid:2)

max
(cid:2)

f1

=

(cid:5) , ˜VH,N (t)

M I SH,N , R L SH,N
VH,N (t) ,
(cid:5)
R L SH,V , M I SH,N , VH,N (t)

if M I SH,N > R L SH,V
otherwise.

,

84

R. H. Ordóñez-Hurtado et al.

Table 5.3 Maximum allowed density ( f2) given r D
r D
11
f2 (r D)
5

9.5
5.5

8.5
6

7.5
7

13
4.5

15
4.2

19.5
3.9

21
3.8

(cid:5)(cid:2)

where f1 provides a value corresponding to the linear interpolation of the VH,N (t)
. Note that min (•, 1) ensures
using a curve given by
that the maximum value of ¯VH,N (t) is 1 even when the velocity overcomes the
corresponding R L S.

0, M I SH,N

0, R L SH,V

(cid:5)(cid:6)

(cid:2)

(cid:5)

,

Vehicular Density Normalisation

This normalisation depends on the raw value of the vehicular density, the polling radio
r D, and the Maximum Allowed Density (MAD) curve (constructed from Table 5.3).
The normalised vehicular density can be calculated as

¯δH,N (t) = min

(cid:2)

(cid:5)
αdensit y ∗ δH,N (t) , 1

,

αdensit y =

1
f2 (r D)

,

where the value of f2 (r D) (representing the MAD given r D) is calculated according
to a linear interpolation using data in Table 5.3 (obtained from simulation tests).
Again, min (•, 1) assures that the maximum value of ¯δH,N (t) is 1 even when the
vehicular density overcomes the corresponding estimated MAD.

5.5 Methodology: Second Stage

Once the trafﬁc scenario is determined, we can use such information to design our
Advisory ISA methodology. However, since the deﬁnition of the recommended speed
VR (and as a consequence, the recommended distance DR) should be based upon
both the determined trafﬁc scenario and the Next Vehicle’s velocity (VN ), then we
ﬁrst introduce a model for updating VN in cases of a virtual Next Vehicle.

5.5.1 Updating Speed in Virtual Next Vehicles

If a virtual Next Vehicle is chosen, then both the location and velocity of the Next
Vehicle have to be calculated from other sources rather than a real vehicle on the
road. Recall that we already assigned the location of such a virtual Next Vehicle
as (x H + xahead , yH ) (see Sect. 5.4.1), but a model for its velocity updating is still
missing. Thus, we propose a way to update VN similar to

5 Intelligent Speed Advising Based on Cooperative Trafﬁc Scenario Determination

85

Table 5.4 Decision matrix for VN , αN V and αR
AC
Trafﬁc scenario

FT

Value of VN
Value of αN V
Value of αR

0.3
1.4
0.7

0.2
0.7
0.7

CT

0.1
0.9
0.7

PB

0.1
0.9
0.45

LC

0.3
1.4
0.7

VN (t) = αN V (t) ∗ VN (t − 1) ,

where αN V (•) is the evolution parameter, but including some particular consider-
ations. Our way for updating the normalised virtual Next Vehicle speed ¯VN is then
given by

(cid:2)

¯VN (t) = min
¯VN (t − 1)
f

(cid:2)

αN V (T (t − 1)) ∗ f
(cid:2)
(cid:5)
= max

¯VN (t − 1) , VN

(cid:2)

(cid:5)

¯VN (t − 1)

(cid:5)
, 1
(T (t − 1))

(cid:5)

,

,

(5.1)

(5.2)

where T (•) is the determined trafﬁc scenario, and VN
(•) is the minimum allowed
normalised speed for a virtual Next Vehicle. The inclusion of this minimum limit
speed, which is greater than zero, is to avoid ¯VN = 0 which represents that the Host
Vehicle is approaching a stopped vehicle, which is not true because there are no real
vehicles around the NPI (see Fig. 5.2). Then, min (•, 1) in (5.1) is to guarantee that
¯VN never exceeds the maximum normalisation value 1, and max
in (5.2)
is to guarantee that the virtual Next Vehicle is always moving at least at VN . Both
αN V and VN are design parameters, and reference values (obtained from simulation
tests) are given in Table 5.4.

•, VN

(•)

(cid:5)

(cid:2)

Justiﬁcation for values in Table 5.4 are as follows:

• Given previous Free-Trafﬁc/Leaving-Congestion scenarios, it is assumed that the
virtual Next Vehicle can accelerate without problems. Thus, αN V = 1.4 represents
an increase of 40 % in VN , and VN

= 0.3 sets a minimum value for ¯VN at 0.3.

• Given previous Congested-Trafﬁc/Passing-Bottleneck scenarios, it is assumed that
the virtual Next Vehicle could not have accelerated, and probably could have had
a small deceleration. Thus, αN V = 0.9 represents a decrease of 10 % in VN , and
VN

= 0.1 sets a minimum value for ¯VN at 0.1.

• Given a current Approaching-Congestion scenario, it is assumed that the virtual
Next Vehicle is indeed decelerating. Thus, αN V = 0.7 represents a decrease of
30 % in that VN , and VN

= 0.2 sets a minimum value for ¯VN at 0.2.

5.5.2 Proposed Recommended Speed Scheme

We propose a calculation method for the recommended cruise speed similar to the
one presented in [5], i.e. a convex linear combination with time-variant coefﬁcients.

86

R. H. Ordóñez-Hurtado et al.

However, here we calculate the recommended speed by combining two terms, the
Host Vehicle speed VH and the Next Vehicle speed VN , as follows

VR (t) = (αR (T (t))) ∗ VN (t) + (1 − αR (T (t))) ∗ VH (t) ,

(5.3)

where αR (•) is a time-variant weighting factor calculated from the decision matrix
presented in Table 5.4. Note that αR is a design parameter, so values in Table 5.4
were tuned from simulation tests. The justiﬁcation for values of αR is as follows:

• Approaching-Congestion/Congested-Trafﬁc scenarios should force the Host Vehi-
cle to slow down in order to travel at most around VN , which in general is a
real vehicle inside a dense platoon immediately ahead of the Host Vehicle. Then,
αR = 0.7 means that the recommended speed depends more upon VN than VH ,
causing VN to act like an upper bound.

• Free-Trafﬁc/Leaving-Congestion scenarios should force the Host Vehicle to speed
up in order to reach VN , which is expected to be traveling in a Free-Trafﬁc scenario.
Then, αR = 0.7 means that the recommended speed depends more upon VN rather
than VH , causing VN to act like a goal speed.

• The Passing-Bottleneck scenario is determined based on the existence of a Next
Vehicle who is leaving the congestion with positive high ΔVN . However, here the
Host Vehicle is about to leave the trafﬁc jam but is still inside it, so the recom-
mended speed should depend more upon VH than VN . Then, αR = 0.45 causes
VH to act like an upper bound.

According to (5.3), it is observed that VR always depends directly on both VH
and VN , so any noisy behaviour in either of them will be directly reﬂected on VR.
Thus, two additional processes have to be added: (1) a quantisation process, to avoid
a noisy recommended speed, and (2) a saturation process, to avoid recommending a
speed greater than the speed limit of the road on which the Host Vehicle is traveling.
With this we ﬁnally obtain VR ∈ min ({5 ∗ n} , R L SH ), with n = 1, 2, ....

5.5.3 Proposed Recommended Distance Scheme

We can assess the performance of our recommended speed scheme by evaluating the
usually adopted safe inter-distance policy [10]

DR (t) = h0 + h1V f (t) + h2

V 2
f

(t) − V 2
l

(t)

,

(cid:3)

(cid:4)

where DR is the recommended (safe) distance, h0 is the minimum safe distance
to the preceding vehicle, h1 is the minimal required headway time (usually set in
hs = 0.6 [s]), h2 is a problem-dependent weighting factor, Vf corresponds to the
speed of the Host Vehicle, and Vl to the speed of the preceding vehicle. However,
here the reference is the Next Vehicle, which does not necessarily coincide with the

5 Intelligent Speed Advising Based on Cooperative Trafﬁc Scenario Determination

87

preceding vehicle. Thus, we have to take

Vl (t) = VN (t) ,

and h0 as the safe distance to the Next Vehicle, redeﬁned as follows

(cid:7)

h0 =

(cid:8)

X N − (X H + Gmin)
L V + Gmin

∗ (L V + Gmin) + Gmin,

where Gmin is the minimum allowed gap (safe distance) between two consecutive
vehicles, and L V is the mean longitude of a vehicle in the network. Note that the
Approaching-Congestion, Congested-Trafﬁc and Passing-Bottleneck scenarios are
of special interest, because only in these cases it is expected that there exists a high
density of vehicles between the Host Vehicle and the Next Vehicle (i.e., a higher
probability of collision).

Now, the recommended distance must be compared to the relative distance Xr el ,
measured as the difference between the Host Vehicle’s position and the Next Vehicle’s
position

Xr el = X N − X H .

Then by deﬁning e = Xr el − DR, the case e ≥ 0 means that there is a safe
situation (the relative distance is greater than or equal to the recommended distance),
and thus the case e < 0 means that there is a non-safe situation.

5.6 Validation

To validate the proposed methodology, we use SUMO to simulate thirty-one vehicles
with properties as in Table 5.5, which travel according to a modiﬁed Krauss car-
following model [11] on the road deﬁned by Fig. 5.1 and Table 5.6. Vehicle 08
exhibits a special behaviour: it stops at Distance = 296 m (road section S4) for
100 s, after which it restarts its travel. The data obtained from SUMO was exported
to the Matlab environment Version 7.12.0.635 (R2011a).

The idea behind using vehicles with very high deceleration abilities is to obtain
data in extreme situations (i.e. the vehicles are very prone to having a collision), in
order to evaluate the performance of the proposed methodology in recommending
a safe speed early. In addition, speed restrictions on S2/S3 and S5 emulate realistic
behaviours around a trafﬁc bottleneck and the variety of piecewise constant speed
limits along a same road, respectively.

88

Attribute

Vehicle’s ID

Table 5.5 Properties of simulated vehicles used in tests

Vehicle type
A

03, 09, 11, 13, 15, 17,

19, 23, 25, 27, 29, 31

04, 05, 07, 10, 12, 14,
18, 20, 24, 26,28.

01, 02, 06, 08, 16,
21, 22, 30

R. H. Ordóñez-Hurtado et al.

Length [m]
Max Speed [m/s]
Acceleration [m/s2]
Deceleration [m/s2]
Minimum Gap [m]
Sigma

4.4
40
3
10
2.5
0.5

B

4.0
30
2
10
2.5
0.5

S1
S2
S3
S4
S5

175
5
30
235
55

C

4.2
16.677
1
10
2.5
0.5

27.778
0.7
2.5
27.778
2.5

Table 5.6 Properties of road
sections in Fig. 5.1

Section

Length (m)

Max speed (m/s)

Fig. 5.3 Entire trafﬁc scenario determination for vehicle 20 using LOM

5.6.1 Trafﬁc Scenario Determination

The inference engine was implemented using the FL Toolbox for use with Matlab
[12], and tested using rN = 4 m, r D = 14 m, xahead = 32 m, WL = 3.5 m and
NL = 2. The obtained results for vehicle number 20 are presented in Fig. 5.3 using
the LOM (Last Of Maximum) method to calculate the outputs. With this method, all
the estimations have a certainty value of 1.0 (i.e. complete certainty).

The trafﬁc scenario determination for the entire set of vehicles is shown in
Fig. 5.4a, b. From Fig. 5.4a, it can be concluded that almost all trafﬁc scenarios

5 Intelligent Speed Advising Based on Cooperative Trafﬁc Scenario Determination

89

Fig. 5.4 Entire trafﬁc scenario estimation for all vehicles using LOM. a Vehicle versus distance.
b Vehicle versus velocity versus time

Fig. 5.5 Entire VR proﬁle for vehicle 20 using the proposed methodology

immediately below a cut at Distance = 190 m (the medium point of the bottleneck)
are determined as a Passing-Bottleneck scenario (magenta), and that some vehicles
detect the new speed limit around Distance = 463 m as a Congested-Trafﬁc sce-
nario (red) for a few seconds, just after the new speed limit’s commencement at
Distance = 445 m.

For its part, Fig. 5.4b shows that most of the velocities beneath a cut at V elocit y =
10 [km/h] are successfully classiﬁed as either Passing-Bottleneck or Congested-
Trafﬁc scenarios. Moreover, increasing velocities are suitably classiﬁed as either
Free-Trafﬁc scenario (green) or Leaving-Congestion scenario (cyan), generally after
Passing-Bottleneck or Congested-Trafﬁc scenarios, as conﬁrmed in Fig. 5.4a. Finally,
decreasing velocities in Fig. 5.4b are successfully classiﬁed as an Approaching-
Congestion scenario (yellow) when a Passing-Bottleneck or Congested-Trafﬁc sce-
nario is about to occur (also conﬁrmed in Fig. 5.4a).

90

R. H. Ordóñez-Hurtado et al.

Fig. 5.6 Analysis of VR for all vehicles in function of time. [Black sections: beyond road’s length].
a HV-speed/traﬁc-scenario porﬁles. b Prevalence of the VR over VH porﬁle: Bule means VR > VH

Fig. 5.7 Analysis of VR for all vehicles in function of distance. Prevalence of the VR proﬁle over
the VH proﬁle: blue means VR > VH

5.6.2 Recommended Speed

Results for the particular case of Vehicle 20 (Fig. 5.5) show that the critical
Approaching-Congestion scenario is tackled properly by detecting the sudden (and
maintained) decreasing of VN at times 78 s and 177 s and then imposing an antici-
pated low VR. With this, the Host Vehicle can be warned of the oncoming trafﬁc jam
early, and thus gains several seconds to perform a smoother braking action.

Another sudden decrease in VN occurs at 165 s, and a low speed is recommended
for a single instant. Such a decrease is not caused by any congestion, but by a stopped
vehicle (Vehicle 08) in the middle of a Free-Trafﬁc scenario. Then, the VR proﬁle
is momentarily affected, indicating the existence of an isolated stopped vehicle (the
estimated scenario remains as a Free-Trafﬁc scenario during, and for some instants
after, such a detection).

The performance of all vehicles can easily be analysed from Figs. 5.6 and 5.7 with
a quick visual inspection, due to the colour-convention used: blue sections indicate

5 Intelligent Speed Advising Based on Cooperative Trafﬁc Scenario Determination

91

Fig. 5.8 3D analysis of e = Xr el − Dr for all vehicles. Colored sections correspond to e < 0
(according the previous color convention). a Xr et , Dr obtained from V f = VH . b Xr et , Dr obtained
from V f in function of VR

that VR ≥ VH . Note that the section for VR < VH corresponding to the lower arrow
in Fig. 5.7 exhibits a pattern that in general coincides with Approaching-Congestion
scenarios, which can be explained as the approaching of the oncoming Congested-
Trafﬁc/Passing-Bottleneck scenarios with a suitable safe (low) speed. Two other cases
in which VR < VH also happen can be better understood from Fig. 5.7: the middle
arrow indicates the detection of an isolated vehicle which is stopped in the middle
of the road (Vehicle 08); and the upper arrow represents the case in which a segment
of the road with a lower speed limit will be promptly reached.

5.6.3 Recommended Distance

Our DR scheme was tested with data from both:(1) the original set-up (without taking
into account VR), and (2) the improved set-up (manual and isolated adjustment of
the speed according to our VR scheme) with h2 = 0.01, L V = 4.2, and Gmin [m] =
2.5 [m].

In Fig. 5.8a (original setup) we can see that many of the e < 0 cases are produced
in Approaching-Congestion scenarios. This is particularly interesting because, there,
VH is much faster than VN , producing large negative values for e (Fig. 5.8a), thus
resulting in a high probability of collision. In Fig. 5.8b (improved setup) we can see
that most of those dangerous situations are suitably tackled, and just a few of minor
e < 0 still remain.

Recall that in Cooperative ACC schemes the control law depends on the value of
e [10]: the smaller e value, the weaker action control (breaking effort) in tracking the
safety parameters. Thus, according to Fig. 5.8b, our recommended speed/distance
schemes provide high performance in terms of travelling in safe conditions.

5.7 Conclusions and Future Work

A new scheme for safe speed advising based on a cooperative and decentralised
methodology for trafﬁc scenario determination was proposed. Its performance was
assessed using safe policies and supported by experimental tests via SUMO package.

92

R. H. Ordóñez-Hurtado et al.

Currently, efforts are focused on evaluating the proposed ISA system beyond the
used setup, i.e. using other realistic situations such as roads with curves and mobile
bottlenecks.

An immediate future task is to use the proposed methodology to design a
Cooperative ACC system by closing the speed/distance loops using the here proposed
VR and DR schemes and a suitable controller. For such a mandatory ISA we have
to be able to develop the corresponding analysis to guarantee string stability. In
addition, other kinds of information can be used to improve the performance of the
advisory system, such as meteorological (weather) and environmental (pollution)
information.
Abstract The problem of driver control and trajectory optimization for the lane
change maneuver is approached through the application of the same design and
simulation tools used in the development of modern automobiles. The vehicle model
and driver control algorithms are combined with a genetic algorithm for trajectory
optimization to determine an optimal path for achieving an objective measure of
maximum speed. Results are compared with subjective results from a professional
driver using a new driver-in-the-loop system. The conclusion is integrated objective-
subjective simulation methods can be used earlier in the design to improve vehicle
handling performance.

6.1 Background

The process of engineering complex systems including automobiles has undergone a
dramatic change in the last two decades. A major reason for this fundamental change
is the development of computer based tools for design drafting, digital mock-up, and
simulation. Model-based engineering (MBE) elevates computer based models in the
engineering process to a central and governing role in the speciﬁcation, design, inte-
gration, validation, and operation of a system [4]. All major automotive companies
have adopted MBE techniques to various degrees.

A Virtual Prototype is a computer simulation of a physical product that can be
presented, analyzed, and tested from concerned product life-cycle aspects such as
design/engineering [14].

Complete virtual prototyping environments which compare the simulated perfor-
mance of an automobile against a set of objective metrics are now available and
have become standard practice for handling performance, ride performance, and
even durability [11, 12]. However, the subjective experience the individual feels
while driving the vehicle is as important as the performance metrics printed in a
magazine, and so a broader approach than virtual prototyping with objective mea-
sures is required. So far these subjective experiences have not been encapsulated in
objective metrics.

6.1.1 Experiential Engineering

The ﬁeld of Experiential Engineering attempts to re-create the human environment
for driving the vehicle so that decisions requiring human perception (from emotions
or other difﬁcult to measure inputs) can be made about the design of the vehicle.
To be successful, this environment must be utilized during the product development
process, in parallel with the vehicle’s technical development [8].

Our approach is to combine objective and subjective measurement into an in-
tegrated environment of engineering tools and processes, thereby accelerating the
vehicle development process. We refer to the objective tests as conducted via “of-
ﬂine simulation” and subjective tests as conducted via “online simulation”, which
puts the vehicle operator “in-the-loop” of control.

6.1.2 Lane Change Problem

Determination of an optimal control strategy to conduct the ISO lane change ma-
neuver or obstacle avoidance maneuver has been studied for some time [3, 7, 9]. An
optimal preview control method is applied to the automobile path following prob-
lem in [9]. The method was applied to the closed loop simulation of an automobile
driver/vehicle system during a lane-change maneuver. The computer simulation re-
sults are compared with equivalent vehicle test measurements. In [7], the authors
consider open-loop and closed loop lane-change maneuvers and design time op-
timal steering controllers with nonlinear constraints. First, they generate a special
open loop lane-change steering signal which minimizes the period of lane-change
subject to constraints on the lateral acceleration and jerk magnitude. Then, they dis-
cuss how to implement those steering commands in the closed-loop system using a
lane-following controller.

Most recently, the problem was approached with a reduced vehicle dynamics
model and driver control model that is solved repeatedly on a moving prediction
horizon to yield near optimal setpoint trajectories for the full model [3]. A NLP
approach is used to solve the problem of ﬁnding the path and driver control for
the autonomous guidance problem. We take a similar approach here with a reduced
vehicle dynamics model that is solved repeatedly, however, the trajectory control
approach we take is more general and the application is toward the automobile
handling design problem. Also, we are looking for a solution to the design problem
that leads to a vehicle that gives a good “subjective” feeling of control.

6 Driver Control and Trajectory Optimization Applied to Lane Change Maneuver

95

6.2 Model Based Engineering Environment for Objective

Evaluation

ADAMS/Car is an industry standard virtual prototyping solution for the design of
handling, ride, and durability characteristics of an automobile. The software efﬁ-
ciently organizes and solves a complete set of differential and algebraic equations in
the time domain [1].

VI-CarRealTime is an ADAMS/Car derivative model, speciﬁcally developed to al-
low the application of reduced order ADAMS/Car models to realtime problems such
as racing trackside simulation, fast optimization and design of experiments studies,
and hardware and driver in the loop simulation. The VI-CarRealTime model is a 14
DOF model representing 6 DOF’s for the vehicle and 2 DOF’s for each wheel. A
VI-CarRealTime model can be automatically extracted from an ADAMS/Car model
and automatically compared with the ADAMS/Car results for a series of standard
events [2].

6.2.1 Determination of Driver Controls

VI-Driver is a virtual prototype of a human driver that is designed to drive a simulated
vehicle model in a very simple and efﬁcient way [5, 10]. The driver model has been
developed with the idea that the “driver” must be:
• robust enough to adapt to a wide range of vehicle characteristics
• simple to tune, and self-adapting whenever possible
• capable of driving on both limit and sub-limit maneuvers.

VI-Driver separates the lateral and longitudinal control problem into uncoupled
controllers, as shown in Fig. 6.1. Each control loop has a predictive (feed-forward)
and compensatory (feedback) control system. In the most general case, the lateral
controller takes a trajectory to follow as input, and a speed proﬁle to match with the
longitudinal controller.

The target trajectory curve for lateral tracking is determined through the following

process. Refer to the trajectory model shown in Fig. 6.2.

Given a target curve γ which represents the trajectory that must be followed, we

deﬁne a connecting contour γ

c (in red) with the following constraints:

1. initial position (compatible with the vehicle position)
2. initial orientation (compatible with vehicle speed, vehicle side slip angle β)
3. ﬁnal position (the reference trajectory evaluated at the preview distance D)
4. ﬁnal orientation (smoothly joining the reference trajectory evaluated at the pre-

view distance D).

To ﬁt these constraints, a cubic polynomial is used, and the coefﬁcients are calculated
with the following relations:

96

P. J. McNally

Fig. 6.1 VI-Driver lateral and longitudinal controllers

Fig. 6.2 Connecting contour for determining reference direction

(cid:2)

(cid:2)

γ
c(0, t)
∂ γ
(0, t)
c
∂x
γ(D, t)
∂ γ
∂x

(D, t)

(cid:2)

(cid:3)

0
β

(cid:2)

(cid:3)

(cid:3)

=

=

(cid:3)

L 0
L 2 − L 1

(6.1)

Using the differential ﬂatness property, the connecting contour is used as the
control input trajectory. The same property allows inverting that trajectory and cal-
culating the appropriate steering control action. The preview distance parameter, D,
can be adjusted to shape the input reference.

For directional control, the simplest vehicle model that captures the dynamical
effects of interest is the classical bicycle treated as a nonholonomic model, as shown
in Fig. 6.3.

VI-Driver’s lateral controller uses the bicycle model as the basis for implementing
a model predictive control technique [10]. Given the vehicle speed V, the side slip

6 Driver Control and Trajectory Optimization Applied to Lane Change Maneuver

97

Fig. 6.3 Classical bicycle
model used as reference for
lateral controller

angle β, the preview time (t p), and the preview distance D (computed as V · t p),
the principle provides a very good approximation of the steering angle necessary to
bring back the vehicle on the target path.

A ﬁnal stage has been implemented, which compensates for the unmodeled lateral
dynamics. This yaw rate controller uses the reference path curvature and the actual
vehicle yaw rate to correct the steering action to bring the vehicle instantaneous
curvature as close as possible to the reference path curvature.

Because of unmodelled dynamics, disturbances and numerical integration noise,
the simulated vehicle almost always diverges from the global optimal trajectory
target. Nevertheless, the simplicity and the natural robustness of the lateral controller
provides correct steering action, and it has been observed to behave very realistically,
even in cases where the target trajectory cannot be followed due to excess‘ive side
slip. More advanced MPC methods which include slip prediction have also been
implemented for other work but at the sacriﬁce of computation speed [5].

6.2.2 Optimization Problem

The automotive manufacturer wishes to ﬁnd the vehicle suspension and chassis de-
sign which executes the lane change maneuver in minimum time.

Formally, the design optimization problem is stated as:

Find u∗, p which causes
˙x(t) = a(x(t), u(t), p)
T o f ollow an admissible tra jector y x∗ that minimi zes the per f or mance measur e
min(J ) = t f + w · v

Where u(t) is our (admissible) driver control, p is a vector of suspension and
chassis design parameters and the cost function is a weighted combination of ﬁnal
maneuver time t f and vehicle speed v, a constant for our maneuver.

Towards this goal, we have constructed computational methods to solve the fol-
lowing two problems: (1) given a vehicle speed, ﬁnd a feasible trajectory through
the set of cones so that no cones are hit, and (2) ﬁnd the minimum time to execute
the lane change maneuver over all feasible trajectories through the set of cones.

98

P. J. McNally

Fig. 6.4 Spline control points applied to ISO lane change trajectory

Fig. 6.5 Process ﬂow for path and speed optimization

Problem 1 is setup with a population of trajectories, parameterized by a set of
trajectory spline points, as shown in Fig. 6.4. A simulation is run for each candidate
trajectory. Problem 2 is initiated by increasing the starting speed for the maneuver.
The two problems are solved automatically as one iteration. The number of
total iterations is set by the user. Ultimate convergence to the ﬁnal combination of
maximum speed, minimum time, and correct trajectory is determined by reviewing
successive run results.

The overall process of simulated vehicle control, trajectory optimization, and
vehicle speed maximization is shown in Fig. 6.5. VI-Driver is used to control the
path of the vehicle through the cones at a constant speed.

The Press Maneuvers Optimizer block uses a genetic algorithm to generate a set
of target trajectories, parameterized by the spline points. For each iteration, a cone
interference check is made to verify if the target trajectory is feasible. If a simulation
results in a cone hit, all trajectories with the same spline segment are pruned out
and the dynamic simulation is not run. All trajectories that result in a successful
simulation without a cone hit are used as a starting set for the next generation.

6 Driver Control and Trajectory Optimization Applied to Lane Change Maneuver

99

Fig. 6.6 Convergence of optimal solution for compact car lateral displacement, ISOLC

The start (constant) speed is increased and a new cycle begins. Depending on the
user speciﬁed number of reﬁnements, additional generations are run for the trajectory
creation process. The event is completed when at least one combination of trajectory
and maximum speed is identiﬁed which runs completely without a cone hit situation.
The optimal is a weighted combination of highest speed and minimum time [15].

6.2.3 Ofﬂine Optimization Results

Simulations were run for three vehicle types to check the robustness of the algorithm;
a high performance sports car, a sport-utility vehicle, and a compact car. Also, two
cone layouts were examined; the ISO lane change layout and the Consumer Reports
lane change layout. The Consumer Reports layout is similar to Fig. 6.4 but with only
one pair of cones for the middle section.

The vehicle lateral displacement from the initial lane and the handwheel angle
(steer demand) are used to illustrate convergence and for later comparison with a
real driver. From Figs. 6.6, 6.7, 6.8, 6.9, it can be concluded that the optimization
converges to a steady state lateral displacement and steering proﬁle in six genera-
tions of the trajectory optimization for the ISO lane change maneuver and within 3
generations for the Consumer Reports lane change maneuver.

Table 6.1 shows the convergence of the optimizer for lap time and speed for each
iteration of the ISO lane change maneuver. Note the unexpected change in maximum
lateral acceleration from iteration 2 to 3.

A vehicle’s characteristics, such as track width, wheel base, roll center height, and
other design parameters will have an effect on optimal lane change performance. The
results of the off-line optimization have been used to improve vehicle handling in
the lane change maneuver through design parameter changes [15].

100

P. J. McNally

Fig. 6.7 Convergence of optimal solution for compact, steer demand, ISOLC

Fig. 6.8 Convergence of optimal solution for compact, steer demand, CR LC

6.3 Virtual Prototyping Environment for Subjective Evaluation

The previous sections have illustrated a method for evaluating the handling charac-
teristics of a new vehicle to execute the lane change maneuver. The ofﬂine method
of evaluating a vehicle is an objective measure of performance, but as discussed
previously, vehicles are also evaluated for their subjective performance through a
customer test. New technology for the subjective evaluation of a vehicle for handling
characteristics during the early design stage was recently introduced [6]. This section
describes this new technology for subjective evaluation of the handling characteris-
tics of a vehicle.

6 Driver Control and Trajectory Optimization Applied to Lane Change Maneuver

101

Fig. 6.9 Convergence of optimal solution for compact car yaw rate, CR LC

Table 6.1 Optimizer convergence results, ISLOC

Iteration

Lap time, seconds
Lateral accel. Max, G
Speed, avg, km/h

1

7.14
0.761
86.3

2

6.78
0.786
90.8

3

6.03
0.752
102.1

4

5.87
0.79
105.0

5

5.82
0.793
105.8

6

5.78
0.802
106.5

VI-DriveSim Dynamic is a high-ﬁdelity, ‘hardware and driver-in-the loop’, full-
motion vehicle simulator developed for the simulation of vehicle handling response.
The simulator is the result of a collaborative effort between Multimatic, VI-grade,
Concurrent, SimCoVR, and Ansible Motion [6]. Two complete systems have been
built to date. Additionally, a complete new driving simulator design that also simu-
lates vehicle ride quality in addition to handling quality has now been developed [13]
VI-DriveSim Dynamic is an integration of real-time vehicle dynamics simulation
software, a six-degree-of-freedom (6DOF) motion platform, high-deﬁnition graph-
ics, state-of-the-art motion cueing and a highly conﬁgurable driver interface. (see
Figs. 6.10 and 6.11).

VI-CarRealTime provides real-time, high-ﬁdelity, fully dynamic vehicle motion
simulation. VI-DriveSim is used to integrate the analysis engine with an immersive
graphics and high resolution visualization program. The motion platform utilizes an
innovative compact mechanism to provide decoupled lateral, longitudinal, and yaw
motion with large displacement capacity. The pitch, roll, and heave axes are less
important for handling dynamics and are coupled.

The resultant lateral, longitudinal, and yaw motions provide the driver’s vestibular
system with appropriate onset ‘cues’. The result is a superior response compared to
a hexapod. The visual cues are projected onto a 160◦, 1.5 m high, 4 m diameter
cylindrical screen, which moves in X –Y , while the projectors move in X –Y and
yaw, allowing for a large ﬁeld of vision and a highly immersive viewing experience.

102

P. J. McNally

Fig. 6.10 Driving simulator functional block diagram

To achieve the most realistic simulation, particular attention was also given to the
steering feedback.

Multimatic Technical Centre and their development driver have run hundreds of
real and virtual laps of the company’s lidar scanned and meshed test track, Calabo-
gie Motorsports Park, Ontario, with the company’s fully characterized parameter
or P-Car. The traces in the plot (Fig. 6.12) show excellent correlation, but more
importantly, their driver has repeatedly been able to demonstrate that even minor
mechanical and aerodynamic changes made on the P-Car can be discerned on the
simulator, and vice versa.

6.3.1 Driver Maneuvers in a Controlled Experiment

Prior to the ofﬂine optimization study, an experiment was conducted using a pro-
fessional driver-engineer from the manufacturer of the same compact car used in
the optimization study. This driver has a great deal of driving experience with the
compact car as well as other vehicles on a physical test course.

The ﬁrst step of the experiment was to familiarize the driver with the motion
simulator environment and the vehicle model. The driver used a simulated skid pad
to conduct two types of maneuvers to familiarize himself with the vehicle: constant
radius cornering and the lane change maneuver. The driver results are for a double
lane change maneuver with a slightly longer layout than the Consumer Reports cone

6 Driver Control and Trajectory Optimization Applied to Lane Change Maneuver

103

Fig. 6.11 The simulator’s highly immersive visual experience

Fig. 6.12 Correlation between the P-Car (blue) and the simulation (red). The plots show speed (top),
steering angle (middle), and lateral acceleration (bottom) for one lap at Calabogie Motorsports Park

spacing. This layout was more familiar to the driver but resulted in scaling differences
between the results that are discussed later.

As part of the experiment, changes to the vehicle setup were made to determine
if the driver had sensitivity to the change in the vehicle performance. The following
changes were made, each acknowledged by the driver:
• Gross vehicle weight change (Added 800 lbm)
• Roll Stiffness Distribution Change by adding 250 N-m/deg rear roll stiffness.
• Reducing the rear lateral force compliance steer by 0.04 deg
• Faster Steering from 16.3 to 15.0
• Rear Toe to Zero (From .38 deg in).

The focus of this chapter is comparing the driver results on the simulator with the
optimization results, and not on the assessment of the driving simulator as a subjective
vehicle design tool. However, the ultimate intent is to use the driving simulator as a

104

P. J. McNally

Fig. 6.13 Repeated ground track, professional driver, lane change

supplement to physical proving ground testing using a simulated vehicle model that
is closer to the ﬁnal design than a physical prototype.

6.4 Driving Simulator Results (Online)

Figure 6.13 shows ground track results that are obtained from the driving simulator
as raw data. The vertical axis is lateral displacement and the horizontal axis is lon-
gitudinal displacement, both in meters. Because the driver has the ability to reset the
simulation at any time, he can decide to continue the event until the end or start over,
speeding up the learning process.

Figure 6.14 compares the results of the online simulation and ofﬂine simulation.
In addition to slight layout differences, the professional driver modulated the throt-
tle during the maneuver whereas the simulation was found to hold velocity better,
resulting in differences in scaling of the yaw rates. For now, we are considering the
general shape of the response to determine if the professional driver learns a similar
optimal path and control as the genetic and driver control algorithm.

Figure 6.15 compares the steering angle results of the online simulation, and
ofﬂine simulation. Again, differences between the ofﬂine and online experiment
account for differences in scaling of the yaw rates between the two simulations. For
now, we are considering the general shape of the steer angle response to determine
differences in learning between the professional driver and the genetic algorithm.

6.4.1 Imposing Constraints on Simulated Driver Controls

In an attempt to better match the actual driver performance, two adjustments were
made to the driver controls. The ﬁrst adjustment was to increase the preview distance.
The preview distance increases the distance to ﬁt a connecting contour, which was
expected to give a smoother control. As shown in Fig. 6.16, this adjustment results
in lower and smoother yaw rates at a penalty of a longer transit time.

The second adjustment was to increase the driver anticipation effect, used to
compensate for slower vehicle response due to inertia and compliance. An increase
in anticipation effect moves the starting reference point of the connecting contour by

6 Driver Control and Trajectory Optimization Applied to Lane Change Maneuver

105

Fig. 6.14 Comparison of yaw rate, online and ofﬂine simulation

Fig. 6.15 Comparison of steering angle, online and ofﬂine simulation

an amount (AC · velocity). The results of this change are shown in Fig. 6.17. This
adjustment shows promise as it results in faster maneuver times and in lower driver
control requirements.

6.5 Conclusions

This paper has compared an objective method of using simulation-based optimization
to determine the “best” automobile design for the lane change maneuver with a
subjective method which utilizes a driving simulator.

The objective method is based on running a series of simulations with a vehicle
model and determining both the driver steering control and a set of trajectory points

106

P. J. McNally

Fig. 6.16 Effect of preview distance changes

Fig. 6.17 Effect of anticipatory compensation changes

to determine the minimum time maneuver. The subjective method uses the same
vehicle model running in a driver-in-the-loop simulation to allow an expert driver to
give an assessment of the vehicle.

The results of the two methods were compared, primarily with the intention of
improving the objective methods but also to illustrate a new vehicle design process
that utilizes both objective and subjective metrics early in the design process, before
the creation of physical prototypes. Work is in progress for a systematic comparison
using a thoroughly validated vehicle model on the same lane change course for both
ofﬂine and online simulations. Also, a mathematical formalism is under development
for comparing objective and subjective results.

6 Driver Control and Trajectory Optimization Applied to Lane Change Maneuver

107

Abstract Optimal control theory Patrick J. can be used to generate aggressive ma-
neuvers for vehicles under a variety of conditions using minimal assumptions. Al-
though optimal control provides a very powerful framework for generating aggressive
maneuvers utilizing fully nonlinear vehicle and tire models, its use in practice is hin-
dered by the lack of guarantees of convergence, and by the typically long time to
generate a solution, which makes this approach unsuitable for real-time implemen-
tation unless the problem obeys certain convexity and/or linearity properties. In this
chapter, we investigate the use of statistical interpolation (e.g., kriging) in order to
synthesize on-the-ﬂy near-optimal feedback control laws from pre-computed opti-
mal solutions. We apply this methodology to the challenging scenario of generating
a minimum-time yaw rotation maneuver of a speeding vehicle in order to change its
posture prior to a collision with another vehicle, in an effort to remedy the effects
of a head-on collision. It is shown that this approach offers a potentially appealing
option for real-time, near-optimal, robust trajectory generation.

7.1 Introduction

An enormous amount of work has been devoted during the past three decades to the
development of active safety systems for passenger automobiles. This effort has led
to the development of a plethora of active safety systems, such as ABS, TCS, ESP,
RCS, AFS and others [2, 11, 34, 39], many of which are now standard equipment in
production vehicles. The main goal of all these systems is to help the driver avoid,
or prevent, the so-called “abnormal” driving scenarios (skidding, sliding, excessive
under/oversteer, etc). In these conditions, nonlinear effects dominate the vehicle
dynamics, and the tire friction is very close to (or exceeds) the adhesion limit(s).
Driving at the boundary of the adhesion limits of the tires leads to a reduced oper-
ational stability margin for the driver. The main goal of most current active safety
systems is therefore to restrict the operational envelope of the vehicle and the tires
inside a linear, well-deﬁned, stable regime. This is, however, an overly conservative
approach. Enhanced stability comes at the cost of decreased maneuverability. There
are many realistic scenarios where the occurrence (or the post-effects) of a collision
can be alleviated by allowing (or even inducing) the vehicle to operate in its nonlinear
regime in a controlled manner.

The previous observations naturally lead one to investigate algorithms that exploit
the increased vehicle maneuverability brought about by operating the vehicle in
nonlinear and/or unstable regimes. By extending the region of validity of the future
generation of active safety systems one expects to increase their performance. In
our previous work [6, 7, 35–38] we have investigated the mathematical modeling of
vehicles operating in nonlinear and/or unstable regimes, and have demonstrated the
potential beneﬁts of such an approach to achieve collision avoidance and mitigation
beyond what is possible with current active safety systems.

This point of view represents a philosophical departure from current practice, and
differs signiﬁcantly in scope from standard active safety system design for passenger
vehicles. As a result—and understandably so—it brings along with it a slew of
unanswered questions; among them, the key question is how to generate the necessary
control actions (at the short time scales required) that are needed to perform such
extreme maneuvers. Indeed, most drivers—except perhaps expert professional, stunt
and race drivers—would have great difﬁculty initiating an aggressive maneuver and
controlling the vehicle throughout the whole maneuver duration.

Optimal control is a powerful framework that has been used successfully in many
engineering applications to generate feasible trajectories subject to constraints and
complicated system dynamics. The ﬁeld of numerical optimal control has experi-
enced enormous advances during the recent years, to the point that we now have
reliable numerical algorithms to generate optimal trajectories for a variety of prac-
tical engineering problems [4]. Despite these advances, the current state-of-the-art
in numerical optimal control mainly focuses on generating only open-loop optimal
controllers. Furthermore, and unless the underline problem (dynamics, cost) obeys
certain convexity and/or linearity conditions, current trajectory optimizers do not
allow the computation of optimal trajectories in real-time, at least for applications
similar to the one we have in mind in this chapter, where the time allotted to solve the
problem is in the order of a few milliseconds. One example where fast computation
has become possible owing to the current advancement of embedded computing is
the area of Model Predictive Control (MPC), where successive linearizations of the
plant are used to generate a sequence of linear or convex optimization problems over
a ﬁnite horizon that can be solved very efﬁciently on-line [10]. In general, how-
ever, optimal solutions for general nonlinear systems and general cost functions are

7 Real-Time Near-Optimal Feedback Control

111

notoriously sensitive to the provided initial guesses and, in the absence of timely
re-planning, the robustness of these open-loop optimal control laws is questionable.
Consequently, several researchers have recently turned their attention to the gener-
ation of near-optimal trajectories using alternative methods, which bypass the exact
on-line computations required for the solution of complicated, nonlinear optimal con-
trol problems, opting instead for approximate, near-optimal solutions. One typical
approach uses interpolation over pre-computed optimal control actions for a variety
of initial conditions. Naïve interpolation, however, does not ensure feasibility—let
alone optimality—of the resulting interpolated trajectories. In [1], for instance, the
authors used traditional interpolation over pre-computed optimal trajectories. How-
ever, this method turns out to be inaccurate and time-consuming. Another, more
promising, approach is the one proposed in [14], where the optimal control prob-
lem is cast as one of metamodeling, in which the (unknown) map between control
inputs/system response pairs is generated implicitly via a series of computer ex-
periments. Speciﬁcally, the approach in [14] considers the solution to an optimal
control problem obtained by numerical methods as the output of such a metamodel
obtained by a series of off-line simulations. A vast number of publications about
metamodeling of computer experiments can be found in the literature. Most of them
are motivated by the low time-consuming optimization process, derived from having
a metamodel of a given simulation.

In contrast to [1], the framework in [14] is based on rigorous interpolation between
the off-line solutions (the “metamodel”) using ideas from statistical interpolation the-
ory via Gaussian processes, which in geostatistics it is also known as kriging [8, 16,
22, 33]. Kriging approximates a function observed at a set of discrete points with
a convex combination of the observations so as to reduce the least mean-squared
error (MSE), and is a special case of prediction using Gaussian processes [16, 22].
Although classical interpolation focuses on low-order polynomial regression, which
is suitable for sensitivity analysis, kriging is an interpolation technique that provides
better global predictions than classical methods [20, 33]. In this work, we use kriging
to construct a (near-)optimal feedback controller from off-line computed extremal
trajectories. Prior use of kriging has been focused mainly on simulation and meta-
modeling [18, 30, 32]. A brief overview of interpolation using Gaussian processes
and kriging is given in Sect. 7.3.

We apply a technique similar to the one proposed in [14] to obtain near-optimal
“feedback” controllers for the problem of minimum-time aggressive yaw maneuver
generation for a high-speed vehicle impeding a collision with another vehicle at an
intersection (T-Bone collision). Our results show that kriging interpolation is able to
generate very accurate parameterized trajectories in real-time, and hence it may be a
potential option for real-time, near-optimal trajectory generation under such extreme
driving conditions, where the time constraints do not allow the computation of an
exact optimal trajectory in a timely manner using current state of technology.

Prior similar work that uses parameterized trajectory generation includes [9],
which developed an algorithm to generate a whole set of trajectories between two pre-
computed solutions for two different initial conditions, and [31], where parameter-
ized trajectories were generated using experimental demonstrations of the maneuver.

112

P. Tsiotras and R. S. Diaz

However, the control laws obtained in [9, 31] are open-loop and thus susceptible to
uncertainties in the initial conditions and unknown model parameters. The advantage
of the method described in this chapter is that the control is obtained as a function
of the actual state, hence is a “feedback” control.

The chapter is structured as follows. In the next section the problem to be in-
vestigated is introduced, along with the dynamical model of the vehicle and the tire
friction dynamics. Next, the optimal control problem is formulated, which is solved
over a discrete grid of initial conditions. This series of generated solutions at several
discrete points is stored in memory, and is used in Sect. 7.4 to generate a feedback
control by interpolating between the stored solutions on-line using kriging. For the
beneﬁt of the uninformed reader, a brief summary of kriging theory as used in this
chapter is given in Sect. 7.3. In Sect. 7.4.2 we present numerical results from the
application of the proposed approach to the problem of T-Bone collision mitigation at
an intersection between two speeding vehicles, as a demonstration of the possibilities
enabled by the proposed approach for optimal on-line controller generation.

7.2 Aggressive Yaw Maneuver of a Speeding Vehicle

7.2.1 Problem Statement

One of the most lethal collisions between two speeding vehicles is the so-called “T-
bone” collision (Fig. 7.1), which occurs when one of the vehicles drives into the side
of the other vehicle [29]. The vehicle suffering the frontal impact is often referred to
as the “bullet” vehicle, while the one suffering the side impact is said to have been
“T-boned.” If there is inadequate side impact protection, the occupants of a T-boned
vehicle risk serious injury or even death.

Although the bullet vehicle is driving much faster, this collision scenario is spe-
cially dangerous for the driver or the side passenger of the target vehicle. This is
owing to the fact that the requirements in terms of frontal crashworthiness of cars on
the market nowadays is excellent [12]. Frontal-crash tests are carried out at veloci-
ties up to 64 km/h, with the result of the passengers cabin being almost intact. The
suitable design and choice of materials of the front part of the vehicle allows large
structural deformations and thus absorption of the residual energy during impact.
Moreover, the installation of frontal airbags, mandatory in the US since Septem-
ber 1998, has resulted in a great decrease of deaths and injuries owing to frontal
collisions. On the other hand, the side part of the chassis is structurally weak, and
large deformations would result in lethal injuries for the occupants. Unfortunately,
side airbags are currently available only in upscale or mid-range cars, although it is
envisioned that they will also become standard safety equipment for all passenger
vehicles in the future. Reference [13] offers a detailed study on occupant injuries
during side impact crashes. As expected, the most frequent source of severe injuries
is the contact between the chest and the door panel.

7 Real-Time Near-Optimal Feedback Control

113

Fig. 7.1 T-Bone collision

Car manufactures are aware of the high risk involved in side collisions. Volvo, for
instance, in 1991 introduced a special protection system against side collision named
Side Impact Protection System (SIPS). Other car manufacturers have introduced
similar passive safety systems.

In our previous work [6, 7] we investigated the possibility of mitigating the results
from an unavoidable T-Bone collision by using an aggressive yaw maneuver for the
incoming bullet vehicle. The proposed collision mitigation maneuver involves a
rapid yaw rotation of the bullet vehicle at an approximately 90 deg angle that brings
the longitudinal axes of the two vehicles into a nearly parallel alignment, in order
to distribute the residual kinetic energy of the collision over a larger surface area,
thus mitigating its effects. Although this represents a worst-case scenario, where
the target vehicle does not respond (a more optimal strategy would involve a rapid
yaw maneuver of the target vehicle as well), our initial study focuses only on the
case when the bullet vehicle is actively maneuvered during the pre-collision phase.
The generalization to the case when both vehicles collaboratively try to avoid the
collision will probably involve some vehicle-to-vehicle (V2V) communication and
it is left for future investigation. Henceforth, we thus only consider the problem
when only one (the bullet) vehicle is actively controlled. This problem was posed
in [6, 7] as a time-optimal control problem, and it was solved using pseudospectral
methods [25]. In the next two sections we brieﬂy summarize the problem deﬁnition
and its numerical solution.

7.2.2 Vehicle and Tire Model

The model used in this chapter is the so-called “bicycle model” [26], augmented
with wheel dynamics. The nomenclature and conventions regarding this model are
shown in Fig. 7.2. The state is given by x = [u, v, r, ψ, ω f , ωr ]T, where u and v are,
respectively, the body-ﬁxed longitudinal and lateral velocities, r is the vehicle yaw
rate, ψ is the vehicle heading, and ω f ≥ 0 and ωr ≥ 0 are the angular speeds of the

114

P. Tsiotras and R. S. Diaz

Fig. 7.2 Schematic of bicycle model

front and rear wheels, respectively. The system is controlled by u = [δ, Tb, Thb]T,
where δ is the steering angle and Tb, Thb denote the torques generated by the footbrake
and handbrake, respectively.

The equations of motion of the vehicle can be written as shown in (7.1)–(7.4)

(Fx f cos δ − Fy f sin δ + Fxr ) + vr,

(Fx f sin δ + Fy f cos δ + Fyr ) − ur,
(cid:3)
(cid:2)

Φ f (Fx f sin δ + Fy f cos δ) − Φr Fyr

,

˙u = 1
m
˙v = 1
m
˙r = 1
Iz
˙ψ = r,

along with the wheel dynamics

˙ω f = 1
Iw
˙ωr = 1
Iw

(Tb f − Fx f R),

(Tbr − Fxr R),

where m, Iz are, respectively, the mass and yaw moment of inertia of the vehicle,
Iw is the rotational inertia of each wheel about its axis, R is the effective tire radius,
and Φ f , Φr are, respectively, the distances of the front and rear axles from the vehicle
center of mass. In (7.1)–(7.6) Fi j (i = x, y; j = f, r ) denote the longitudinal and
lateral force components developed by the tires, deﬁned in a tire-ﬁxed reference
frame.

(7.1)

(7.2)

(7.3)

(7.4)

(7.5)

(7.6)

7 Real-Time Near-Optimal Feedback Control

115

ax = ˙u − vr

Fzf

Fzr

C.G.

r

f

Fxf = Fxf cos δ − Fyf sin δ

Fxr

W = mg

(Forces not drawn to scale)

Fig. 7.3 Longitudinal load transfer force distribution

These forces depend on the normal loads on the front and rear axles, Fz f and Fzr ,

given by

Fz f =

Fzr =

mgΦr − hmgμxr
Φ f + Φr + h(μx f cos δ − μy f sin δ − μxr )
mgΦ f + hmg(μx f cos δ − μy f sin δ)
Φ f + Φr + h(μx f cos δ − μy f sin δ − μxr )

,

(7.7)

(7.8)

where h is the distance of the vehicle center of mass from the ground (see Fig. 7.3),
and where

μ j = D sin(C arctan(Bs j )), μi j = −(si j /s j )μ j ,

i = x, y; j = f, r,

(7.9)

for some constants C, B and D. Expression (7.9) is a simpliﬁed version of the
well-known Pacejka “Magic Formula” (MF) [24] for the tire friction modeling, and
combines the longitudinal and lateral motion, thus intrinsically incorporating the
non-linear effect of the lateral/longitudinal coupling also known as the “friction
=
circle” (see Fig. 7.4), according to which, the constraint F 2
x, j
(μ j Fz, j )2 ( j = f, r ) couples the allowable values of longitudinal and lateral tire
friction forces.

+ F 2
y, j

≤ F 2

max, j

Incorporating the friction circle constraint is necessary for the correct modeling of
the dynamics occurring during the aggressive maneuvers we consider in this work.

In Eq. (7.9) si j denote the tire longitudinal and lateral slip ratios, given by

sx j =

Vx j − ω j R
ω j R

=

Vx j
ω j R

− 1,

sy j = (1 + sx j )

j = f, r,

(7.10)

,

Vy j
Vx j

where the longitudinal and lateral velocity components, deﬁned in the tire-ﬁxed
reference frame, are given by

116

Fig. 7.4 The friction circle
concept (from [19])

P. Tsiotras and R. S. Diaz

Vx f = u cos δ + v sin δ + r Φ f sin δ, Vy f = −u sin δ + v cos δ + r Φ f cos δ, (7.11)
(7.12)

Vyr = v − r Φr ,

Vxr = u,

and s denotes the total slip, computed as s j = (s2
x j
tire forces in (7.1)–(7.6) are computed by Fi j = Fz j μi j , (i = x, y; j = f, r ).

) 1
2 , ( j = f, r ). Finally, the

+ s2
y j

Following current vehicle technology, it is assumed that handbrake torque is only
applied on the rear axle and the footbrake torque is distributed to both axles by a
factor γb, according to Tb f /Tbr = (1 − γb)/γb, so that Tb f = −(1 − γb)Tb and
Tbr = −γbTb − Thb. It is further assumed that the controls are bounded in magnitude
between upper and lower bounds as follows

δmin ≤ δ ≤ δmax, 0 ≤ Tb ≤ Tb,max, 0 ≤ Thb ≤ Thb,max,

(7.13)

which deﬁne the allowable control constraint set, u ∈ U ⊂ R3. For more details on
the vehicle and tire model used in this work, the reader is referred to [7, 35, 38].

7.2.3 Optimal Control Formulation

Assuming that the vehicle is initially moving on a straight line along the positive x
direction with velocity V0 = u(0), our main goal is to ﬁnd the control input history
u(t) to bring the posture of the vehicle to ψ(t f ) = 90◦ as fast as possible. Without
loss of generality, it will be assumed that the angular velocity of the front and rear
wheels is such that a no-slip condition is satisﬁed, i.e., ω f (0) = ωr (0) = V0/R.

We therefore wish to solve the following optimal control problem

7 Real-Time Near-Optimal Feedback Control

117

Vehicle Ground Trajectory

25

20

15

10

5

0

−5

)

m

(
 
n
o
i
t
i
s
o
P
X

 

0

5

10

30

35

40

15
20
25
Y Position (m)

Fig. 7.5 Pre-computed solutions for different initial vehicle velocities (dry asphalt case, corre-
sponding to μ = 0.8)

⎧

t f

min
u∈U
s.t.

J =

dt,

0
˙x = f (x, u),

x(0) = [V0, 0, 0, 0, V0/R, V0/R]T,
ψ(t f ) = π/2,

(7.14)

(7.15)

(7.16)
(7.17)

where f (x, u) is given by the right-hand side of (7.1)–(7.6) and, besides ψ, the rest
of ﬁnal states are free.

This problem can be solved using a variety of numerical methods [3–5, 17, 23,
27, 28]. In this work, we have used the package GPOPS based on pseudospectral
methods to solve the previous optimal control problem [25]. The problem was solved
for a variety of initial conditions. A typical maneuver obtained by the solution of the
optimal control problem is shown in Fig. 7.5. For more details, the interested reader
is referred to [7]. Table 7.1 summarizes the vehicle model data and tire parameters
used in the numerical examples of Sect. 7.4.2.

In the sequel, we focus on generating optimal solutions for different values of
initial conditions by interpolating between the pre-computed optimal trajectories.
The interpolation method we use is based on representing the input (initial conditions)
and output [control commands obtained from the numerical solution of the optimal
control problem (7.14)–(7.17)] as a realization of a (hidden) Gaussian process. The
goal is then to ﬁnd the unknown parameters of this Gaussian process in order to
predict the optimal control inputs for different problem parameters. Although we
only present the results for different initial conditions, the approach can be easily

P. Tsiotras and R. S. Diaz

Variable

118

m
Iz
Iw
Φ f
Φr
h
R

Table 7.1 Vehicle and tire data used in the numerical simulations

Value

1,245
1,200
1.8
1.1
1.3
0.58
0.29

Unit

Kg
Kg m2
Kg m2
m
m
m
m

Variable

B
C
δmax = −δmin
Tb,max
Thb,max
γb
g

Value

7
1.4
45
3,000
1,000
0.4
9.81

Unit

–
–
deg
Nm
Nm
–
m/s2

generalized to the case of different vehicle or road parameters, as long as we have
enough data points within the range of the parameters of interest.

7.3 Statistical Interpolation Using Gaussian Processes

7.3.1 Basic Theory

The basic idea behind statistical interpolation is that the actual values for all possible
observations are a realization from an underlying stochastic process [16]. It is es-
sentially an interpolation technique over random data ﬁelds and it provides accurate
interpolation even if there is no a priori trend. Kriging is a common term referred to
the case when the underlying statistical process is Gaussian. The basic idea that dif-
ferentiates kriging from the traditional Generalized Least Squares (GLS) approach
is the assumption that, given a point where a prediction is to be made, points closer
to this new point should have a larger weight, i.e., they should have more inﬂuence
on the prediction than points that are further away. This implies that the interpolation
weights are not constant, but rather they must be speciﬁcally computed at each new
location.

A kriging interpolation model has the following features:

(a) It is unbiased, i.e., the expected value of the error is zero.
(b) It is optimal, in the sense that minimizes the variance of the error.
(c) It provides exact interpolation, i.e., the predicted output values at the already

observed points are equal to the observations.

(d) It is computationally very efﬁcient, hence on-line implementation is feasible.

Below we brieﬂy summarize the basic ingredients of the approach. The discussion
in this section is taken mainly from [15]. In order to understand how statistical
prediction works, let us consider a set of given locations X = [x1 . . . xN ] ∈ Rn×N
with xi ∈ Rn, where an unknown function y : Rn → R is observed. A simple
regression model is to assume that

7 Real-Time Near-Optimal Feedback Control

y(x) =

βk fk(x) + z = f (x)Tβ + z,

r⎪

k=1

f (x) = [ f1(x) . . . fr (x)]T, where β =
for some basis functions (regressors)
[β1 . . . βr ]T ∈ Rr is the vector of regression coefﬁcients, and z ∈ R is the ob-
servation error. Let now y = [y(x1) . . . y(xN )]T = [y1 . . . yN ]T ∈ RN be the vector
of observations. The generalized regression model given the data (y, x1, . . . , xN )
follows easily from (7.18)

y = F(X)β + z,

(7.19)

where z = [z1 . . . z N ]T ∈ RN is the vector of observation errors, and F(X) ∈ RN ×r
is the matrix of regressors, given by

F(X) = [ f (x1)T . . . f (xN )T]T =

⎨

⎢
⎢
⎢
⎡

f2(x1) . . . fr (x1)
f2(x2) . . . fr (x2)
...
. . .

f1(x1)
f1(x2)
...
f1(xN ) f2(xN ) . . . fr (xN )

...

⎣

⎤
⎤
⎤
⎦

.

In statistical prediction the errors z in (7.19) are modeled as a stationary covariance

stochastic process1 having the properties

119

(7.18)

(7.20)

(7.21)

(7.22)

E[z] = 0,

cov[z] = E[zzT] = C = σ2R,

where C, R ∈ RN ×N are the covariance and correlation matrices, respectively, de-
ﬁned by

E[zi z j ] = Ci j = σ2Ri j (xi , x j ),

i, j = 1, ..., N .

(7.23)

where Ri j (xi , x j ) are stationary correlation functions to be deﬁned later.

Suppose now that we want to predict the value y(x0) at the new location x0 ∈
co(x1, x2, . . . , xN ), where co(·) denotes convex hull. From (7.18), the predicted value
of y(x0) is then given by

y(x0) = f (x0)Tβ + z0,

(7.24)

where the scalar z0 represents the prediction error. Here is where kriging and GLS
differ. The later assumes that both the sample disturbances in (7.18) and the predictor
disturbance in (7.24) are independent, that is, cov[z, z0] = 0. However, in view of
the interdependence of disturbances in the samples (C has non-zero off-diagonal
elements), it seems more reasonable to assume that [15]

E[z0] = 0,

(7.25)

1 A stationary covariance process has constant mean and variance and the covariance matrix depends
only on the distance between the corresponding inputs.

120

P. Tsiotras and R. S. Diaz

cov[z0] = E[z2
0

] = σ2,

cov[z, z0] = σ2r (x0),

(7.26)

(7.27)

where r (x0) ∈ RN is the vector of correlations between z and z0.

Assuming now that the optimal linear predictor of (7.24) can be written in terms

of the observed values, one obtains

ˆy(x0) =

wi yi = wTy,

(7.28)

N⎪

i=1

where w = [w1 . . . wN ]T ∈ RN is the column vector of weights. The residual error
of the approximation is given by

ε(x0) = ˆy(x0) − y(x0) =

wi yi − y(x0).

(7.29)

N⎪

i=1

In order to determine the optimal weights w kriging imposes the conditions [15, 20]

min
w

var[ε(x0)]

s.t. E[ε(x0)] = 0,

(7.30)

to obtain the Best Linear Unbiased Predictor (BLUP). In some texts [20, 21] the
criterion involves the minimization of the mean square error instead. It turns out that
both criteria are equivalent if the estimator is unbiased.

The minimization problem in (7.30) can be re-written as a quadratic programming

(QP) problem in the form

var[ε(x0)] = min
w

min
w
subject to F(X)Tw − f (x0) = 0,

σ2(1 + wTRw − 2wTr (x0)),

whose solution is readily obtained as follows

w∗ = R−1(r (x0) − F(X)λ∗),
(cid:2)
F(X)TR−1 F(X)
λ∗ =

(cid:3)−1

(cid:2)

F(X)TR−1r (x0) − f (x0)

(cid:3)

.

Using the previous expressions, one may ﬁnally express the best linear unbiased
predictor of (7.28) as

ˆy(x0) = R−1

(cid:10)
r (x0) − F(X)

(cid:2)

F(X)TR−1 F(X)

F(X)TR−1r (x0) − f (x0))

(cid:3)−1

(cid:2)

A deeper insight in the predictor can be obtained by expressing (7.34) as

(7.31)

(7.32)

(7.33)

(cid:11)

y.
(7.34)

7 Real-Time Near-Optimal Feedback Control

ˆy(x0) = f (x0)Tβ∗ + r (x0)γ∗,

121

(7.35)

where

β∗ = (F(X)TR−1 F(X))−1 F(X)TR−1y,

γ∗ = R−1(y − F(X)β∗).

(7.36)

The term β∗ is the GLS solution to the regression problem y ≈ F(X)β, also known
as Aitken’s GLS estimator [15]. From (7.35) it can be seen that, if independence of the
disturbances is considered,that is, r (x0) = 0, then the solution becomes equivalent
to GLS. Another important point is that β∗ and γ∗ are ﬁxed for a given set of design
data x1, x2, . . . , xN and y. Thus the computational effort required to calculate the
value of the interpolated function at one point involves only the computation of two
vectors (by evaluating the regression basis functions and the correlation function)
and two simple products.

As mentioned previously, (7.35) is an exact interpolator, in the sense that it returns
the observed value at the design points. This can be easily shown from (7.35) by
choosing x0 = xi . Then r (xi ) is just the ith column of the correlation matrix R.
Hence R−1r (xi ) = ei where ei is the ith column of the identity matrix. It follows
that

ˆy(xi ) = f (xi )Tβ∗ + r (xi )R−1

y − F(X)β∗

(cid:2)

(cid:3)

= f (xi )Tβ∗ + ei (y − F(X)β∗)
= f (xi )Tβ∗ + yi − f (xi )Tβ∗ = yi .

(7.37)

7.3.2 Choice of Correlation Functions

It is important to emphasize that the accuracy of the method is highly dependent
on the choice of correlation functions in (7.23) and (7.27), since they determine the
inﬂuence of the observed values in the surrounding locations. These are not known
a priori, however, and they have to be estimated from the data. In order to ﬁnd a way
to approximate the correlation functions, it is customary to assume that they can be
expressed as

Ri j (θ; xi , x j ) =

(k)
ρ(θ; x
i

, x

(k)
j

) =

(k)
ρ(θ; |x
i

− x

(k)
j

|),

(7.38)

n(cid:12)

k=1

n(cid:12)

k=1

for some parameter θ and xi , x j ∈ Rn with x(k) denoting the kth component of
the vector x. The expression (7.38) implies that multi-dimensional correlations are
expressed as a product of n one-dimensional correlation functions. Spatial correlation
functions depend on both the parameter θ and the distance between the considered
(k)
|. In order to result in proper correlation functions Ri j , the
points Φ = |x
i

− x

(k)
j

122

P. Tsiotras and R. S. Diaz

coordinate correlation function ρ must satisfy 0 ≤ ρ(θ; Φ) ≤ 1 for all Φ ≥ 0.
Furthermore, it must satisfy ρ(θ; 0) = 1 and limΦ→∞ ρ(θ; Φ) = 0, encoding the fact
that far-away points have weaker or no correlation, whereas coincident points yield
maximum correlation.

The parameter θ determines how fast the correlation function goes to zero. This
parameter can be obtained using Maximum Likelihood Estimation (MLE). Figure 7.6
shows the effect of θ is the response surface for the function f (x, y) = x 2 + y3. For
simplicity, a constant polynomial is selected as the general trend. Different kriging
models are built for different values of θ. The resulting metamodel representation
and the observation points for the decreasing values of θ are also shown in Fig. 7.6.
The spatial evolution according to the distance from the origin and the inﬂuence
of the parameter θ, for different correlation functions, is shown in Fig. 7.7. As it is
customary in practice, the state variables are normalized so that have unit length.
Consequently, the normalized support (|d| = Φ) of ρ is this ﬁgure is 0 ≤ |d| (cid:2) 2.

7.4 Application to On-line Aggressive Vehicle Maneuver

Generation

7.4.1 Feedback Controller Synthesis

Using the method outlined in Sect. 7.2.3, a set of trajectories was computed ofﬂine
using ﬁve equidistant initial conditions corresponding to vehicle initial speeds V0 =
[40, 48, 56, 64, 72] km/h. The pre-computed open-loop optimal trajectories for
three of the cases considered are shown in Fig. 7.8.

We are interested in obtaining a controller able to perform the maneuver de-
scribed in Sect. 7.2.1 in a (near-)optimal manner for any initial velocity in the interval
40 km/h ≤ V0 ≤ 72 km/h. To this end, we use the interpolation expressions derived
in Sect. 7.3.1, speciﬁcally, Eq. (7.35). A separate interpolation model is needed for
each variable we want to interpolate. In this case we have a total of four interpo-
lating metamodels: three for the control signals and one more for the optimal ﬁnal
time. A uniform discretization of the optimal trajectories provides the input data
X = [x1 . . . xN ], whereas the control commands δ, Tb, Tbh, and the ﬁnal time t f
comprise the vector of the observed variables y at the same time instances. Given
now a state x0 = (u(tk), v(tk), ψ(tk), ω f (tk), ω f (tk)) of the vehicle trajectory at
some time tk, we obtain the required control inputs as a function of the current state
as follows

δ(tk) = ˆy1(x0) = κ1(u(tk), v(tk), ψ(tk), ω f (tk), ω f (tk)),
Tb(tk) = ˆy2(x0) = κ2(u(tk), v(tk), ψ(tk), ω f (tk), ω f (tk)),
Tbh(tk) = ˆy3(x0) = κ3(u(tk), v(tk), ψ(tk), ω f (tk), ω f (tk)),

(7.39)

(7.40)
(7.41)

7 Real-Time Near-Optimal Feedback Control

123

1.4

1.2

1

0.8

0.6

0.4

0.2

0

−0.2

−0.4

−0.6

1.5

1

0

0.5

(a)
2

1.5

0.5

1

0

−0.5

−1
1

(c)

1.5

0.5

2

1

0

−0.5

−1
1

1

0.5

0

 
0

1

0.5

1.2

1

0.8

0.6

0.4

0.2

0

−0.2

−0.4

−0.6

1.5

1

0

0.5

(b)
2

1.5

0.5

1

0

−0.5

−1
1

(d)

1.5

0.5

2

1

0

−0.5

−1
1

0.5

0

0

1

0.5

0.5

0

−0.5

0

−0.5

−1

−1

1

0.5

0.5

0

−0.5

0

−0.5

−1

−1

1

0.5

0.5

0

−0.5

0

−0.5

−1

−1

1

0.5

−0.5

0.5

0

−0.5

0

−0.5

−1

−1

−0.5

1

0.5

Fig. 7.6 Inﬂuence of the parameter θ in the response surface. a θ = 1,000, b θ = 20, c θ = 5 d θ
obtained from MLE

Exponential

Gauss

 

1

θ =0.5
θ =1
θ =2

0.5

1.5

2

0.5

1.5

2

1
|d|

Linear

1
|d|

1
|d|

Cubic

1
|d|

0
0

0.5

1.5

2

0
0

0.5

1.5

2

Fig. 7.7 Different possible choices for correlation functions ρ(θ; |d|)

124

,
y
t
i
c
o
l
e
V

 
.

g
n
o
L

)
s
/
m

(
 
u

 

20

15

10

5

0

°

)
s
/

(
 
r
 
,
e
t
a
R
w
a
Y

 

200

150

100

50

0

r

,

 ω
d
e
e
p
s
 
l
e
e
h
w

 
.

F

)

M
P
R

(
 

600

500

400

300

200

100

Longitudinal Velocity

Lateral Velocity

P. Tsiotras and R. S. Diaz

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

Time (s)

Yaw Rate

Time (s)

Heading Angle

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

Time (s)

Time (s)

Front wheel speed

Rear wheel speed

Case 1
Case 2
Case 3

Case 1
Case 2
Case 3

Case 1
Case 2
Case 3

 
,
y
t
i
c
o
l
e
V

 
l
a
r
e
t
a
L

 

 
,
e
l
g
n
A
g
n
d
a
e
H

i

)
s
/
m

(
 
v

)

°

(
 

ψ

r

ω

 
,

d
e
e
p
s
 
l
e
e
h
w

 
.

R

)

M
P
R

(
 

5

0

−5

−10

−15

100

80

60

40

20

0

600
500
400
300
200
100
0

Case 1
Case 2
Case 3

Case 1
Case 2
Case 3

Case 1
Case 2
Case 3

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

Time (s)

Time (s)

Fig. 7.8 Optimal open-loop state trajectories generated with GPOPS

where, for notational convenience, we have introduced, rather informally, the interpo-
lating functions κi (i = 1, 2, 3, 4) to denote the right-hand-side of (7.35). Similarly,
the optimal time to perform the maneuver from the current state is given by

t f (tk) = ˆy4(x0) = κ4(u(tk), v(t)k), ψ(tk), ω f (tk), ω f (tk)).

(7.42)

Note from (7.39) to (7.41) that the approach yields, at each instant of time, a control
action that depends on the current state, that is, the resulting control has a feedback
structure. In essence, we have developed a tool for controller synthesis where the
open-loop optimal controllers are combined to a single feedback strategy. The dif-
ference with standard approaches is that this synthesis is not performed analytically,
but rather numerically, via an implicit interpolation of the pre-computed open-loop
control laws.

For all computations we have used the DACE toolbox for Matlab [21]. Both the
correlation functions and the allowable values for the parameter θ were determined by
trial and error. Constant and ﬁrst order polynomials were sufﬁcient for this problem,
along with cubic correlation functions (see Fig. 7.7). The optimal value of θ was
obtained using MSE, as explained in Sect. 7.3.2.

7 Real-Time Near-Optimal Feedback Control

125

7.4.2 Numerical Results

The family of near-optimal controls is shown in Fig. 7.9a–c. The red lines highlight
the pre-computed solutions used to obtain the interpolating metamodel.

These results show that the controller obtained using the proposed statistical in-
terpolation technique generates near-optimal solutions for the whole range of initial
velocities considered. In all simulations the trajectories reach the ﬁnal constraint,
ψ = 90◦, as required. Furthermore, notice in Fig. 7.9a–c how the interpolated so-
lutions match the pre-computed ones at the trial sites. This is a consequence of the
exact interpolation property of the interpolation scheme, shown in (7.37). Notice also
that the solutions vary smoothly along the whole range of initial velocities.

The average to compute a single interpolation of all three controls was 1.2 ms (or a
rate of 800 Hz) on a Intel Pentium Core 2 Duo processor running at 2.4 GHz with 4 GB
of RAM. This rate is considered fast enough for real-time controller implementation.
The parameter θ that affects the behavior of the correlation functions is shown
in Fig. 7.10 for the case of the footbrake command. For very large values of θ the
solution tends to the GLS solution (r (x0) = 0 except at the observation points). The
oscillatory behavior for large values of θ observed in these ﬁgures is owing to the
fact that we have chosen a zero order polynomial for the footbrake, in which case the
interpolating terms tend to a superposition of impulse functions at the observed points
(see Fig. 7.7). As the value of θ is reduced, each observation increases its “region
of inﬂuence” over a larger area of the space, thus “averaging out” the contributions
from neighboring observation points.

It is also of interest to explore the positive attributes that arise from having a
controller in feedback form [see again (7.39–(7.41)]. Although there is no analytic
expression for the feedback controller, the control action is obtained as a function of
the current state. Feedback controllers are more desirable than open-loop controllers
since they can account for sudden changes in the state, unmodelled uncertainties, etc.
In order to evaluate the beneﬁts of having a controller in a feedback form, a simulation
with a disturbance representing a 30 % reduction in the yaw rate at t = 0.6t f was
carried out. The comparison was performed at one of the trial locations where the
interpolated solution matches the pre-computed one, so the comparison is fair. The
initial velocity was chosen as V0 = 56 km/h. Figure 7.11 shows how the interpolated
control changes when the disturbance is applied and how the system is ﬁnally guided
to the ﬁnal constraint despite the abrupt change in the state at t = 0.6t f .

7.5 Conclusions

The future generation of active safety systems for passenger vehicles will have to take
advantage of the nonlinearities of the vehicle and tire friction dynamics in order to
safely implement more aggressive obstacle avoidance maneuvers in the case of an im-
peding accident. Unfortunately, generating optimally such aggressive maneuvers—at

126

(a)

)
g
e
d
(
 
g
n
i
r
e
e
t
s

30

20

10

0

−10
0

P. Tsiotras and R. S. Diaz

0.5

t (s)

1

1.5

80

40

50

60

70

V0 (m/s)

40

50

60

70

V0 (m/s)

0.5

t (s)

1

80

1.5

(b)

)
−
(
 
t
u
p
n
i
 
e
k
a
r
b
t
o
o
f

0.4

0.3

0.2

0.1

0
0

(c)

)
−
(
 
t

u
p
n

i
 

e
k
a
r
b
d
n
a
h

1.5

1

0.5

0
0

40

50

60

70

80

V0 (m/s)

0.5

t (s)

1

1.5

Fig. 7.9 Interpolated optimal control histories. a Steering command. b Footbrake command.
c Handbrake command

Fig. 7.10 Effect of correlation parameter θ on the optimal footbrake command response surface.
a Large value of θ. b Medium value of θ. c Low value of θ

150

100

50

80

60

40

20

0

0

)
s
/
g
e
d
(
 
e
t
a
r
 

w
a
Y

)
g
e
d
(
 

l

 

ψ
e
g
n
a

 

i

g
n
d
a
e
H

7 Real-Time Near-Optimal Feedback Control

Interpolation
Pre−computed

127

Interpolation
Pre−computed

)
g
e
d
(
 
g
n
i
r
e
e
t
S

)
−
(
 
s
e
k
a
r
B

20

10

0

−10

0

1

0.8

0.6

0.4

0.2

0

0

0.2

0.4

0.8

1

1.2

0.6
Time (s)

0

0

0.2

0.4

0.8

0.6
Time (s)

1

1.2

Interp. FB
Pre−computed FB
Interp. HB
Pre−computed HB

Interpolation
Pre−computed

0.2

0.4

0.8

1

1.2

0.2

0.4

0.8

1

1.2

0.6
Time (s)

0.6
Time (s)

Fig. 7.11 State evolution comparison under disturbance

the time scales required along with convergence guarantees—is still an elusive goal
with current trajectory optimizers. In this chapter we investigate the use of a statis-
tical interpolation technique based on Gaussian processes (e.g., kriging) to generate
near-optimal trajectories, along the corresponding control actions, from a set of off-
line pre-computed optimal trajectories. The resulting approach essentially generates
a metamodel of the action-response map based on the pre-computed optimal control
solutions. The resulting interpolation model emulates an optimal feedback controller,
as long as the initial conditions are contained in the convex hull of the off-line test
locations.

Our numerical results show that the resulting controller has excellent perfor-
mance, always guiding the system to the exact terminal constraint. Furthermore, the
controller is extremely fast to compute, since it is based on simple algebraic manip-
ulations and hence it is beneﬁcial for all similar situations where decisions must be
taken within extremely short deadlines.
Abstract Modern vehicle dynamic control systems are based on new types of ac-
tuators, such as active steering and active differentials, in order to improve the over-
all handling performance including stability, responsiveness, and agility. Numerical
techniques of off-line optimization of vehicle dynamics control variables can con-
veniently be used to facilitate decisions on optimal actuator conﬁgurations and pro-
vide guidance for design of realistic, on-line controllers. This chapter overviews the
previous authors’ results of assessment of various vehicle dynamics actuator conﬁg-
urations based on application of a back propagation through time (BPTT) conjugate
gradient optimization algorithm. It is then focused on detailed optimization of active
front and rear steering control variables for various maneuvers and design speciﬁca-
tions, where a nonlinear programming-based optimization tool is used.

8.1 Introduction

The conventional vehicle dynamics control systems are based on using wheel brakes
as actuators [13, 15]. By braking solely or predominantly one of the wheels, a proper
amount of active yaw torque is generated and at the same time the vehicle is de-
celerated, which contributes to the vehicle handling stability and responsiveness
(i.e. oversteer and understeer compensation, respectively). In recent years the active
chassis systems are being equipped with different types of additional actuators such
as active steering or active differentials [7, 8, 10], which can provide superior han-
dling performance without being intrusive to the driver (no NVH disturbance unlike
for hydraulic brakes) and without affecting agility (minimal reduction of the vehicle
velocity).

In the early stage of active chassis hardware speciﬁcation/selection, optimization
techniques can be used for assessment of various single- or multi-actuator chassis
conﬁgurations. More speciﬁcally, an open-loop optimal control algorithm is applied
to a proper nonlinear vehicle dynamics model to ﬁnd time response of control vari-
ables that minimize the speciﬁed cost function (e.g. minimal trajectory following
error) under various equality and inequality constraints (e.g. limited control input
authority or state variable magnitude). At the same time, the optimization results can
be used as a benchmark for achievable performance of production-oriented (on-line)
control systems (e.g. model predictive control systems [5]) as well as to give good
insights that can facilitate control system design and calibration.

Although different control variable optimization algorithms have been used in
various automotive power train studies (e.g. dynamic programming for optimization
of hybrid electric power trains [2, 6] and nonlinear programming for turbocharger
power assist system optimization [12]), their application to vehicle dynamics control
ﬁeld have been relatively scarce (with exceptions of, for instance, [9, 16] where
handling analyses were conducted). The authors’ recent chapter [4] have dealt with
assessment of various vehicle dynamics actuator conﬁgurations, based on the ap-
plication of a back propagation through time optimization (BPTT) algorithm [11].
Those assessment results are outlined in this chapter, as a background for presenting
a more recent active front and rear steering optimization study based on a funda-
mentally different nonlinear programming method implemented through TOMLAB
optimization platform [14].

8.2 Overview of Previous Optimization and Assessment Results

8.2.1 Optimization Algorithm

The general optimization problem is to ﬁnd a control vector input u(t), 0 ≤ t ≤ tf ,
(cid:2) tf
which minimizes the Bolza-type cost function J0 = Φ((cid:2)x(tf ) +
0 F0((cid:3)x(t), u(t))dt,
subject to nonlinear plant state equations ˙(cid:3)x = φ((cid:3)x(t), u(t))dt,(cid:3)x(0) = (cid:3)x0, and subject
to the ﬁnal conditions on the state vector b((cid:3)x(tf )) = 0, and subject to the control
and state vector inequality constraints g((cid:3)x(t), u(t)) ∈ 0 and equality constraints
h((cid:3)x(t), u(t)) = 0.

In the previous work [4], the optimal control vector input u(t) was found by using
an iterative gradient descent algorithm with respect to control vector: u(l+1)(t) =
u(l)(t) − η ∂ J
, where the total cost function J included the basic (user-deﬁned)
function J0 extended with the penalty terms for the ﬁnal conditions, and the equality
∂ J
∂u was calculated by utilizing the BPTT
and inequality constraints. The gradient

∂u(l)(t)

8 Applications of Computational Optimal Control

133

algorithm based on the plant model discretized in time using the Adams method [11].
The Jacobians were calculated numerically. The learning rate η was made time variant
using the Dai-Yuan conjugate gradient method, in order to improve the algorithm
convergence rate.

8.2.2 Vehicle Model

A 10-Degree of Freedom (DoF) vehicle dynamics model [8] with a full “magic”
formula tire model was implemented within the optimization program. The model
includes six state variables, which are related to the longitudinal (U ), lateral (V ), and
heave (W ) velocities, and roll ( p), pitch (q), and yaw (r ) rates. The remaining four
state variables correspond to the rotational speeds of each wheel. In addition, six state
variables related to suspension submodel and vehicle trajectory in the inertial (X–Y)
coordinate system are used (roll, pitch, and yaw angles, heave displacement, and
vehicle X,Y position), as well as state variable(s) related to ﬁrst-order lag term(s) de-
scribing the actuator dynamics. Thus, the overall nonlinear dynamics model includes
from 17 to 19 state variables and from 1 to 3 control variables, depending on the
number of actuators used in particular vehicle conﬁguration.

Due to the paper length constraints, only the main model state equations, related

to the lateral velocity and yaw rate DOFs, are given:

M( ˙V + Ur ) = Fyf + Fyr

Izz ˙r ∞= bFy f − cFyr − w
2

(Fx1 + Fx2 + Fx3 + Fx4)

where M is the vehicle mass, Izz is the vehicle moment of inertia around the vertical
axis, b and c are the distances between the vehicle center of gravity and the front and
rear axles, respectively, w is the vehicle track (the distance between the left and right
wheel axes). Fx and Fy denote the longitudinal and lateral tire forces, respectively,
after being transformed from the tire to vehicle coordinate system. Here, the index
i = 1, . . . , 4 represent the tire number starting from the front-left tire towards the
rear-left tire in the clockwise direction, and the indices f and r refer to front and rear
axle, with Fy f = Fy1 + Fy2 and Fyr = Fy3 + Fy4. The sign conventions are such that
the yaw rate r is positive for counter-clockwise turning, where the wheels 1 and 3 are
inner wheels. For the sake of simplicity of presentation, the yaw rate state Eq. (8.2)
omits a roll cross-coupling term that is of secondary importance.

The tire model describes nonlinear, combined-slip tire static curves as functions
of the tire normal force Fzi , i = 1, . . . , 4, calculated from a nonlinear suspension
model, and the tire sideslip angle αi and the longitudinal slip ηi , given by:

αi = δi − arctan

(cid:2)

(cid:3)

Vi
Ui

(8.1)

(8.2)

(8.3)

134

J. Deur et al.

Fig. 8.1 Tire model static curves

ηi = Rωi − Ui

Ui

(8.4)

where ωi are the wheel rotational speeds, δi are the road wheel angles, R is the
effective tire radius, and Ui and Vi are the longitudinal and lateral wheel center
velocity components, respectively:
Ui = U + (−1)i w
2

r, V1,2 = V + br, V3,4 = V − cr

(8.5)

The modeled tire static curves are shown in Fig. 8.1 The obtained tire forces
Fxti and Fyti are transformed into the vehicle coordinate system by using the wheel
steering input δi , thus obtaining the forces Fxi and Fyi that are fed into the state-space
model (see Eqs. 8.1 and 8.2).

The considered actuators include active front and rear steering (AFS and ARS),
active rear, front and, central differentials of limited slip and torque vectoring types
(ALSRD, TVRD, ALSFD, TVFD, ALSCD, and TVCD). The vehicle (a mid-size
sedan) is of rear wheel drive (RWD) type, except in the cases of using the front or
central differentials, when a FWD or 4WD conﬁguration is considered, respectively.
The active differential torque transfer is subject to the following constraints [3, 10]:
(1) the ALSD cannot transfer the torque to faster wheel, and (2) the TVD can transfer

8 Applications of Computational Optimal Control

135

Table 8.1 List of double lane change maneuver variants

No.

1
2
3

Ti (Nm)

0
350
250

μ

0.6
1
0.6

Speciﬁcs

Initial understeer, then oversteer
Understeer under torque
Initial understeer, then instability

the torque to faster wheel (or faster axle for TVCD) only if the faster-slower wheel
relative speed difference is smaller than the Allowable Wheel Speed Difference
factor (AWSD = 28.6 % for the given TVDs). These constraints were conveniently
implemented through the vehicle model rather than via inequality constraints.

8.2.3 Formulation of Optimization Problem

The optimization study was conducted for three characteristic types of double lane
change maneuver (DLC; Table 8.1). The objective was to ﬁnd the control inputs for a
given actuator conﬁguration, which minimized the path following error given by the
cost function subintegral function F0((cid:3)x(t), u(t)) = Kh(Y −YR(X ))2, where YR(X R)
is the DLC reference trajectory. This objective is subject to inequality constraints
(limits) on control input variables and sideslip angle β = ar ctan(V /U ) (20≈ and
15≈, respectively), as well as on the active front steering angle rate (to avoid largely
affecting the perceived driver torque feedback).

Maneuver 1 is deﬁned as follows. The front steering input δ f is ﬁrst optimized
to follow the given DLC reference path for the tire-road friction coefﬁcient μ = 1
and zero driveline input torque (Ti = 0). The optimized variable δ f is then used as
an open-loop driver input (again with Ti = 0) for optimizations of vehicle dynamics
control inputs for the reference trajectory achieved in the ﬁrst step, but reduced fric-
tion coefﬁcient μ = 0.6. Due to the already saturated lateral tire forces (for μ = 1),
the friction reduction results in tendency of passive vehicle to initially understeer
and then strongly oversteer (see ‘no control’ response in Fig. 8.2a). Maneuver 2 uti-
lizes the same front steering input δ f and the reference trajectory, but it is applied
under the accelerating conditions (Ti = 350 Nm) and the nominal road condition
μ = 1. Obviously, in the presence of accelerating torque and unchanged driver
steering input, the passive vehicle is prone to understeer, particularly in the second
part of response (Fig. 8.2b). Maneuver 3 is similar to Maneuver 1. The main differ-
ence is that the optimization relates to a non-zero driveline torque (Ti = 250 Nm).
According to tire friction ellipse (Fig. 8.1), this reduces the rear (driven) tire lateral
forces, thus making the passive vehicle unstable (the sideslip angle β starts diverg-
ing around the peak trajectory point, see Sect. 8.3). Also, the initial understeer is
more emphasized than in Maneuver 1 (cf. Fig. 8.2a and c), because of the growth
of vehicle velocity and corresponding rise of achievable (stationary) turning radius

136

J. Deur et al.

Fig. 8.2 Trajectory following optimization results for three DLC maneuvers and ARS actuator

Rt = U 2/ay,sat for the given (saturated) lateral acceleration ay,sat = μg (see Eq. 8.1
and note that ay = ˙V + rU and (Fy f + Fyr )sat = Mgμ).

8.2.4 Optimization and Assessment Results

The optimization results for different single- and multi-actuator conﬁgurations and
the three DLC maneuvers are given in Table 8.2. The trajectory following accuracy
is characterized by the root-mean-square (RMS) error of Y (X )−YR(X ). The vehicle
stabilization is reﬂected in the ability of suppressing the magnitude of sideslip angle
β. The agility is better if the traveled distance X (t f ) over the constant maneuver time
period is larger. Based on these indices, the different actuator conﬁgurations have
been ranked, with the ﬁnal ranking/assessment results also included in Table 8.2.
The assessment results are brieﬂy discussed below, with the reference to [4] for
more detailed elaboration.

According to the RMS data in Table 8.2 and also the trajectory plots in Fig. 8.2,
Maneuver 3 is the most difﬁcult in terms of trajectory following accuracy. This is

8 Applications of Computational Optimal Control

137

)

m
h
t
i
r
o
g
l
a
T
T
P
B
g
n
i
s
u
(

s
r
e
v
u
e
n
a
m
d
n
a

s
n
o
i
t
a
r
u
g
ﬁ
n
o
c

r
o
t
a
u
t
c
a

l
a
i
t
n
e
r
e
f
f
i
d
-
e
v
i
t
c
a
d
n
a
g
n
i
r
e
e
t
s
-
e
v
i
t
c
a

s
u
o
i
r
a
v
r
o
f

s
t
l
u
s
e
r
n
o
i
t
a
z
i
m

i
t
p
o
e
v
i
t
a
r
a
p
m
o
C

2
.
8
e
l
b
a
T

k
n
a
r

k
n
a
r

)

m

(

)

f

t

(
X

)

m

(
S
M
R

)

m

(

)

f

t

(
X

)

m

(
S
M
R

)

m

(

)

f

t

(
X

)

m

(
S
M
R

r
o
t
a
u
t
c
a
-
i
t
l
u
M

r
o
t
a
u
t
c
a

e
l
g
n
i
S

3

r
e
v
u
e
n
a
M

2

r
e
v
u
e
n
a
M

1

r
e
v
u
e
n
a
M

n
o
i
t
a
r
u
g
ﬁ
n
o
c

r
o
t
a
u
t
c
A

.
o
N

1

5

9

2
1

8

1
1

1
1

3
1

3

6

7

2

4

0
1

1

2

4

7

3

6

5

8

o

*
*
o
o

*
*

*

*
*
*

*

.

5
7
1
1

.

9
8
1
1

.

5
7
1
1

.

2
1
1
1

.

4
7
1
1

.

7
9
1
1

.

7
6
1
1

.

2
9
1
1

.

8
7
1
1

.

3
9
1
1

.

1
5
1
1

.

9
6
1
1

.

4
5
1
1

.

0
5
1
1

x
a
m

|

β

)
g
e
d
(

7
0
3
4

.

4
5
3
5

.

4
7
7
4

.

.

3
8
1

2
2
8
5

.

4
3
7
4

.

6
3
0
5

.

3
2
1
6

.

4
6
0
5

.

6
4
3
4

.

8
0
1
6

.

0
1
0
5

.

4
4
2
7

.

3
2
4
6

.

0
9
1
0

.

4
3
2
0

.

6
2
3
0

.

7
6
4
5

.

9
6
2
0

.

2
3
4
0

.

0
1
4
0

.

7
5
5
0

.

0
2
2
0

.

8
4
2
0

.

3
4
2
0

.

5
7
3
0

.

6
8
1
0

.

2
9
1
0

.

.

7
2
2
1

.

9
2
2
1

.

8
1
2
1

.

1
4
2
1

.

4
3
2
1

.

8
4
2
1

.

9
9
1
1

.

2
4
2
1

.

4
2
2
1

.

6
3
2
1

.

7
9
1
1

.

0
1
2
1

.

0
2
2
1

.

2
1
2
1

x
a
m

|

β

)
g
e
d
(

3
0
4
4

.

7
1
8
4

.

8
7
4
3

.

6
3
4
3

.

2
5
5
3

.

4
0
6
2

.

7
6
9
2

.

7
5
4
3

.

4
3
8
4

.

2
8
7
3

.

4
6
0
4

.

5
6
1
3

.

0
6
6
4

.

6
8
8
3

.

8
3
0
0

.

5
4
0
0

.

6
8
0
0

.

3
4
2
0

.

2
1
1
0

.

8
5
1
0

.

0
3
1
0

.

4
0
6
0

.

3
4
0
0

.

4
6
0
0

.

9
6
0
0

.

0
3
1
0

.

5
7
0
0

.

0
8
0
0

.

.

0
4
0
1

.

8
4
0
1

.

1
3
0
1

.

7
5
0
1

.

8
2
0
1

.

7
5
0
1

.

9
2
0
1

.

6
4
0
1

.

7
4
0
1

.

3
5
0
1

6
.
2
0
1

.

0
4
0
1

8
.
1
0
1

6
.
0
0
1

x
a
m

|

β

)
g
e
d
(

5
6
5
.
4

2
0
5
.
5

4
7
7
.
4

5
3
8
.
4

7
4
7
.
5

2
2
8
.
4

0
1
4
.
5

5
9
2
.
7

1
0
9
.
4

3
3
7
.
4

1
1
2
.
5

2
0
0
.
5

3
6
2
.
7

4
5
8
.
6

6
1
1
.
0

6
4
1
.
0

0
4
1
.
0

0
9
2
.
0

4
2
1
.
0

8
5
2
.
0

8
5
3
.
0

4
0
4
.
2

9
4
1
.
0

0
6
1
.
0

5
6
1
.
0

3
8
2
.
0

1
1
1
.
0

1
0
1
.
0

D
R
S
L
A
&
S
F
A

D
C
V
T
&
D
R
V
T

D
R
V
T
&
S
F
A

D
C
V
T
&
D
R
S
L
A

D
F
V
T
&
D
R
V
T

D
C
V
T
&
D
R
V
T

D
F
V
T
&

D
R
S
L
A

D
R
V
T

D
F
V
T

D
F
S
L
A

D
C
V
T

D
C
S
L
A

S
R
A

S
F
A

1

2

3

4

5

6

7

8

9

0
1

1
1

2
1

3
1

4
1

)
k
c
a
b
d
e
e
f

e
u
q
r
o
t
S
F
A

r
e
t
t
e
b
(

t
r
o
f
f
e

l
o
r
t
n
o
c

r
e
l
l
a
m

s

f
o
s

m
r
e
t
n
i

s
r
o
t
a
u
t
c
a

e
r
o
m
g
n
i
c
u
d
o
r
t
n
i

e
c
n
a
m
r
o
f
r
e
p

f
o
s

m
r
e
t
n
i

s
r
o
t
a
u
t
c
a

e
r
o
m
g
n
i
c
u
d
o
r
t
n
i

y
b

y
b

t
n
e
m
e
v
o
r
p
m

i

t
n
e
m
e
v
o
r
p
m

i

=
*

=
o

138

J. Deur et al.

because it is hard to stabilize the accelerating passive vehicle on the low-μ surface
(see Table 8.1), and also to compensate for the initial understeer in the case of reduced
μ. Maneuver 2 is the least difﬁcult, because the friction coefﬁcient is the highest.

The active rear steering (ARS) provides the best overall performance, owing to
a high control authority of both yaw rate and lateral velocity/acceleration dynam-
ics (the control input δr = δ3,4 can inﬂuence both state Eqs. 8.1 and 8.2, through
the rear lateral forces F y3, 4). Although quite effective, the individual rear or front
torque vectoring differentials (TVRD or TVFD) are inferior to the ARS actuator.
This is because they directly inﬂuence only the yaw rate dynamics through gener-
ating difference in left and right longitudinal tire forces (see Eq. 8.2), and because
the longitudinal force generation is limited by a low normal load of inner tires. The
combined front TVD and rear TVD conﬁguration provides excel-lent performance,
owing to the balanced front/rear axle torque distribution (for this 4WD conﬁgura-
tion) and increased TVD control authority (both axles generate the yaw torque).
However, when compared to the ARS actuator, the TVRD+TVFD conﬁguration is
characterized by somewhat reduced agility (due to the certain decelerating action of
TVDs [3]) and increased sideslip magnitudes (due to strong yaw torque generation).
The central TVD can rarely contribute to the performance boost of the TVFD+TVRD
conﬁguration.

The active front steering (AFS) is also among the best performers, but it is
consistently worse than the ARS actuator due to a lower control authority (see
Sect. 8.3). The AFS+TVRD and TVRD+TVCD controls have also been found to
be viable conﬁgurations, where the former provides a good trade off between the
performance and limited AFS control effort, and the latter improves the TVRD per-
formance for the throttle-on Maneuvers 2 and 3 due to its 4WD feature and additional
understeer and oversteer compensation imposed by TVCD. However, they do not of-
fer as signiﬁcant improvement over the individual controls as the TVRD+TVFD
conﬁguration.

The TVCD is inferior to TVFD or TVRD for the coasting Maneuver 1, because it
acts on the lateral tire forces indirectly—through spinning the front axle for oversteer
compensation or rear axle for understeer compensation. On the other hand, it gives
rather good performance for the accelerating Maneuvers 2 and 3, partly because of
its 4WD feature. The front and rear active limited slip differentials (ALSFD and
ALSRD) give worse performance than TVDs, which is explained by their limited,
zero-AWSD-related control authority: (1) the oversteer compensation is constrained
by the weakly-loaded inner wheel being spun above the outer wheel speed, and
(2) the understeer compensation is unfeasible (the torque cannot be transferred to
faster/outer wheel), unless the inner wheel tends to spin for an accelerating maneuver.
The ALSCD barely gives any improvements over the passive vehicle.

The presented comparative study has demonstrated that the BPTT optimization
algorithm can represent a useful tool for assessment of various vehicle dynamics
actuator conﬁgurations. However, certain issues have been observed in the optimiza-
tion results: (1) the optimization of some multi-actuator conﬁgurations give worse
(RMS error) results than in the case of corresponding single-actuator conﬁguration
(see e.g. AFS+ALSRD conﬁguration in Table 8.2), and (2) the optimization was

8 Applications of Computational Optimal Control

139

inconsistent for the ALSRD actuator and Maneuver 3 (unrealistically high RMS er-
ror). The former can be explained by the fact that optimization ends in a local optimum
for more complex-multi actuator conﬁgurations (especially those with actuators of
different types). The latter can be caused by highly nonlinear clutch model used to
describe the active differential dynamics. In order to avoid issues with multi-actuator
conﬁguration optimization, a more detailed ARS/AFS study has been conducted by
using the TOMLAB optimization platform (see Sect. 8.3).

8.3 Detailed Optimization for Active Steering Conﬁgurations

8.3.1 Optimization Algorithm

TOMLAB optimization platform is Matlab interface package for modeling, optimiza-
tion and optimal control [14]. It consists of modules for optimal control formulation
(PROPT), automatic differentiation (MAD) and variety of problem solvers (SNOPT,
KNITRO, CPLEX etc.). The user speciﬁes state equations that are considered as
equality constraints, initial and ﬁnal conditions, constraints and cost function. The
optimization approach is based on pseudospectral collocation method in which the
optimal control problem is discretized and transformed into large-scale nonlinear
programming (NLP) problem [1]. The solution takes polynomial form of nth order,
where n is the number of collocation (time grid) points speciﬁed by the user. The
number of grid points is signiﬁcantly smaller than in the case of BPTT algorithm,
where a dense grid was needed to explicitly calculate the control input values at each
grid point. This difference may contribute to a lower local minima sensitivity of the
NLP algorithm when compared to its BPTT counterpart. The polynomial solution
needs to satisfy the discretized state equations and constraints in the collocation
points. If solver claims that solution is optimal, it satisﬁes necessary, not sufﬁcient,
optimality conditions. In this work the large-scale sparse solver SNOPT is used,
which is based on the sequential quadratic programming (SQP) method. As SNOPT
uses nonlinear function gradients, calculated automatically by MAD, the problem
must be smooth (ﬁrst-order differentiable) around the optimal solution.

8.3.2 Active Rear Steering (ARS)

The ARS optimization results are shown in Fig. 8.3 for the three DLC maneuvers
deﬁned in Table 8.1, and a soft constraint imposed on the control input. The related
performance indices are given in ﬁrst two rows of Table 8.3. The sign conventions
are such that negative ARS control input, the rear road wheel angle δr , contributes
to increase of positive yaw rate r . That is, the ARS actuator generates oversteer (or
compensate for understeer) if sgn(δr ) ≡= sgn(r ), and the understeer is generated

140

J. Deur et al.

Table 8.3 Comparative optimization results for various active-steering conﬁgurations and different
maneuvers (using Tomlab tool)

Actuator
conﬁguration constraint

Control input RMS (m)

| β |max X (t f ) (m)
(deg)

| α |max
(deg)

ηmax (%)

| M z |max
(kNm)

(a) Maneuver 1
Yes
ARS
No
ARS
AFS
Yes
ARS & AFS Yes
ARS & AFS No
ARS & AFS Weak
(b) Maneuver 2
Yes
ARS
No
ARS
AFS
Yes
ARS & AFS Yes
ARS & AFS No
ARS & AFS Weak
(c) Maneuver 3
Yes
ARS
No
ARS
AFS
Yes
ARS & AFS Yes
ARS & AFS No
ARS & AFS Weak

0.112
0.087
0.137
0.091
0.031
0.069

0.044
0.017
0.045
0.030
0.006
0.027

0.176
0.158
0.229
0.163
0.101
0.145

4.58
4.75
5.26
4.96
17.7
8.38

4.06
4.20
4.05
4.66
20.7
4.69

4.75
4.43
5.14
4.29
17.86
5.23

103.9
100.4
104.4
102.5
92.4
100.0

123.2
118.0
123.2
122.2
109.7
121.7

116.6
112.7
118.6
115.7
105.2
112.9

9.2
27.2
9.4
9.7
37.3
18.5

8.7
32.1
8.1
9.4
48.1
10.0

9.8
25.8
10.3
9.7
32.0
22.1

0.06
0.3
0.04
0.1
0.4
0.2

6.7
37.8
7.0
11.0
49.9
5.8

12.3
26.2
3.7
11.2
47.7
8.0

8.0
11.8
10.3
12.5
16.7
16.5

8.0
22.0
12.9
11.3
28.4
19.8

9.0
11.6
10.1
13.7
16.9
16.6

(i.e. oversteer is compensated for) if sgn(δr ) = sgn(r ). Therefore, the δr and r
time responses in Fig. 8.3a (Maneuver 1) indicate that the control action is such that
there are three characteristic, relatively short periods of understeer compensation
(USC): t ≥ [0, 0.3], [1, 1.25] and [2.5, 2.7]s. The ﬁrst USC action steers the vehicle
towards the reference path, with the note that the actual vehicle trajectory response
is delayed with respect to control action due to the inﬂuence of vehicle dynamics
(i.e. the ARS provides a preview control action during initially straight motion). The
second USC intervention results in “cutting” the trajectory around its peak point, in
order to minimize the trajectory following error in the absence of ability to accurately
follow the reference trajectory peak on the reduced-μ surface. The third USC action
is similar to the ﬁrst one.

The USC actions result in characteristic peaks of the yaw torque, calculated as
∞= bFy f − cFyr (cf. Eq. 8.2), which provides boost of yaw rate r to generate
Mz
de-sired oversteer. Accordingly, each USC action provokes large rates of change of
the sideslip angle β (see Eq. 8.1 and recall that β = ar ctan(V /U )). In order to
effectively limit the sideslip angle β, and, thus, provide an ample stability margin
(compared to the passive/uncontrolled vehicle), each The USC interval is followed
by a relatively long interval of oversteer compensation (OSC). USC-related boosts

(c)
4

−2

0

2

0

4

2

0

−2

0

10

5

0

−5

5

0

−5

−10

25

20

15

0.4
0.2
0
−0.2
−0.4

5

0

−5

5
0
−5
−10

(b)
4

−2

0

2

0

4

2

0

−2

0

10

5

0

−5

5

0

−5

−10

28

26

24

22

20

0.4
0.2
0
−0.2
−0.4

5

0

−5

4

2

0

−2

(a)

]

m

[
 
)

X
Y

(

]

m

[
 
)
t
(

Y

]
°
[
 
)
t
(
β

4

2

0

4

2

0

−2

0

−2

0

10

5

0

−5

]

2

s
/
m

[
 
)
t
(

a

y

5

0

−5

−10

]
s
/
m

[
 
)
t
(

U

22

21

20

0

]
s
/
d
a
r
[
 
)
t
(
r

0.4
0.2
0
−0.2
−0.4

]

m
N
k
[
)
t
(

M

5

0

z

−5

]
°
[
)
t
(

r

δ

4

2

0

−2

8 Applications of Computational Optimal Control

141

Reference
No control
Optimal control

50

100

50

100

50

100

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

Fig. 8.3 Optimization results for ARS actuator and three DLC maneuvers

of side slip angle, i.e. its large deviation, result in decelerating force on the vehicle,
thus somewhat affecting the agility (the end speed U (t f ) is reduced compared to
reference and uncontrolled vehicle, Fig. 8.3).

The lateral acceleration response ay tends to follow that of the reference vehicle
(related to μ = 1). However, since the lateral acceleration is limited to 0.6g for the

142

J. Deur et al.

reduced μ = 0.6, accurate following of the lateral acceleration peaks around 1g
is not possible, which is “compensated for” by wider and sharper edges of lateral
acceleration. This gives a characteristic square-wave-like shape of ay response. The
tire sideslip angles αi and lateral forces Fyi assume similar response shape (not
shown in Fig. 8.3), particularly for rear tires (i = 3, 4) over which the ARS actuator
has a direct control authority.

Since the high-μ Maneuver 2 is less critical than Maneuver 1 (Sect. 8.2), the ARS
control input magnitudes are rather modest in this case (Fig. 8.3b). The dominant
control action relates to 2nd USC during the interval t ≥ [1, 1.4]s (and related 2nd
OSC for t ≥ [1.5, 2.2]s), which compensates for the emphasized understeer behavior
after the trajectory peak point. Other response features are qualitatively similar as
described above for Maneuver 1, including the effect of square-wave shaping of
lateral acceleration (particularly, during the dominant 2nd USC action).

The results for Maneuver 3 (Fig. 8.3c and Table 8.3c) are qualitatively similar to
those of Maneuver 1, with the main difference that the control action is strongest
for this more critical maneuver. Due to inability of accelerated vehicle to follow the
sharp trajectory around the peak point, the 1st USC action (around t = 0.1 s) is
made stronger to overshoot the initial part of trajectory, i.e. to “cut” the trajectory,
to a larger extent than in Maneuver 1. Accordingly, the lateral acceleration response
widely saturates afterwards, as well, thus getting closer to the square-wave shape. The
2nd USC intervention (around t = 1s) is also stronger to provide a more emphasized
“cutting” of the trajectory around its peak point.

Table 8.3 indicates that the trajectory following error can be notably reduced when
the control input constraint is omitted. However, the control input δr then reaches
excessive values (and has rather oscillatory behavior), the tire operates deeply in
the unstable saturation region (large magnitudes of αi ), the vehicle side-slip angle
magnitudes increase for the acceleration Maneuvers 2 and 3, and the longitudinal slip
of inner rear/driven tire is large. Also, due to an extremely abrupt and high-magnitude
nature of (control input) response, the obtained optimization results could not have
been fully reproduced through post-optimization simulation (a certain trajectory drift
occurred).

8.3.3 Active Front Steering (AFS)

The AFS optimization results, with the soft control input constraint included, are
given in third rows of Table 8.3. These results, as well as previous ARS results, are
in a good agreement with the BPTT optimization results (cf. Tables 8.2 and 8.3).

Although the magnitudes of the control inputs φδ f and δr are comparable (see
Fig. 8.4), the AFS control performance is notably worse than the ARS one (Table 8.3).
This is explained by the fact that the driver already utilizes the front steering input to
a large extent, while the rear steering control action can effectively boost the unused
transient performance of rear tires. More speciﬁcally, the driver’s front steering effort
δ f = δ1,2 is directly transferred to the front tire sideslip angles α1,2 and, thus, to

8 Applications of Computational Optimal Control

143

]
°
[
 

f

 δ

,
f 
δ
 Δ

,
 
δ

r

5
0
−5
−10

]

N
k
[

1
y

F

]

N
k
[

3
y

F

5

0

−5

5

0

−5

0

1

2

3

4

5

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

t [s]

t [s]

]

m
N
k
[

M

z

10

0

−10

0

5

0

−5

]

N
k
[

2
y

F

]

N
k
[

4
y

F

5

0

−5

ARS control
AFS control
Reference vehicle

Fig. 8.4 Comparative ARS and AFS optimization results for Maneuver 3

the front lateral forces Fy1,2, while the rear tire sideslip angles α3,4 (and the related
forces Fy3,4, are built up indirectly through a lagged response of the lateral velocity
V (or the sideslip angle β) and the yaw rate r (see Eq. 8.3).

On the other hand, the ARS control action δr = δ3,4 can directly inﬂuence α3,4
and Fy3,4, thus signiﬁcantly improving the lateral vehicle responsiveness. This is
illustrated by the comparative ARS and AFS responses of lateral forces Fyi (Fig. 8.4,
Maneuver 3), which shows the following (with particular attention to the 1st USC
event around t = 0.1 s): (1) the AFS action boosts the front lateral forces during
the transient interval, but it has a limited authority over the rear lateral forces, (2) the
ARS action makes the rear lateral forces response very fast and timely to assist the
AFS action in boosting the overall yaw torque and lateral acceleration response.

8.3.4 Four Wheel Steering (4WS = ARS & AFS)

When the ARS is combined with AFS in a 4WS conﬁguration, the trajectory fol-
lowing RMS error can be reduced by 7–30 % depending on maneuver (Table 8.3,
regular input constraint). Here, the more critical the maneuver, the lower is the RMS
error reduction. Figure 8.5a shows the corresponding time responses for Maneuver
1. The supporting AFS action is manifested in a strong 1st OSC intervention around
t = 0.3 s, which has a counter-steering meaning, and supplemental 2nd and 3rd USC
intervention around 1.1 and 2.65 s, respectively. The counter-steering interventions
allows for a stronger 1st USC action by the ARS actuator, thus boosting the critical
ﬁrst peak of (oversteer) yaw torque Mz and sideslip angle β when compared with

J. Deur et al.

144

(a)
0

0

0

5
0
5
0

0
0
0

0

0

0

(b)

]
°
[
β

10

0

−10
0

]

2

s
/
m

[

y

a

5
0
−5
−10

]

m
N
k
[

M

z

10
0
−10

f

f

]
°
[
 
δ
 
,
 
δ
Δ

 
,
 
δ

r

20

0

−20

0

0

1

2

3

4

5

1

2

3

4

5

Reference
No control
Optimal control
3
2

0

1

4

5

0

1

2

3

4

5

0

1

2

3

4

5

0

1

2

3

4

5

δ
r
Δδ
f

0

1

2

3

4

5

1

2

3

4

5

t [s]

t [s]

Fig. 8.5 Comparative 4WS optimization results for cases of regular (a) and weak (b) constraint on
ARS and AFS control inputs, and Maneuver 1

ARS control only (cf. Figs. 8.3a and 8.5a and see also Table 8.3a). The β-boost
affects the agility to some extent (Table 8.3a).

The 4WS can reduce the trajectory following RMS error by 40–65 % if the control
input constraint is omitted (Table 8.3). However, this results in an unacceptable
high-magnitude oscillatory behavior of control inputs and other variables, as already
explained in Sect. 8.3.1. Also, the magnitudes of sideslip angle β and longitudinal
slip η are very high (a “drifting” vehicle with spinning inner rear wheel).

If a weak control input constraint is used, the RMS error can be reduced by 11–
24 % when compared to the regular input constraint (Table 8.3), with a generally ac-
ceptable, well-damped response (Fig. 8.5b), suppressed magnitudes of sideslip angle
β, and a characteristic, strong and impulsive response of the yaw torque Mz. How-
ever, the AFS control input magnitudes are high, particularly the counter-steering
one, which may not be convenient from the standpoint of perceived driver torque
feedback. Also, the agility is somewhat deteriorated due to the increased β-peaks,
particularly after the 1st USC phase.

8.4 Conclusion

The presented study has demonstrated that advanced algorithms of computational
optimal control can represent a useful tool for assessment of various vehicle dynamics

8 Applications of Computational Optimal Control

145

actuator conﬁgurations and gain the insights into optimal control actions of those
actuators. The back propagation through time (BPTT) conjugate-gradient algorithm
and nonlinear programming (NLP)-based TOMLAB tool have given comparable
optimization results for single-actuator conﬁgurations, while the NLP approach has
proven to be more effective in multi-actuator conﬁgurations.

Among various single-actuator conﬁgurations the active rear steering (ARS) ac-
tuator gives the best overall performance, because of its ability to directly inﬂuence
the, otherwise unused/lagged, dynamic potential of rear tire lateral forces. The active
front steering (AFS) actuator can effectively assist the ARS actuator, but the related
performance boost is strongly related to an excessive AFS counter-steering action
that can affect the perceived driver torque feedback. When considering the active
differential application, it has been found out that the combined front and rear torque
vectoring differential (TVD) conﬁguration has the ability of reaching the ARS con-
trol performance. The AFS & TVRD and TVRD & TVCD conﬁgurations have also
been found to provide good performance. The front or rear TVDs are inferior to
ARS, but they may approach the AFS performance. The active limited slip differ-
entials (ALSDs) are inferior to TVDs, particularly for maneuvers with emphasized
understeer behavior.
Abstract Stochastic dynamic programming (SDP) is applied to generate control
policies that adjust vehicle speed to improve average fuel economy without de-
grading, signiﬁcantly, the average travel speed. The SDP policies take into account
statistical patterns in trafﬁc speed and road topography. Speciﬁc problems of fuel ef-
ﬁcient in-trafﬁc driving and fuel efﬁcient lead vehicle following are considered, and
it is shown how these problems can be treated within an SDP framework. Simulation
results are summarized to quantify fuel economy improvements, and experimental
results are reported for the fuel efﬁcient lead vehicle following case. The properties
of vehicle speed trajectories induced by SDP policies are examined.

9.1 Introduction

Fuel efﬁcient driving has emerged as one of the pathways to increasing fuel economy
of passenger cars. Fuel economy can be improved by driving at efﬁcient speeds,
accelerating quickly, but smoothly, coasting, and burn and coast (also known as
Pulse-and-Glide), see [22]. “Pulse-and-Glide” policies are particularly interesting in
view of their connections with periodic optimal control [7, 19, 20].

References [3, 6, 8, 10, 13, 21] describe the use of deterministic dynamic pro-
gramming and model predictive control to improve fuel economy. Systems that con-
trol vehicle speed based on electronic horizon have been introduced for commercial
heavy vehicle applications [5]. References [2, 14, 18] focus on stability and the
design of adaptive cruise control (ACC) systems.

Our approach to fuel efﬁcient speed control [11, 12, 16, 17] in this and in previous
publications is based on the perspective that the vehicle operating environment (e.g.,
speed of vehicle(s) in front of our vehicle in trafﬁc) is inherently stochastic due to
the uncertain nature of trafﬁc. Even though for a known route, the road topography
is known, the road grade can also be treated as stochastic if the route being traveled
is not a priori known or to avoid relying on detailed topographic information. We
model the statistics of transitions in trafﬁc speed and road grade by Markov Chain
models. With the knowledge of these statistics (e.g., speciﬁc to a certain geographic
region where the driver operates the vehicle), vehicle speed and following distance
can be optimized for best-on-average fuel economy and travel time performance
using Stochastic Dynamic Programming (SDP).

Such an SDP policy prescribes the optimal vehicle speed as a function of current
values of road grade, reference speed (“local” trafﬁc speed, lead vehicle speed or our
vehicle speed) and distance to preceding vehicle for best-on-average performance in
terms of fuel consumption and travel time in a given geographic region. The SDP
policy is generated off-line using value iterations or linear programming (along with
appropriate approximations and simpliﬁcations) and is stored for on-line use. This
approach opens up a possibility of implementing fuel efﬁcient vehicle speed control
at lower cost and complexity versus alternatives that use electronic horizon.

The previous solutions to fuel efﬁcient vehicle speed control, with possible ex-
ception of [3, 21] which focused on the application of stochastic MPC, did not treat
the vehicle operating environment as stochastic. The present chapter summarizes and
uniﬁes our results for fuel efﬁcient in-trafﬁc driving and fuel efﬁcient following of
a vehicle driving at a constant speed, provides further details, discussion, analysis,
and includes previously unreported experimental results for the fuel efﬁcient vehi-
cle following case. Because this chapter contains a summary of previous work, it
encompasses different simulations and vehicle experiments that track the evolution
of our study. Throughout this evolution, while the general approach remained the
same, tuning, settings, and models have changed because these modiﬁcations were
beneﬁcial, e.g., to improve experimental vehicle drivability.

9.2 Modeling for SDP Policy Generation

The models used for SDP control policy generation include the representations for
vehicle dynamics, the stochastic models of road grade and trafﬁc speed, and the
cost function and its separate components. The models and the optimization are all

9 Stochastic Fuel Efﬁcient Optimal Control

149

based on spatial discretization. That is, given a distance segment of length Δs, and
values of road grade, reference speed, host vehicle speed, and relative distance at the
beginning of the current segment, the models produce the values of these variables
at the start of the next distance segment.

9.2.1 Longitudinal Vehicle Dynamics

A simpliﬁed model for longitudinal vehicle dynamics has been adopted for control
policy generation. The controlled vehicle is referred to as the host vehicle, and its
velocity is denoted by v. The reference speed, vr e f , represents either the local trafﬁc
speed in the in-trafﬁc driving scenario or the speed of the preceding (lead) vehicle in
the lead vehicle following scenario. Finally, the relative distance between the vehicles
, v+, and ρ+ we denote reference vehicle speed, host vehicle
is denoted by ρ. By v
speed, and relative distance values one distance segment ahead.

+
r e f

The host vehicle speed is updated according to the following dynamic equation,

where u is a control input corresponding to an offset in the host vehicle speed relative
to trafﬁc speed at the beginning of the next trafﬁc segment. This model has been used
to generate SDP policies for our simulation case studies of fuel efﬁcient in-trafﬁc
driving and lead vehicle following.

For in-vehicle experiments, we replaced (9.1) with an alternative model,

v+ = vr e f + u,

v+ = v + u,

where u is a control input corresponding to an offset in the host vehicle speed at
the next distance segment relative to the host vehicle speed at the previous distance
segment. The use of model (9.2) resulted in better drivability of the experimental
host vehicle.

An approximate model for relative distance dynamics is deﬁned by

where

ρ+ = ρ + (v+ − v)ΔT,

ΔT =

2Δs
+ vr e f

,

+
v
r e f

is (approximately) the time to travel the road segment of length Δs. We use Δs = 30
m to generate control policies in our simulation case studies. To provide faster control
updates and improve experimental vehicle safety, we reduced Δs to 15 m when
generating control policies for the vehicle experiments.

(9.1)

(9.2)

(9.3)

(9.4)

150

K. McDonough et al.

In both the experimental vehicle testing and the computer simulations, we pro-
vided a set point speed, v+, to existing speed controllers and relied upon these existing
controllers to execute the necessary changes in speed.

9.2.2 Stochastic Models of Reference Speed and Road Grade

Transitions in reference speed and road grade are modeled using Markov Chains.
Transition probabilities are deﬁned for changes in reference speed and road grade
over a road segment of length Δs,

P(v

+
r e f

|vr e f ), P(θ+|θ),

(9.5)

with values of vr e f and θ quantized to values on a discrete grid, vr e f ≤ {0, 1, . . . , 36}
m/s,

θ ≤ {−6, −5, . . . , 5, 6} %.

The identiﬁcation of the transition probabilities has been performed from 16 data
sets collected on-board of an experimental vehicle. The vehicle has been driven along
a route on and around M-39 (mixed highway and city driving), in northbound and
southbound directions, during different times of day (in rush hour trafﬁc and off-peak
hours trafﬁc) and with the driver emulating two different driving styles (‘smooth’
and ‘aggressive’). Transition probability models have been identiﬁed using

P(x j | xi ) ∈

Nxi ,x j
Mxi

,

(9.6)

where P(x j|xi ) is the approximate probability of transition of a variable x ≤ {vr e f , θ}
from a discrete state xi to state x j , Nxi ,x j is the number of transitions from state xi
to state x j observed in the data, and Mxi is the total number of transitions out of
state xi . Figure 9.1 illustrates the transition probability matrices learned based on
one of the data sets. Note the near diagonal character of the model suggesting that
= vr e f and θ+ = θ,
continuing with the same reference speed and grade, i.e., v
is most likely. On the right side of Fig. 9.1 we observe more off-diagonal entries at
lower vehicle speeds as it takes longer in time for the vehicle to travel the distance
segment and thus more time is available to accelerate to different speeds.

+
r e f

Assuming that θ and vr e f are independent, it follows that

P(θ+, v

+
r e f

|θ, vr e f ) = P(v

+
r e f

|vr e f )P(θ+|θ).

(9.7)

Remark 1 For the in-trafﬁc driving, we ultimately advocate a multi-model approach
where several transition probability models (TPMs) and SDP policies are developed
for different trafﬁc types (e.g., rush hour trafﬁc versus off-peak hour trafﬁc) and
road types. A Kullback-Liebler (KL) divergence can be used to establish similarity
between currently observed transition probabilities and transition probability models

9 Stochastic Fuel Efﬁcient Optimal Control

151

|

)
θ
+
θ
(
P

1
0.8
0.6
0.4
0.2
0

+

)

Vt

|

Vt
(
P

1
0.8
0.6
0.4
0.2
0

15

10

5

θ +

30

20

10

+
Vt

0

2

4

6

0

10

12

8
θ

0

5

10 15 20 25 30 35

0

Vt

Fig. 9.1 A surface plot of grade (left) and reference vehicle speed (right) transition probabilities

that have been stored and for which the corresponding SDP policy is available. The
SDP policy for the best matching TPM is then switched to for the on-board use.
References [9, 15] discuss an evolving models approach where multiple models are
generated to cover the drives of interest. However, [9, 15] do not generate SDP
policies.

9.2.3 Cost Function Constituents

The SDP problem uses an incremental cost function of the general form,

R = ¯W f + λ ¯Tt + φ(ρ),

(9.8)

where the constituents are the expected fuel consumption, ¯W f , over the segment of
length Δs, the expected segment travel time, ¯Tt , and the distance constraint violation
penalty, φ(ρ). The subsequent formulations of the SDP problem for the in-trafﬁc
driving use (9.8) with φ(ρ) = 0. The constituents of the cost function are now
discussed.

9.2.3.1 Fuel Consumption

The general model for the fuel ﬂow is of the form,

W f = W f (v, v+, θ, θ+),

(9.9)

where v and θ are the vehicle speed and the road grade, respectively, at the beginning
of the current road segment of length Δs, while v+ and θ+ are the vehicle speed and
road grade, respectively, at the beginning of the next road segment of length Δs.

For the simulation case studies, the model (9.9) has been developed based on a

single hidden layer neural network and has the form,

152

x10−3

Training Data

K. McDonough et al.

Data

NN Output

4700

4800

4900

5000

5100

5200

5300

x 10−3

Simulation Point [ ]

Testing Data

]
g
k
[
 
n
o
i
t
p
m
u
s
n
o
C

 
l
e
u
F

]
g
k
[
 
n
o
i
t
p
m
u
s
n
o
C

 
l
e
u
F

6

4

2

0

4

3

2

1

0

4850 4900 4950 5000 5050 5100 5150 5200 5250
Simulation Point [ ]

Fig. 9.2 Example of the training and testing data for the neural network model of the fuel ﬂow
based on CARSIM data. Note only a small sample of the 7,000 data points was selected in each
plot for clarity

W f = σ2(w2σ1(w1unn + b1) + b2),

(9.10)

where σ1 and σ2 are the hyperbolic and linear activation functions, respectively; w1
and w2 are the corresponding vectors of weights; b1 and b2 are the corresponding
vectors of biases; and unn = (v, v+, v+ − v, θ, θ+)T is the model input vector.
Using the trainbr function in MATLAB neural network toolbox, the neural network
was trained using Bayesian regularization back propagation applied to 16 vehicle
drives replicated in CARSIM environment. Roughly 14,000 data points were used
to generate the neural network −7,000 to train and 7,000 to test. See Fig. 9.2.

For the experimental vehicle testing, a physics-based fuel consumption model
representative of the 2007 Ford Edge experimental vehicle has been used. Note that
both models account for gear shifts and torque converter lock/unlock events.

The expected value of fuel consumption used in the incremental cost function

(9.8) has the form

¯W f = Ev+,θ+ [W f (v, v+, θ, θ+)].

(9.11)

9.2.3.2 Travel Time

The travel time of a road segment of length Δs can be approximated as

153

(9.12)

(9.13)

(9.14)

(9.15)

9 Stochastic Fuel Efﬁcient Optimal Control

The expected value of travel time used in the incremental cost function (9.8) has the
form,

9.2.3.3 Distance Constraint Penalty

The penalty function for the distance constraint violation in (9.8) has one of the
following forms. The ﬁrst form,

Tt (v, v+) = 2Δs
v + v+

.

¯Tt = Ev+[Tt (v, v+)].

φ(ρ) =

⎧
⎪⎨

⎪⎢

κ
κ

0

if ρ > ρmax ,
if ρ < ρmin,
else,

was used for the simulations while the second form,

φ(ρ) =

⎧
⎪⎨

⎪⎢

(κeρ−ρmax − κ)
(κeρmin−ρ − κ)
0

if ρ > ρmax ,
if ρ < ρmin,
else,

was used for in-vehicle experiments. In the above, [ρmin, ρmax ] is the desired interval
in which the distance is to be maintained and κ > 0 is a parameter. The value of
κ = 10 has been used to generate SDP policies for fuel efﬁcient vehicle following
for both simulations and experiments. Values of ρmin = 3 m and ρmax = 10 m have
been used for the simulations with (9.14) while values of ρmin = 5 m and ρmax = 15
m have been used for the vehicle experiments using (9.15). A switch was made from
(9.14) to (9.15) in order to eliminate discontinuities within the cost function.

We note that the minimum distance constraint is imposed to prevent host vehicle
colliding with another vehicle in front, while the maximum distance constraint is
imposed to improve driving comfort and reduce the impact of the host vehicle actions
on the ﬂow of trafﬁc around it. We do not attempt to take advantage of drag reduction
in close following even though in principle such a possibility can be realized by
prescribing a small value for ρmax . We also do not attempt to use asymmetric penalty
factors in (9.14) or (9.15) and equally weight both relative distance extremes as both
extremes are important for the safety of the host vehicle and surrounding trafﬁc.

154

K. McDonough et al.

9.3 Stochastic Dynamic Programming

SDP is used to generate best-on-average control policies. For the incremental cost
(9.8), the stochastic optimal control problem that SDP solves is of the form

J = E

qk R(v(k), θ(k), ρ(k))

(9.16)

⎡

∞⎣

k=0

⎤

≈ min
u≤U

,

subject to the model in Sect. 9.2 where 0 ≡ q < 1 is a discount factor introduced
to guarantee that the cost is ﬁnite and the set U denotes the set of feasible control
values. In (9.16), the value of q = 0.96 in order to approximate the average cost.

We use the value iteration approach [1] to solve the SDP problem. Under the
standard assumptions, the following iterations converge, as n ≈ ∞, to the value
function V ≥(vr e f , v, θ, ρ),

Vn+1(vr e f , v, θ, ρ) = minu≤U Qn(vr e f , v, θ, ρ, u),

⎣

Qn(vr e f , v, θ, ρ, u) =

R(vr e f , v, θ) +

θ+, v

+
r e f q Vn(v

+
r e f

, v+, θ+, ρ+)P(v

+
r e f

, θ+ | vr e f , θ),

V0(vr e f , v, θ, ρ) = 0.

(9.17)

The value iterations are performed numerically using standard gridding and linear

interpolation techniques.

9.4 Simulation Case Studies

To quantify the fuel economy beneﬁts of the SDP approach, simulation case stud-
ies were implemented in a simulation environment based on CARSIM and Mat-
lab/Simulink. We used CARSIM to emulate a trafﬁc analog vehicle that replicates
the data collection drives of our experimental vehicle. We also implement in CARSIM
the host vehicle responding to control inputs generated by SDP policy executed in
Simulink. The SDP policy was generated to prescribe the offset relative to reference
speed in (9.1),

u ≤ {−3, −2, −1, 0, 1, 2, 3} m/s.

The metrics used to evaluate the results are the percent mpg improvement and

percent difference in average vehicle speed. They are deﬁned by

%mpgimp = mpgh − mpgt

mpgt

× 100, %vdi f f =

× 100,

(9.18)

¯vh − ¯vt
¯vt

9 Stochastic Fuel Efﬁcient Optimal Control

155

]

%

[
 
t
n
e
m
e
v
o
r
p
m

I
 

G
P
M

 
t
n
e
c
r
e
P

12

10

8

6

4

2

0

−2

−4

0.5

0

−0.5

−1

−1.5

−2

−2.5

]

%

[
 
d
e
e
p
S
 
n
i
 
e
g
n
a
h
C

 
t
n
e
c
r
e
P

−3

0

0

2

8

6

4
Simulation Number []

10

12

14

16

18

5

10

15

Simulation Number []

Fig. 9.3 Left the percent fuel economy increase for the in-trafﬁc driving case study in the non-
porous trafﬁc case. Right the percent change in average speed

where mpgt , ¯vt are, respectively, the fuel economy and the average speed of the trafﬁc
analog vehicle, while mpgh, ¯vh are, respectively, the fuel economy and the average
speed of the host vehicle. Positive values in %mpgimp indicate the fuel economy
improvements of the host vehicle and positive values in %vdi f f faster average speed
of the host vehicle sersus the trafﬁc analog.

9.4.1 In-trafﬁc Driving

For the in-trafﬁc driving, vr e f = vt . The value of the weight λ = 0.002 in (9.8) was
chosen after some tuning. We assumed φ(ρ) ∗ 0 in (9.8) at the stage of generation
of SDP policies. As a result, the SDP policy became independent of the relative
distance, ρ, which simpliﬁed its ofﬂine computation and online implementation.
When evaluating this SDP policy, two case studies of non-porous trafﬁc and porous
trafﬁc were considered.

9.4.1.1 Non-porous Trafﬁc

In the non-porous trafﬁc case, the host vehicle was not able to pass the trafﬁc analog
vehicle and the brakes would be activated in the simulation to ensure there was no
collision. The non-porous trafﬁc represented the worst case for the evaluation of SDP
policy. The results based on our 16 drives are summarized in Fig. 9.3. For the non-
porous trafﬁc case, the average improvement in mpg is 2.97 % with an average drop in
average speed of 0.78 %. Slight positive values of the average speed difference on the
right of Fig. 9.3 for some of the drives indicate that the host and travel analog vehicles
ended up closer together at the end of the simulation than when the simulation was
started.

156

K. McDonough et al.

]
h
p
m

[
 
d
e
e
p
S
 
e
l
c
i
h
e
V

70

60

50

40

30

20

10

0

0

Traffic
Host

200

400

800

1000

1200

600
Time [s]

Fig. 9.4 The time histories of trafﬁc analog (dotted) and host vehicle (solid) speeds for the simu-
lation 6 in the non-porous trafﬁc case

Figure 9.4 compares the vehicle speed time history of the trafﬁc analog vehicle
and host vehicle for drive 6 where the largest fuel economy improvement has been
observed. The speed of the host vehicle with the SDP policy has fewer and smaller
abrupt changes and an overall “smoothed-out” character, especially for large acceler-
ations and decelerations. This conclusion is also conﬁrmed by examining the vehicle
speed traces for other drives.

9.4.1.2 Porous Trafﬁc

In the porous trafﬁc case, the host vehicle is able to follow the SDP policy freely
passing or being passed by the trafﬁc analog vehicle if needed. This case is consistent
with the cost function used for SDP policy generation and represents the best case
scenario. The results based on our 16 drives are shown in Fig. 9.5. For the porous
trafﬁc case, the SDP policy achieved simultaneous improvement in mpg (average
improvement is 5.67 %) and an increase in average speed (average increase is 5.38 %).
Note that in the non-porous trafﬁc case, the average speed for many of the simu-
lations is lower than the trafﬁc analog. Though one can argue that some of the fuel
economy improvement can, in principle, be due to this reduction, it is clear from
the porous trafﬁc case results show that simultaneous increases in average speed and
fuel economy are also feasible.

9 Stochastic Fuel Efﬁcient Optimal Control

157

]

%

[
 
t
n
e
m
e
v
o
r
p
m

I
 

G
P
M

 
t
n
e
c
r
e
P

18

16

14

12

10

8

6

4

2

0

]

%

[
 
d
e
e
p
S
 
n
i
 
e
g
n
a
h
C

 
t
n
e
c
r
e
P

11
10
9
8
7
6
5
4
3
2
1
0

0

2

6

4
8
Simulation Number [ ]

10

12

14

16

0

2

6

8

4
Simulation Number [ ]

10 12 14 16 18

Fig. 9.5 Left The percent fuel economy increase for the in-trafﬁc driving case study in the porous
trafﬁc case. Right The percent change in average speed

Table 9.1 Fuel economy improvement broken down between trafﬁc conditions and trafﬁc type

Percent improvement in mpg

Trafﬁc condition

Rush hour
Rush hour
Off-peak
Off-peak

Trafﬁc type

Porous
Non-porous
Porous
Non-porous

8.98
2.20
2.39
3.73

9.4.1.3 Rush Hour Versus Off-peak Trafﬁc Conditions

Table 9.1 compares the average results over rush hour simulations (drives 1, 2, 5,
6, 9, 10, 13, 14) and off-peak trafﬁc conditions (drives 3, 4, 7, 8, 11, 12, 15, 16).
In both the porous and non-porous cases, the fuel savings, as compared to the lead
vehicle, come from smoothing the accelerations and a reduction in the amount of
vehicle braking. This observation is consistent with the results that in the non-porous
case the host vehicle performs better than trafﬁc during off-peak times while in the
porous case the host vehicle does better during rush-hour times.

9.4.2 Optimal Vehicle Following

We consider next the vehicle following scenario, where the host vehicle follows,
without passing, the lead vehicle that is driven at a constant speed, vr e f , where
vr e f ≤ {45, 50, 55, 60} mph. For this case, separate SDP policies with φ(ρ) ⇐= 0
in (9.15) and λ = 0.0012 in (9.8) were generated for each of four values of vr e f .
Furthermore, the cases of uniformly zero grade along the route and non-zero grade
modeled stochastically, as discussed in Sect. 9.2.2, were considered separately. The
SDP policies are functions of ρ, v, and θ (in the non-zero grade case) and prescribe

158

K. McDonough et al.

With Grade
Zero Grade

]

%

[
 
t
n
e
m
e
v
o
r
p
m

I
 

G
P
M

 
t
n
e
c
r
e
P

20

18

16

14

12

10

8

6

4

2

0

45

50

55

60

Simulation Traffic Speed [mph]

Fig. 9.6 Fuel economy improvement with SDP policies. The blue (ﬁrst) set of bars are for the
non-zero grade policies and the red (second) set of bars are for zero grade

the offset u in (9.1). Note that the zero grade policies are basically deterministic
policies. The zero grade policies were simulated assuming zero grade while the non-
zero grade policies were simulated with the grade proﬁle recorded over the same
route as in Sect. 9.2.2.

The fuel economy is improved with SDP policies, see Fig. 9.6. This improvement
is attributed to Pulse-and-Glide behavior (oscillation) of the host vehicle speed in-
duced by the SDP policies, see Figs. 9.7 and 9.8. The Pulse-and-Glide behavior has
been observed in both non-zero grade (Fig. 9.7) and zero grade (Fig. 9.8) simulated
drives. The sharp acceleration slope and more gradual deceleration (coasting) slope
in non-zero grade simulation become more regular in the zero grade case. The fuel
ﬂow during sharp acceleration (pulse) exceeds fuel ﬂow of the lead vehicle, but is
less during the deceleration (coasting) phase. This results in a lower overall fuel con-
sumption, seen in the right side of both Figs. 9.7 and 9.8 of the host vehicle compared
to the lead vehicle. Due to the distance constraint, average vehicle speeds of the host
and lead vehicles are nearly the same.

The fuel improvement mechanism of Pulse-and-Glide differs from that of accel-
eration smoothing. The acceleration smoothing limits the magnitude of the acceler-
ations based on prediction of the lead vehicle velocity. It keeps the host vehicle from
braking as much as trafﬁc, potentially also avoiding unnecessary downshifts and
torque converter unlocks. With Pulse-and-Glide, the lead vehicle is assumed to be at
a constant and known speed, and the control policy takes advantage of differences
in efﬁciency between operating points in the engine map, and of efﬁciently executed
transients, to reduce fuel consumption.

9 Stochastic Fuel Efﬁcient Optimal Control

159

]
h
p
m

[
 
d
e
e
p
S
 
e
l
c
i
h
e
V

]
h
p
m

[
 
d
e
e
p
S
 
e
l
c
i
h
e
V

60

58

56

54

52

50

48

59

58

57

56

55

54

53

52

51

50

200

250

350

400

300
Time [s]

5

10

15
Distance Traveled [km]

20

25

30

Fig. 9.7 Left time history of lead vehicle speed (dashed) and host vehicle (solid) for a part of the
drive with non-zero grade. Right fuel consumption versus distance traveled of lead vehicle speed
(dashed) and host vehicle (solid)

Traffic
Host

1.5

1

0.5

]
g
k
[
 

d
e
m
u
s
n
o
C

 
l
e
u
F

0

0

1.5

1

0.5

]
g
k
[
 

d
e
m
u
s
n
o
C

 
l
e
u
F

0

0

Traffic
Host

Traffic
Host

Traffic
Host

200

250

350

400

300
Time [s]

5

10

15
Distance Traveled [km]

20

25

30

Fig. 9.8 Left time history of lead vehicle speed (dashed) and host vehicle (solid) for a part of
the drive with zero grade. Right fuel consumption versus distance traveled of lead vehicle speed
(dashed) and host vehicle (solid)

9.5 Vehicle Experiments

The experimental testing of fuel efﬁcient vehicle following was performed in a 2007
Ford Edge. The tests were performed along the M-39 highway portion of the same
route used for data collection in Sect. 9.2.2. We bypassed the vehicle speed set-
point fed to the vehicle cruise controller with the output of SDP policy running on
a dSPACE RTI 1005 board. The testing was restricted to vehicle speed following
scenario, where the lead vehicle driving at a constant speed was implemented as a
virtual vehicle (in software) while the host vehicle was the experimental vehicle.
This implementation permitted testing with a single available vehicle which did not
have a radar nor ACC. The vehicle was driven over the same route twice whenever
testing was performed, once with the regular cruise control and then with the SDP

160

K. McDonough et al.

policy. This was done in order to reduce errors due to day-to-day ﬂuctuations in fuel
economy.

After preliminary testing, to improve driving comfort we regenerated the SDP
policies to prescribe the offset to the current host vehicle speed (see (9.2)) rather than
to the lead vehicle speed, vr e f , and restricted the offset values to a small range u ≤
{−2, 0, 2} mph to prevent large speed change requests. We additionally constrained
u by adding to U the constraint 50 ≡ v + u ≡ 60. We used λ = 0.0012 in the cost
(9.8) as this value improved vehicle drivability.

Over 12 drives on M-39 (half in northbound and half in southbound direction) with
vr e f = 54 mph, the average fuel economy improvement is 4.51 % with a maximum
of 11.58 % and a minimum of −3.28 %. The maximum and minimum were observed
on the same day during which there was a strong wind that may have skewed the
results. Without these outliers, the average fuel economy improvement is 5.38 %.

Figure 9.9 shows the results of vehicle experiments for one of the drives. An
oscillating pattern, representative of Pulse-and-Glide, clearly emerges in the exper-
imental vehicle speed. The difference in the character of the response is attributed
to changes in SDP problem formulation that we made to improve vehicle drivability
and to the slow and asymmetric (between acceleration and deceleration) response
of the nominal cruise controller to the set-point provided by the SDP policy. Also
due to the nominal cruise controller response (unmodelled at the stage of generating
SDP control policies), the average speed of the host vehicle ended up below the
lead vehicle average speed. The distance ρ computed by a limited integrator in our
implementation was thus saturated at the upper bound, ρmax , during the tests.

The average speed difference over all 12 drives is −1.95 mph. To account for the
increased fuel economy due to a lower average speed, test drives were performed
using the standard cruise control set to 50, 52, and 54 mph in order to build a
relationship between a reduction in average speed and increase in fuel economy.
The resulting relationship is, on average, a 0.49 % reduction in fuel consumption for
every percent drop in average speed. This results in a corrected fuel consumption
improvement of 2.74 % when considering all of the tests and an improvement of
3.61 % when not considering the outliers.

9.6 Concluding Remarks

Fuel economy can be improved by optimal control of vehicle speed. One approach to
developing such a speed controller, that does not use an electronic horizon of preview
information, is through the stochastic modeling of trafﬁc and terrain, and through
the application of stochastic optimal control. The chapter provided a demonstration
of this approach and showed that stochastic dynamic programming based policies
can improve fuel economy through the mechanisms of smoother accelerations in
in-trafﬁc driving scenarios and through Pulse-and-Glide when following another
vehicle moving at a constant (or nearly) constant speed. While these fuel economy
improvement mechanisms have been discussed in previous literature, it is interesting

9 Stochastic Fuel Efﬁcient Optimal Control

161

56

55

54

53

52

51

50

49

48

]
h
p
m

[
 
d
e
e
p
S
 
e
l
c
i
h
e
V

Traffic
Host

0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0

]
l
a
g
[
 
d
e
m
u
s
n
o
C

 
l
e
u
F

0

100 200 300 400 500 600 700 800

0

Time [s]

4

2
6
Distance Traveled [miles]

8

10

12

Fig. 9.9 Left time history of vehicle speed from vehicle testing. Right cumulative ﬂow of the host
vehicle (solid) versus lead vehicle (dashed)

that they also emerge in the process of solving a stochastic optimal control problem.
The simulation and experimental results in the chapter provide a quantiﬁcation of
the beneﬁts that can be achieved with this approach.

For the in-trafﬁc driving, the smoothing of accelerations can be viewed as a way
to eliminate aggressive driver behaviors that are detrimental to fuel economy. In the
case of vehicle following, the lead car is not exhibiting any aggressive behaviors
and thus the optimization exploits a Pulse-and-Glide mechanism. Consequently, the
results of our case studies are not contradictory.

Much room remains for further research. This includes further vehicle experiments
and beneﬁt quantiﬁcation in relation to existing Adaptive Cruise Control (ACC)
systems. The issue of acceptability of Pulse-and-Glide type policies also requires
further study in terms of customer and trafﬁc ﬂow impact. Our experience in the
experimental vehicle suggests that driving comfort can be improved to a level that
can be acceptable to some customers, and the impact on trafﬁc ﬂow can be minimized
by a judicious choice of the cost and constraints.

We note that we have not pursued the development of a policy for in-trafﬁc driving
with a distance constraint because such a policy depends on more state variables
and due to the curse of dimensionality is more complex to generate and store. The
development of such a comprehensive policy is left to future work.
Abstract Impressive improvements of efﬁciency and safety of vehicles have been
achieved over the last decade, but increasing trafﬁc density and drivers’ age accentu-
ate the need of further improvements. The contributions summarized in this chapter
argue that a substantial additional fuel beneﬁt can be achieved by extending the well
introduced Adaptive Cruise Control in a predictive sense, e.g. taking into account
a predicted behavior of other trafﬁc components. This chapter starts by discussing
results on the potential beneﬁts in the ideal case (full information, no limits on com-
puting power) and then examines how much of the potential beneﬁts is retained
if approximate solutions are used to cope with a realistic situation, with limited
information and computing power. Two setups are considered: vehicles exchang-
ing a small set of simple data over a V2V link and the case of mixed trafﬁc, in
which some vehicles will not provide any information, but the information must
be obtained by a probabilistic estimator. The outcome of these considerations is that
the approach is able to provide—statistically—a substantial fuel consumption beneﬁt
without affecting negatively the driveability or the driver comfort like other methods,
e.g. platooning, would.
Classical vehicle design aims to fulﬁll the needs of a wide variety of potential drivers
in a wide variety of situations. While emissions and fuel consumption are deter-
mined under very well deﬁned test conditions, actual consumptions and emissions
arise from the operation of generic drivers under generic conditions. Different driver
styles are known to affect very strongly the fuel consumption [1]. Advanced Driving
Assistance Systems (ADAS) and autonomous vehicles can do more than support
a different driving style, i.e. take a fuel optimal decision in real time considering
several boundary conditions. This chapter shows that this idea—which can be seen
as a seamless extension of normal adaptive cruise control (ACC)—offers a high fuel
beneﬁt potential. It can be realized with different degrees of complexity and can be
used both in a connected trafﬁc or—with some performance reduction—in a mixed
trafﬁc environment with high predictability and comfort.

The driving force behind the development of ADAS has clearly been safety, as
in the case of anti-lock brake systems (ABS), ﬁrst developed in 1929 for airplanes,
followed by traction control, electronic stability programs (ESP) and brake assistants
and many more (see [2] for an overview). Some ADAS have an impact on energy
efﬁciency, in particular the Cruise Control (CC), which enforces a constant driving
speed, and ACC [3–6], which additionally enforces a safe headway.

Recently, the focus has been extended to Cooperative ACC (CACC) [7–10] made
possible by modern communication possibilities. Still, the focus is mainly safety, at
the level of single vehicles, or fuel consumption, at the trafﬁc level, by preventing
jams, scheduling gear shifts etc. Some works have also addressed fuel efﬁciency, see.
e.g. in [7] for a Model Predictive Control (MPC) solution or [3] for a Pulse and Glide
(PnG) algorithm for a continuous variable transmission. Stochastic trafﬁc models
have been examined in [11] and applied to stochastic DP [12, 13].

This chapter focuses on the minimization of fuel consumption in moderate, non-
congested trafﬁc typical of a commuter travel. Computations and measurements are
done on the basis of the available test car and engine (BMW320d and N47).

10.2 Problem Statement

We consider the speed control of a vehicle with a target speed vr e f in a multi vehicle
scenario in which it has to cope with other vehicles with an own speed proﬁle, in
particular with a preceding one which acts as a disturbance, as shown in Fig. 10.1.
We shall assume the controlled car to be equipped with some distance measurement
device, e.g. radar. For simplicity, we shall not consider lane or gear changes. In this
case, the related problem can be stated intuitively as

10 Predictive Cooperative Adaptive Cruise Control

165

Fig. 10.1 Considered scenario, V2V communication is advantageous but optional

min
a(t)

Q f,T = min
a(t)

q f (v(t), a(t)) dt,

(10.1)

1
T

T(cid:2)

0

where q f is the current fuel consumption depending on the vehicle’s speed v(t) and
acceleration a(t), T the observation time, all other conditions assumed to be equal
(path, temperature, pressure, humidity etc.).

10.2.1 Casting the Problem into the Mathematical Form

The basic dynamic equations of two vehicles moving within a string are given in the
simplest form by

Δ ˙x = v p − v
˙v = a

(10.2)

where v p is the velocity of a disturbing, preceding vehicle, a the acceleration and
Δx > 0 the inter-vehicle distance.

Fuel consumption of a Diesel engine can be approximated by a static map depend-
ing on the engine torque and the rotational engine speed or accordingly on vehicle
acceleration and vehicle speed, as shown in Fig. 10.2. The transient fuel consumption,
not covered by the static map,adds typically about 4 % [14]. Boundary conditions
can be derived by additional requirements.

A minimum distance is needed to prevent rear-end crashes. In [15] a historical
review on car following models and their underlying spacing policies is given and
in [16] collision avoidance capabilities of spacing policies are discussed.The most
common spacing policy used, e.g. in [10], is linearly depending on the vehicle speed v

Δx ≥ Δxmin,0 + hminv.

(10.3)

166

D. Lang et. al

BSFC −Vehicle Speed −Vehicle Acceleration, gear:3

original data
Interpolated map
max. acceleration

 
 

C
F
S
B

]
h
/
g
k
[

60

40

20

0
0

20

40

Vehicle Speed
[m/s]        

60 −2

0

2

V e hicle A c c eleratio n

2 ]             

[ m /s

Fig. 10.2 Interpolated map of static fuel consumption, ﬁxed gear, BSFC means brake-speciﬁc-
fuel-consumption, q f

where Δxmin,0 denotes the minimum inter-vehicle distance at stand still and hmin
is the time-headway. Maximum distance is not a typical boundary condition, as, if
the distance is large enough, both ACC and CACC would work as a standard CC.
However, in congested trafﬁc it seems advisable to limit this quantity to prevent loss
of road capacity (and also to reduce frequency of third vehicle entering in the space
between the actual vehicle and the predecessor). A maximum inter-vehicle distance
is enforced by the constraint

Δx ≤ Δxmax,0 + hmax v,
vP ≥ vr e f

v = vr e f ,

vP < vr e f

(10.4a)

(10.4b)

considering the case that the speed of the preceding vehicle exceeds the reference
speed, Δxmax,0 being the maximum distance at stand still and hmax the time headway
coresponding to the maximum inter-vehicle distance.

Additional boundary conditions have to be included to respect system inherent
limitations like maximum accelerating or decelerating power as well as maximum
and minimum speed of the vehicle

where amax and amin are the speed dependent maximum and minimum acceleration
and vmax and vmin denote the velocity limits of the vehicle.

Combining all this leads to the nonlinear optimization problem

amin(v) ≤ a ≤ amax (v)
vmin ≤ v ≤ vmax

T(cid:2)

0

min
a(t)

(cid:2)
(cid:3)
q f (v(t), a(t))

dt

(10.5a)
(10.5b)

(10.6a)

10 Predictive Cooperative Adaptive Cruise Control

167

Table 10.1 Potential fuel beneﬁts with respect to a preceding vehicle assuming perfect knowledge
of the future

Floating margin (m)

Potential fuel beneﬁts (%)

10

9.2

20

14.7

30

18.3

40

20.2

50

22.1

60

23.9

70

24.4

80

25.7

s.t.

˙Δx(t) = v p(t) − v(t)

˙v(t) = a(t)

Δxmin,0 + hminv(t) ≤ Δx(t) ≤ Δxmax,0 + hmax v(t)
amin(v(t)) ≤ a(t) ≤ amax (v(t))
vmin ≤ v(t) ≤ vmax

(10.6b)

Several other constraints can be introduced to ensure ride comfort and the acceptance
by a human driver, for example limitations of acceleration or jerk.

10.3 Assessment of Potential

This nonlinear optimization problem cannot be solved in real time, but an approx-
imate off-line numerical evaluation is possible in order to ascertain the potential
of the method, providing the problem is simpliﬁed by discretization in time (see
[22] for details). For this evaluation, we assume the preceding vehicle to follow a
trajectory as in the FTP-75 (between 640 and 1,140 s) shifted by 24 km/h to bet-
ter approximate a commuter trafﬁc situation (assuming no jams). The behavior of
the controlled vehicle l is shown in Fig. 10.3, in which the bottom subplot depicts
the speed proﬁle of the preceding vehicle, as well as the fuel optimal speed proﬁle
while the top graph illustrates the corresponding inter-vehicle distance. The optimal
behavior corresponds to the expectations, the controlled vehicle uses the information
on the future speed proﬁle of the preceding vehicle to smooth its own speed proﬁle
by ﬂoating between a minimum and maximum bound. A ﬂoating margin of 20 m
leads to a fuel consumption reduction of approximately 14.7 % with respect to the
preceding vehicle. As portrayed in Table 10.1, the results show a strong dependency
on the allowed ﬂoating margin.1 The setup can be extended to a string of vehicles.
Figure 10.4 portrays the speed proﬁles of a string consisting of vehicles. As
expected, a further reduction in acceleration and deceleration maneuvers towards the
rear of the string is clearly visible. The effect on fuel economy is shown in Table 10.2.

1 maximum–minimum allowed distance.

168

D. Lang et. al

Fig. 10.3 The typical behavior of the optimized following vehicle. The optimized speed proﬁle
of the succeeding vehicle is essentially smoothed and is ﬂoating between minimum and maximum
inter-vehicle distance

Table 10.2 Potential fuel beneﬁts with respect to a predecessor in a string of vehicles assuming
perfect knowledge of the future (ﬂoating margin = 20 m)

Vehicle position in string

Potential fuel beneﬁts (%)

2

14.7

3

23.4

4

28

5

31.3

6

32.9

7

33.4

10.4 Nonlinear Receding Horizon Optimization

The results shown in the preceding section hint at a large available potential, but
of course the implicit assumption of perfect knowledge of the future speed proﬁle
of the predecessor is not realistic. Also on-line solution of the problem with a very
high number of manipulated variables (500) seems out of question for some time.
However, Table 10.1 shows that the potential fuel beneﬁts approaches a saturation
for increasing ﬂoating margin, so that we might expect something similar as far as
the optimization time is concerned.

So we consider addressing the problem by a moving horizon strategy, as done in
model predictive control (MPC), see e.g. [18, 19]. Indeed, in MPC, only a relatively
short horizon is considered, thus a short string of values of the manipulated variables is

10 Predictive Cooperative Adaptive Cruise Control

169

Fig. 10.4 Speed proﬁles of a string of vehicles (vehicle 1: string leader, vehicles 2–7: controlled
vehicles)

Table 10.3 Comparison of potential fuel beneﬁts (ﬂoating margin = 40 m)

Prediction horizon

Potential fuel beneﬁts (%)

5 s

2.8

10 s

12.3

15 s

17.1

20 s

18.6

30 s

19.2

40 s

19.7

unlimited

20.2

computed, but only the ﬁrst value is really used. At the next time step, the optimization
is repeated. Although it is well known that the strategy does not necessarily lead to
the optimal solution it is usually accepted as a sensible approximation. Figure 10.5
presents the dependency of the achieved fuel consumption beneﬁt on the length of the
ﬁnite prediction horizon for different margins using a nonlinear solver of the receding
time version of the original problem. As expected, the same saturation occurs not
only in terms of ﬂoating margin, but also in terms of prediction time, albeit with
some cross dependency. Table 10.3 compares some of the obtained results to the
optimal solution depicted in Table 10.1. As the prediction horizon becomes longer,
the potential beneﬁts converge to the optimal values.

The impact of the ﬂoating margin on trafﬁc capacity is shown in Fig. 10.6 for an
average average vehicle length of 4 m. As expected, the trafﬁc capacity decreases
with increasing ﬂoating margin, see Fig. 10.7.

10.5 Approximate Control Law Within the Linear MPC

Framework

While the solution of the preceding section is already easier to implement than
ﬁrst one a further computational simpliﬁcation can be obtained by using the linear
MPC framework, using local linearizations as proposed in [20]. Figure 10.8 shows

170

D. Lang et. al

Fig. 10.5 Dependency of the achieved fuel consumption beneﬁt on the length of the ﬁnite prediction
horizon for different margins

Fig. 10.6 Trafﬁc capacity with respect to the prediction horizon

the behavior of the MPC-CACC with respect to the preceding vehicle, comparing
speed and acceleration with a prediction horizon of 20 s and a control horizon 10 s.
All together the behavior of the MPC-CACC resembles the behavior and ﬁndings
presented by Sect. 10.3. The corresponding values of fuel beneﬁt and the inﬂuence of
different prediction horizon, are presented in Table 10.4. As expected, fuel beneﬁts
increase in a string, but converge also to a limit after a few vehicles as shown in
Table 10.5. The effect of ﬂoating margin is quite similar to those of Fig. 10.5.

10 Predictive Cooperative Adaptive Cruise Control

171

Fig. 10.7 Trafﬁc capacity with respect to the provided margin

Table 10.4 Comparison of average fuel consumption and beneﬁt of MPC-CACC with different
prediction horizons

Preceding
vehicle

MPC-CACC
PH = 5

PH = 10

PH = 15

PH = 20

l/100 km
Relative fuel beneﬁt in (%)
Average capacity in vehicles/min
Average capacity in (%)

4.71

4.19
11.04
20.16
92.7

3.95
16.14
20.8
105.0

3.85
18.28
25.62
117.9

3.85
18.27
26.16
120.3

Table 10.5 Comparison of average fuel consumption and beneﬁt of MPC-CACC within a string
of vehicles

Vehicle

l/100 km
In-line beneﬁt in (%)

Preceding
vehicle

4.71

Following vehicle #
1

2

3.85
18.27

3.61
6.18

3

3.49
3.28

4

3.45
1.16

5

3.42
0.95

10.6 Approximate Control Law Utilizing an Identiﬁed

Hammerstein–Wiener Model

There is growing interest in applying MPC on more automotive issues, and pro-
gresses in algorithms and computational power make this choice the longer the more
realistic [21]. However, for practical applications a further approximation level may
be interesting based on the design of a ﬁxed network whose output mimicries the
behavior of the optimal control without the corresponding computational burden.

172

D. Lang et. al

Fig. 10.8 Inter-vehicle distance including constraints and vehicle speed

Indeed, the optimal controller uses the velocity of the preceding vehicle vP as
input and delivers the optimal speed as output. If we use this quantity to compute
the optimal distance to the preceding vehicle Δx(t), and use vP as input and Δx(t)
as output, it turns out that a nonlinear Hammerstein–Wiener (nlHW, see Fig. 10.9)
model can be tuned to yield a good, cycle-independent approximation.

The nonlinearities of the identiﬁed model can be interpreted as an approximation
of the distance constraints imposed on the corresponding optimization problem [22].
Of course, such a ﬁxed controller needs additional elements to take into account the
predictive action. This is recovered by adding a non causal smoothing ﬁlter, requir-
ing a prediction of approximately 10 s. The smoothing ﬁlter additionally ensures the
drivability of the approximated inter-vehicle distance. The schematic of this approx-
imation, including an external branch to prevent an offset is portrayed in Fig. 10.10.

10 Predictive Cooperative Adaptive Cruise Control

173

Fig. 10.9 Structure of nlHW

Fig. 10.10 Basic structure of approximate control

Fig. 10.11 Basic structure of safety layer with constraint enforcement controllers

Naturally, an additional safety layer is required to ensure the strict fulﬁllment of
the range bounds by modifying the approximated vehicle acceleration, but this would
be needed in any real application anyway. The basic structure of the proposed safety
layer is shown in Fig. 10.11.

174

D. Lang et. al

Fig. 10.12 Optimal inter-vehicle distance and its approximation

Table 10.6 Comparison of potential consumption reductions

Prediction horizon (s)

Beneﬁts at different margins
20 m (%)
10 m (%)

10
15
20
30
40
Approximation

9.9
10.8
11.2
11.3
11.3
10.3

11.4
14.4
15.1
15.3
15.3
13.4

30 m (%)

40 m (%)

11.9
16.3
17.5
18.4
18.5
15.7

12.3
17.1
18.6
19.2
20.2
17

An example of an approximated inter-vehicle distance is displayed in Fig. 10.12.
The resultant potential fuel beneﬁts are shown in Table 10.6. The approximated
solution yields beneﬁts close to those achievable with a receding horizon of 15 s. A
more detailed discussion and further results can be found in [22].

10.7 Trafﬁc Prediction Model From Data

All methods presented until now assumed some knowledge on the future behavior
of the preceding driver. This information, however, is usually not available. This
section presents some results on possible prediction methods using a set of nonlinear,
autoregressive (NARX) models, both in the case of interconnected and nonconnected
vehicles using data gathered in suburban road trafﬁc near to Linz, Austria. These

10 Predictive Cooperative Adaptive Cruise Control

175

Fig. 10.13 1 and 5 s ahead prediction, employing ‘V2V assisted approach’ and the ‘measurements
only approach’

Fig. 10.14 Comparison of of the prediction quality between the two approaches

models are given by

y(t + i) = fi (u(t), u(t − i))

(10.7)

176

D. Lang et. al

Fig. 10.15 Impact of imperfect prediction on fuel beneﬁt

while y(t) = v(t) is the vehicle speed. As the trafﬁc can include both connected
and independent vehicles, we need to consider both the case in which the preceding
vehicle transmits in real time a set of data (its position, speed as well as the acceler-
ation, gas, brake and clutch pedal positions) and the case in which only information
on position, speed and acceleration of the preceding vehicle can be used by mea-
surement or reconstructed by sensors on the controlled vehicle alone. Examples of
the performance of the predictors for 1–5 s ahead for both approaches are given in

10 Predictive Cooperative Adaptive Cruise Control

177

Fig. 10.13. The results correspond to the intuition that the estimate becomes less
precise for an increasing time distance. In addition to this, it is clearly visible that
the V2V approach yields more accurate results as shown in Fig. 10.14.

The top subplot in Fig. 10.15 shows results for a prediction horizon of 10 s using
hard constraints and the trafﬁc estimation with V2V based estimation with a reduced
fuel beneﬁt of 2.3 % due to the imperfect prediction. However, the strong reduction is
also due to the hard constraints as—together with the imperfect prediction—they lead
to sudden corrections as in the bottom subplot in Fig. 10.15. If the hard constraints
on the upper bound are relaxed, then more moderate acceleration (bottom subplot in
Fig. 10.15) are required, and a large part of the fuel savings is recovered (9.4 %).

10.8 Conclusions and Outlook

Coordinated control is receiving much attention, as the availability of cost effective
communication and computational systems allows new possibilities. There are dif-
ferent ways to exploit this new opportunity, and much work is being done at the safety
or at the infrastructure level. However, as this exposition meant to explain, there are
many opportunities also at the local level, centered around the single vehicle, which
should be used as well.
Abstract Topology optimization methods for continuum systems (structural topol-
ogy, shape, material) are well-established. However, these methods do not apply
to non-continuum or dynamic systems with discrete components with unique char-
acteristics as with hybrid vehicles. This chapter examines the power train topol-
ogy and control design optimization problem at vehicle system level. The design
space related to power train and control system optimization level is rapidly increas-
ing with new developments in power train, auxiliary technologies, system architec-
tures (topologies) and cyber-physical systems. The multi-objective, mixed or hybrid
(continuous/discrete time) character on both coupled levels of the problem requires
relative long computation time. Therefore, it requires a bi-level (nested) or simul-
taneous system design approach. Since, sequential or iterative design procedures
fail to prove system-level optimality. In this chapter, some illustrative examples
are discussed related to nested control and design optimization problems related to
continuous/stepped-gear transmission shifting, power split control and/or in combi-
nation with topology optimization.

11.1 Introduction

The design of a hybrid vehicle propulsion system is a complex task. The problem
is often multi-objective (e.g., minimizing emissions, maximizing acceleration per-
forming while minimizing system and component costs) and requires solving control
and design problems that have continuous and discrete dynamics. In literature often
case studies are selected, where the technology or topology choice have been ﬁxed
based on engineering knowledge (or heuristics) and the size of components (kW,
kWh) is chosen as the main design variable. This simpliﬁes the problem at hand, yet
may still impose difﬁculties and challenges related to the control design.

Analytical methods based on optimal control theory (Pontryagin’s Minimum Prin-
ciple, [1]) are very efﬁcient in solving the control problem for a class of hybrid
vehicle systems [2–6]. However, difﬁculties arise when discrete-state variable, e.g.
engine on/off, or gear position with a stepped-gear box with comfort constraints, are
included in the design problem [7, 8]. Practically, these problems are circumvented by
calculating, e.g., separate Hamiltonian functions (or values) related to each discrete-
controlled state individually and accordingly are solved for the admissible control
input, which minimizes this set of Hamiltonian functions [9]. Inherently, a singular
solution for the optimal control may occur with this method [10], and heuristics is
required in choosing a particular mode resulting in a suboptimal solution.

The control problem is nonconvex, and often, e.g., the engine on/off and gear-
position state are optimized a priori, or by using simpliﬁed (heuristic) rules. The
remaining control problem and constraints are sometimes convexiﬁed to speed up
the design process [11].

11.1.1 Co-design Methods

In literature, some authors address the combined control and propulsion system
design [11–13]. Often the design space related to technology choice or topology
variation is limited to one or two main possibilities reducing the design space sig-
niﬁcantly. However, in order to create fundamentally new conﬁgurations or topolo-
gies new and efﬁcient methods are required. Particular if dynamics are important it
becomes very challenging to make proper design decisions [14, 15]. This process of
coupled system and control optimization can be done utilizing a sequential, iterative,
bi-level or simultaneous strategy [16]. In [17] the vehicle system design and control
are optimized in an iterative manner: ﬁrst, the independent system design parame-
ters are selected using a Latin-Hypercube Sampling (LHS) method, and given a
(heuristic) controller the fuel economy subject to performance constraints are opti-
mized. Accordingly, at the optimal set of design parameters for the propulsion sys-
tem, the control rules for the system are optimized using deterministic Dynamic
Programming (DP). In a second iteration, again the optimal set of design parame-
ters is found given the updated controller. The process converges till a stopping
criteria related to the relative improvement is satisﬁed. From theory it follows that
the control and system design problems are coupled and that sequential or iterative
strategies fail to guarantee system-level optimality [16]. So far in literature, bi-level
or simultaneous strategies applied to the hybrid vehicle system design is limited. In
[18], the multiobjective design problem is nested where for every feasible system
design (topology and technology constant) the control design is optimized separately
using DP. Previously, in [19] also a multiobjective co-design (control and propulsion
system) for a parallel hybrid problem is addressed, yet using a rule-based control

11 Topology Optimization of Hybrid Power Trains

183

strategy (ADVISOR, [20]) limiting the achievable control performance. The nonlin-
ear Pareto frontier is computed and the sensitivity of the main design parameters to
the targets is systematically investigated. Particle swarm optimization, generic algo-
rithms, and deterministic search methods, such as Nelder-Mead simplex algorithm,
was also suggested as efﬁcient search methods to solve optimal sizing problem. Yet,
the authors in [18] claim computing the separate objective values for different sizes
to be more efﬁcient, since the sizing problem can be solved repeatedly with minimal
computational effort for any combination of weights.

11.1.2 Problem Deﬁnition: System Design Optimization

In this section, we would like to introduce the general system design problem, denoted
as P. In the following section of the article, this problem is used to derive the different
types of control and system design problems individually based on the analyzed case
under consideration, or assumptions. Let

Fi (dc) := Φ(x(t f ), t f ) +

L(x(t), u(t), t)dt for i ≤ {n + 1, . . . , N }

(11.1)

⎧

t f

t0

and

dc := [uT (t) x T (t) t0 t f ]T

(11.2)

be the controller design objectives and the vector of the controller design variables.
The control inputs and state variables are denoted as u(t) and x(t). The initial and
ﬁnal times are denoted as t0 and t f respectively. The global system design problem
P is formulated as, minimization of the vehicle system Fi (d p) and controller design
objectives Fi (dc) to the system and controller design variables (d p, dc), which are
elements of all the feasible system/controller designs D. The system and controller
designs are subjected to (in-)equally (input and state) constraints denoted as hi (.)
and gi (.) respectively for i = {c, p}.

⎪

⎨⎨⎨⎨⎨⎨⎨⎢
⎨⎨⎨⎨⎨⎨⎨⎡

P :=

⎪
⎨⎢

⎨⎡

D :=

min
{d p,dc}≤D

: J = {F1(d p), . . . , Fn(d p), Fn+1(dc), . . . , FN (dc)}

d p, dc : h p(d p) = 0, g p(d p) ∈ 0, ˙x(t) = f (x(t), u(t), t, d p),
hc(x(t), u(t), t, d p) = 0, gc(u(t), t, d p) ∈ 0, gc(x(t), t, d p) ∈ 0
Φ(x(t f ), t f ) = 0, x(t0) = x0
(11.3)

⎨⎦

subject to
⎣
⎨⎤

184

T. Hofman and M. Steinbuch

Fig. 11.1 Control and propulsion system design problems: a bi-level approach

The inﬂuence of physical system design on the control is accounted for by hc(.),
gc(.) and ˙x(t) to be a function of d p as well. Further, the formulation assumes that
all the state variables can be directly measured and that the physical system and
controller optimization objectives are separable [16].

11.1.3 Outline and Contribution of the Chapter

A bi-level optimization framework has been proven to identify a system optimal
solution. Traditionally, the outer loop optimizes the overall system performance by
varying the plant design. For every feasible plant design tested by the outer loop, the
inner loop calculates the optimal control for the given plant design [16]. In this work
(see also Fig. 11.1), a novel nested solution approach is discussed for

(i) a control design problem alone with discrete (outer loop using dynamic program-
ming) and continuous control inputs (inner loop using Pontryagin’s Minimum
Principle) reducing computation time signiﬁcantly; and,

(ii) a novel co-design problem related to the control (using dynamic programming)
and the vehicle propulsion design (transmission technology choice, sizing of
power converters and topology, using a general purpose solver).

In the later case (ii), the general optimization problem P can also be formulated

as,

min
d p≤φ

⎪

⎨⎨⎨⎨⎨⎨⎢
⎨⎨⎨⎨⎨⎨⎡

: J = {F1(d p), . . . , Fn(d p), Fn+1(dc), . . . , FN (dc)}

P :=

⎪
⎢

⎡

φ :=

d∞
c

= arg

d p, d∞
c
min
dc:(d p,dc)≤D

: h p(d p) = 0, g p(d p) ∈ 0,
{Fn+1(dc), . . . , FN (dc)}

⎦

subject to
⎣
⎤

(11.4)

11 Topology Optimization of Hybrid Power Trains

185

Under the assumption of the existence of a feasible combined physical system
and control design for every feasible physical system design. The backward coupling
from the control design to the physical system design (coupling parameters as output
from the control design to the general physical design problem) is ignored. The
solutions to the Eqs. (11.3) and (11.4) are mathematical equivalent [16].

The control design optimization problem, as described by case (i), including the
gear shift position (denoted as state x1), engine on/off (x2) and power split (x3) has
been visited by others [13], yet no comfort constraints on the gear shift command
has been taken into account (see Sect. 11.2).

x2

L

COMBUSTION ENGINE (CE)

CLUTCH

x3

BATTERY 
SYSTEM

- x4

POS

x4

SWI

PRE

S1

E-MACHINE (EM)

VARIABLE 
RATIO

VEHICLE, WHEEL 
INERTIA

v, a

rfd

FINAL 
DRIVE

x1={ramt , rcvt}

ROAD 
SURFACE

Fig. 11.2 Controlled switching topology: electric machine coupling is selectable (input and output
signals are included; the controlled-state variables xi for i ≤ {1, 2, 3, 4} are indicated by doubled-
headed arrows) [8]

In both discussed case studies, a single objective related to the control design,
i.e., fuel consumption, or CO2 emissions is used respectively. In case study (ii) (see
Sect. 11.3), also a performance constraint (acceleration performance) is imposed onto
the problem by an inequality constraint. Moreover, case study (ii), is an alternative
hybrid propulsion system model where not only the topology choice (pre-(PRE) or
post-coupled electric machine (POS) to the transmission) is as a propulsion design
variable separately analyzed, but also considered as a controlled-state variable (x4).
This is referred to as a switching topology (SWI) (see Fig. 11.2). In literature, so far
known to the authors, individually analyzed hybrid design models of static topology
cases can only be found. The results are based on previously published articles
(by the authors) and the corresponding optimizing problem is shown in Table 11.1.
Without loss of generality, the work proceeds to show with the nested approach that a
system-level optimality is guaranteed and proposes the integration of both problems
as future work (see Fig. 11.1). Finally, we state our conclusions and recommendations
in Sect. 11.4.

186

T. Hofman and M. Steinbuch

Table 11.1 Control and propulsion design cases under consideration

dc: control

d p: propulsion system

x1
x1

Section Gear ratio Engine on/off Power split Topology Technology
11.2
11.3
AMT Automated Manual Transmission; CVT Continuously Variable Transmission; EM Electric
Machine

AMT
{AMT, CVT} [0, 50]

EM size (kW) Ref.
6

x4 = 1
x4

[7]
[8]

x3
x3

x2
x2

11.2 Control Design Optimization: Gear Shift Strategies with

Comfort Constraints for Hybrid Vehicles

Similar to the problem presented by the authors in [13], we formulate our con-
trol design problem. Yet, an additional comfort constraint is added to the (discrete)
gear shift command limiting the admissible gear position [7]. Moreover, the main
contribution of this section is on an alternative computational efﬁcient solution pro-
cedure, which will be discussed in the following parts of this section. Taking into
account physical constraints from the transmission, battery, engine and electric motor,
the optimal control problem under study consists in minimizing the fuel consump-
tion of the vehicle along a prescribed vehicle cycle. The gear position is deﬁned as a
discrete state, denoted as x1. Further, let x2 ≤ {0, 1} be a discrete state representing
the state of the engine: x2 = 0 means the engine is off, while x2 = 1 means the
engine is on. Let x3 be a state corresponding to the state of charge of the battery.
We denote by x = {x1, x2, x3} ≤ X the state vector and deﬁne the control vector
u = {u1, u2, u3} ≤ U (x1, x2) by

⎪
⎨⎢

⎨⎡

u =

u1
the gear shift command,
u2 engine on/off command,
u3 battery power ﬂow,

(11.5)

with

U (x1, x2) = {(u1, u2, u3) : u1 ≤ U1(x1), u2 ≤ U2(x2), u3 ≤ U3(x2)}

(11.6)

where U1(x1) and U2(x2) are discrete values {−1, 0, 1} depending on x1 or x2
value. A full hybrid vehicle is considered, hence the engine can be stopped when the
torque is provided only the electric machine. Introducing the engine state allows to
take into account an extra fuel consumption corresponding to the necessary energy
to crank the engine [13]. If these losses are not engine state dependent, then the
optimal engine state (and corresponding engine on/off command) may follow from
the optimal power split minimizing the cost function. This similar assumption holds
for associated state dependent losses affecting the fuel consumption for the main
drive clutch (S1) or gear shift losses. Although, gear shift losses are neglected here,
the gear shift state is considered, since the following gear position x1(t +) depends

11 Topology Optimization of Hybrid Power Trains

187

on the current gear position x1(t) and the gear shift command u1(t) that limits the
admissible gear position state. The parallel hybrid topology is depicted in Fig. 11.2.
It is assumed that the vehicle wheel speed and acceleration as a function of time,
denoted as the disturbance (or external state) vector,

w(t) = [v(t), a(t)]T ,

(11.7)

are known. Let L(x(t), u(t), w(t)) be the instantaneous fuel consumption in (g/s),
given by

(cid:10)

L(x(t), u(t), w(t)) =

L(u1(t), u3(t), w(t)) if
if
0

x2(t) = 1 (engine running),
x2(t) = 0 (engine stopped).

The continuous state x3(t) is a governed by

˙x3(t) = f3(u3(t)).

(11.8)

(11.9)

Accordingly, the dynamic optimization problem can be formulated as follows:

⎪

⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎢
⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎡

⎧

t f

: J =

L(x(t), u(t), w(t)) dt

min
u(t)≤U , x≤X
⎪

t0
g1 := u1(t) ≤ U1 = {−1, 0, 1} ≈ Z
g2 := x1(t) ≤ X1 = {1, . . . , 5} ≈ N+

(cid:11)

g3 := u2(t) ≤ U2(x2) =

{−1, 0} if x2 = 1
{0, 1} if x2 = 0

≈ Z

(x2), u3(x2)} ≈ R

g4 := x2(t) ≤ X2 = {0, 1} ≈ Zn
g5 := u3(t) ≤ U3(x2) = {u3
g6 := x3(t) ≤ X3 = {x 3
, x 3} ≈ R
g7 := x1(t +) − x1(t) − u1(t) = 0
g8 := x2(t +) − x2(t) − u2(t) = 0
g9 := ˙x3(t) − f3(u3(t)) = ˙x3(t) − u3(t) = 0
g10 := x1(t0) − x10 = 0; g11 := x1(t f ) − x1 f = 0
g12 := x2(t0) − x20 = 0; g13 := x2(t f ) − x2 f = 0
g14 := x3(t0) − x30 = 0; g15 := x3(t f ) − x3 f = 0
g16 := x1 f − x10 = 0; g17 := x2 f − x20 = 0
g18 := x3 f − x30 = 0;

⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎢
⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎨⎡

P1 :=

subject to

(11.10)
The length of the optimization horizon is t f . The ﬁnal-state penalty term is Φ(x(t f ),
t f ) = 0 (see Eq. (11.1)).

188

T. Hofman and M. Steinbuch

(u*, x*)

F1(dc)

(u*1,u*2,x*1,x*2 : u*3,x*3)

1U

(u1,u2,x1,x2 : u*3,x*3)

(x1,x2)

(u1,u2)

f1(x1,u1)
f2(x2,u2)

(u1,u2,x1,x2)

(u*3,x*3)

(u*3,x*3 : u1,u2,x1,x2)

1L

(u3 : u1,u2,x1,x2)

x3

u3

f3(x3,u3)

Fig. 11.3 Bi-level control design optimization: interactions between optimization levels and algo-
rithms. DP Deterministic Dynamic Programming; PMP Pontryagin’s Minimum Principle [7]

11.2.1 Bi-level Optimization: Control Problem

The above described problem (11.10) contains continuous and discrete dynamical
properties. In order to speed up the computation time, a bi-level optimization pro-
cedure is proposed. The original problem is cascaded into two hierarchical prob-
lem levels, where solutions to the upper level problem P ≡
1U requires that the lower
level problem P ≡
1L is optimized. The assumption is that both levels have a single
objective. The optimization problem has a two-way coupling, which is presented in
Fig. 11.3. The lower level problem is optimized for feasible discrete control vari-
ables and states from the upper level problem. On the other hand, the objective
function at the upper level is affected by solutions at the lower level. The opti-
mal variable values are denoted by ∞. The above described problem can be given
as follows [21, 22],










≡
P
1

:=

:=

P

≡
1U
min
(u1,u2,x1,x2) j










⎪
⎨⎢

⎨⎡

s.t.

P

≡
1L

:= min
(u3,x3)

: J ((u3, x3) : (u1, u2, x1, x2) j )

gi ((u3, x3) : (u1, u2, x1, x2) j ) ∈ 0
(u3, x3) ≤ U3 × X3
(.) j := (u1, u2, x1, x2) ≤ {U1 × U2 × X1 × X2} ≥ V1



















.

(11.11)
The subscript j is used to index the feasible NLP subproblems. Let us also deﬁne
the set V1 of all integer assignments (u1, u2, x1, x2)’s for which there exist feasible
solution in the (u3, x3) variables as

(cid:11)

V1 =

(u1, u2, x1, x2) : ∗(u3, x3) ≤ U3 × X3 with gi (u, x) ∈ 0,
i ≤ {1, . . . , 18} ≈ N+

(cid:18)

.

(11.12)

11 Topology Optimization of Hybrid Power Trains

189

11.2.1.1 Solution Procedure

In the following the solution procedure for the bi-level problem is given. As described
it has similarities with the bi-level procedure presented by [23]. Yet, the procedure
is adapted accordingly to the problem under investigation.

Algorithm 1. Bi-level optimization

Let the bi-level optimization problem be deﬁned as in (11.11). A suitable method to
handle mixed-integer non-linear problems is deterministic Dynamic Programming
(DP). Hence, the upper level problem is solved using DP [24]. The lower level
problems contains continuous control variables and Pontryagin’s Minimum Principle
(PMP) is used. Then the solution procedure for such a problem can be deﬁned as
follows.

1. Initialize the optimization method (DP) selected for the upper-level optimization:
since DP is a numerical algorithm used here to solve a continuous and discrete
control problem, the continuous-time model (11.9) must also be discretized. Let
the total discrete-time model describing the system dynamics be given by

xi (k + 1) = xi (k) + fi (xi (k), ui (k), w(k), k) · τt,

k = {0, 1, . . . , n − 1}

(11.13)
for i ≤ {1, 2, 3}. The criterion to be minimized in discrete-time format and
expressed in a non-recursive form becomes,

(cid:11)

(cid:18)

min
u(k)≤U ,x(k)≤X

: J ⇐

Φ(x(0), 0) +

L ≡(x(k), u(k), w(k), k) · τt

n−1(cid:19)

k=1

(11.14)
with the small time step, denoted as τt, deﬁned as the constant difference: τt ⇒
t (k + 1) − t (k). Final state penalty terms Φ(.) at t f ⇒ t (k = N ) related to the
constrained ﬁnal states has been omitted in this analysis. Since, it is assumed
that the initial states equal the ﬁnal states (g16 − g18). The initial fuel cost at
t0 ⇒ t (k = 0) is deﬁned as Φ(x(0), 0). The second term relates to the cumulated
equivalent fuel-mass ﬂow cost, denoted as L ≡, as a function of the control inputs
and states.

2. Compute optimal cost-to-arrive and trajectory-to-arrive matrices (J and H
respectively): after deﬁning the objective function, a vector of optimization vari-
ables and constraints for the upper-level optimization problem (including the
lower-level optimization problem parameterized by the upper-level optimization
variables) then perform optimization as follows. Do for each calculation step for
time-indices k = 0 to n − 1, as follows.

a. Let vector (u1(k), u2(k), x1(k), x2(k)) j contain the current (feasible) values
for the optimization variables on the upper level and solve the dynamic

190

T. Hofman and M. Steinbuch

process model,
level optimization problem P ≡

f1,2(u1,2(k), x1,2(k), k). Deﬁne the corresponding lower-
1L at (u1(k), u2(k), x1(k), x2(k)) j .

b. Find the optimal input and state for the lower level (u∞
3

(k), x ∞
3

(k)) with PMP,

i.e., perform the optimization based on Algorithm 2 (see below).

c. Based on u∞
3

(k) and x ∞
3

(k), evaluate the objective function on the upper level

and provide the objective function value to the optimization method.

Based on the principle of optimality [24], DP is the algorithm, which evaluates
the optimal cost-to-arrive function J (x(k), k) at every node in the discretized
state-time space by proceeding forward-in-time:

i. with the initial cost calculation step

J (x(0), 0) = Φ(x(0), 0)

(11.15)

ii. and, proceeds in time for each intermediate calculation step for time-indices

k = 1 to n − 1,

J (x1,2(k + 1), k + 1) =

(cid:10)

(cid:20)

min
(u1(k),u2(k))≤U1×U2

J (x1,2(k), k) +
L ≡(x1,2(k), u1,2(k), w(k), k : x ∞
3

(k), u∞
3

(k)) · τt

(k), u∞
2

(11.16)
The optimal control (u∞
(k)) is given by the argument that minimizes the
1
righthand side of Eq. (11.16) for each x1(k) and x2(k) of the discretized state-
time space (to simplify notation denoted as x1,2(k)). The time direction may also
be reversed1 and infeasible nodes are assigned with a very high (or, inﬁnite) cost.
As an output of the algorithm (11.15)–(11.16) the associated optimal trajectory-
to-arrive at every node can be effectively stored in a matrix

H (k + 1,x ∞
1,2

(k + 1)) = x ∞
1,2

(k),

(11.17)

which contains the optimal state of the preceding time step (optimal control signal
map). This matrix is used to ﬁnd the optimal control signals during a backward
simulation, starting from the given ﬁnal states x ∞
(n) = x1,2(0) from g16 and
1,2
g17 of Eq. (11.10), to generate the optimal state trajectory with

x ∞
1,2

(k − 1) = H (k, x ∞
1,2

(k))

(11.18)

for k = {n, n − 1, . . . , 1}.
End Do

1 The backward-in-time algorithm starts at a given ﬁnal state; either algorithm is convenient to used
when both (initial and ﬁnal) states are ﬁxed. The forward algorithm is more convenient as it will
optimize the ﬁnal state.

11 Topology Optimization of Hybrid Power Trains

191

3. The optimal solutions for the bi-level optimization problem are J at (u∞
1

(k),
x ∞
(k), x ∞
(k)) with the corresponding optimal lower-level optimization solution
2
1
(k), x ∞
L ≡ at (u∞
3
3

(k), u∞
2

(k)).

Algorithm 2. Lower-level optimization

In the following the function H , called the Hamiltonian [1], deﬁned as

≡(x3(k), u3(k), p(k),k : (u1(k), u2(k), x1(k), x2(k)) j ) ⇒ H (x3(k), u3(k), p(k), k)

L

= L((x3(k), u3(k), p(k), k)) · x2(k) + p(k) · [ f3(x3(k), u3(k), k)]
(11.19)

is used for convenience. The solution procedure is as follows.

1. Initialize the optimization method (PMP) at the given values for the costate p(k)
and control inputs and states (u1(k), u2(k), x1(k), x2(k)) j following from Algo-
rithm 1, step 2a.

2. Deﬁne the objective functions, a vector of the optimization variables and con-
straints in P ≡
1L for the given parameters (u1(k), u2(k), x1(k), x2(k)) j . Start the
optimization procedure as follows. Do for the given calculation step k, as follows.
a. Solve the dynamic process model, f3(u3(k), x3(k), k) with the current opti-

mization variables u3(k).

b. Evaluate objective L ≡ at u3(k) based on the state variables x3(k) for the given

parameters (u1(k), u2(k), x1(k), x2(k)) j .
End Do

3. Save the optimal values of the optimization variables u3(k) and the corresponding
state variable values x3(k), as well as L ≡, which is needed in Algorithm 1.

The above described solution procedure is shown in Fig. 11.4. To simplify the notation
the control input variables in the diagram are omitted. A constant costate value
satisfying the end constraint on the battery energy can not be found, since, e.g.,
engine on and off solutions can be found minimizing both the Hamiltonian (Hx2=1 =
Hx2=0)). To circumvent this problem, a mildly-tuned integrator I is used to update
the costate value p over time. The found solution is computed very efﬁciently using
the nonlinear nonconvex models and is close to global optimal (relative error < 0.4 %,
see next section).

In literature, other approximated methods may use convex modeling to solve the
problem. For example in [25] a heuristic strategy is used in a sequential manner
to solve for the discrete control inputs (gear position, x1, engine on/off, x2) and
accordingly a convex solver for the power split, x3; or, improved (in terms of accuracy
vs. computation speed) in [26] by iteratively updating the costate p using the output
of PMP (for engine on/off decision with the assumption switching the engine on
if Hx2=1 ∈ Hx2=0)) as the high-level problem and again a convex solver (for the
power split, x3) as the low-level problem.

192

T. Hofman and M. Steinbuch

{ p(0), I }

(x(0),0)

Algorithm 1: DP
(Gear position; Engine On/Off)

p(k+1) = p(k) + I (x3(0) - x3

*(k))

(x1(k),x2(k))j

L’

Algorithm 2: PMP
(Power split)

k = k + 1 

x1

x2

*(k)
*(k)

x3

*(k)

k = n - 1?

End

Fig. 11.4 Solution procedure

Table 11.2 Comparison of simulation results

Fuel (g)

Time (s)

DP
300
473

DP-PMP
301
474

Rel. diff. [%]
0.4
0.4

DP
3964
4799

DP-PMP
9
12

Reduction factor
440
400

Cycle
NEDC
FTP75

11.2.2 Simulation Result: Bi-level Control Design

Based on the vehicle model and (physical) constraints given in [7], the above describe
problem P ≡
1 has been solved and the optimal control signals were computed. In
Fig. 11.5, the controlled states in inputs are shown as a function of time for the NEDC.
The difference between DP and DP-PMP method is found to be negligible small (less
than 0.4 %). Differences are also caused by numerical errors caused by griding the
state and input space. However, the computation time is signiﬁcantly reduced from
approximately 4,000 to 9 s (factor 440).2 These results and for the FTP75 cycle
are listed in Table 11.2. In particular for large-scale complex propulsion system
optimization problems, this method can speed up the design procedure signiﬁcantly.

2 HP EliteBook 8530w, Core 2 Due, CPU T9600 @ 2.8 GHz, RAM 4.0 GB

11 Topology Optimization of Hybrid Power Trains

193

1

2

3

e

3

3

e

Fig. 11.5 DP-PMP simulation result for a parallel hybrid vehicle with discrete gear box and engine
start-stop [7]. Pe = engine power; u3 = battery power

11.3 Control and Propulsion System Design Optimization:

Topology, Transmission, Size and Control Optimization
for Hybrid Vehicles

In this section, the combined control and propulsions system optimization for a hybrid
vehicle is discussed [8]. The control problem is different from P1 of the previous
section: the topology selection (pre or post coupling electric machine to the transmis-
sion) is an additional control input. Moreover, the transmission technology, pushbelt
Continuously Variable Transmission (CVT) and Automated Manual Transmission
(AMT), and the sizing in terms of maximum output power for the electric machine
and engine are optimized. Again a bi-level method is used, where in this case at the
upper level the topology and sizing of the components is optimized, P ≡
2U , whereas
at the lower level the control problem P ≡

2L is optimized.

From literature [16] it follows that if the bi-level system design (plant)/controller
optimization strategy is convergent, then it is guaranteed to converge to an opti-
mal combined plant/controller design. Next, a scalar substitute objective function is

194

T. Hofman and M. Steinbuch

deﬁned as the weighted sum of the propulsion system objective (hybrid system cost,
which is proportional assumed with electric machine and battery size), denoted as
F1, and controller objective (fuel consumption costs), denoted as F2; and, the points
on the Pareto set will be generated by varying the weights wi . Given these conditions
the combined propulsion/controller optimization problem becomes:

⎪

⎨⎨⎨⎨⎨⎨⎨⎢
⎨⎨⎨⎨⎨⎨⎨⎡

P2 :=

D :=

and is similar to,


P ≡
2

:=

P ≡
2U

:=

min
(d p) j












⎪
⎨⎢

⎨⎡














min
{d p,dc}≤D

: J = w p · F1(d p) + wc · F2(dc)

d p, dc : g p(d p) ∈ 0, ˙x(t) = f (x(t), u(t), t, d p),
gc(dc, t, d p) ∈ 0
Φ(x(t f ), t f ) = 0, x(t0) = x0

⎨⎦

subject to
⎣
⎨⎤

(11.20)

P ≡
2L

:= min
dc

: J = w p · F1((d p) j ) + wc · F2(dc)



























⎪

⎨⎨⎨⎨⎨⎨⎢
⎨⎨⎨⎨⎨⎨⎡

g p((d p) j ) ∈ 0
gc(dc : (d p) j ) ∈ 0
hc(dc : (d p) j ) = 0
dc ≤ Uc × Xc
(d p) j := d p ≤ D ≥ V2

.

(11.21)

subject to

Let us also deﬁne the set V2 of all integer assignments d p’s (engine and electric
machine power speciﬁcation) for which there exist feasible solution in the dc variables
as

(cid:11)

(cid:18)

V2 =

d p : ∗dc ≤ Uc × Xc with gi (dc, d p) ∈ 0,
i ≤ {1, . . . , 24} ≈ N+

.

(11.22)

Complementary to the previous deﬁned control problem, we introduce a new discrete
state related to the topology choice, denoted as x4 (see Fig. 11.2). If x4 = 1, then
the electric machine pre-coupled to the transmission and vice versa (post-coupled)
if x4 = 0. Moreover, the following inequality constraint related to the power speci-
ﬁcation of the electric machine is added. Finally, initial and ﬁnal state constraints on
x4 are imposed.

11 Topology Optimization of Hybrid Power Trains

195

F1(dp);
F2(dc)

dp

dc*

2U

2L

(dc*,dp*)

(dc*,dp*)

(dp : dc)

(dc* : dp)

(dc : dp)

J

dp

x

u

wp F1(dp)
+
wc F2(dc*)

f(x,u,dp)

Fig. 11.6 Bi-level control and propulsion system design optimization: interactions between opti-
mization levels and algorithms. DP Deterministic Dynamic Programming; GPS General Purpose
Solver [8]

⎪

⎨⎨⎨⎨⎨⎨⎨⎨⎨⎢
⎨⎨⎨⎨⎨⎨⎨⎨⎨⎡

(cid:11)

gc

g p

g5 := u3(t) ≤ U3(x2, d p) = {u3

(x2, d p), u3(x2, d p)} ≈ R;

(cid:11)

≈ Z;

if x4 = 1,
if x4 = 0

g19 := u4(t) ≤ U4(x4) =

{−1, 0}
{0, 1}
g20 := x4(t +) − x4(t) − u4(t) = 0;
g21 := x4(t0) − x40 = 0;
g22 := x4 f − x40 = 0;
g23 := τt0−100 km/ h(d p) − 11 = 0, acceleration time (s);
g24 := d p ≤ D ≈ {R : d p ≥ 0 ∧ d p − u3 = 0}

(11.23)

Under the assumption that the maximum battery power equals the absolute minimum
battery power, i.e., u3 = −u3.

11.3.1 Simulation Result: Bi-level Propulsion System and Control

Design

A General Purpose Solver (GPS) (e.g., sequential quadratic programming) can be
used in ﬁnding the optimal plant design in combination with DP for the control
design (see Fig. 11.6). Here, the responses of the objective functions F1(d p) (hybrid
system costs) and F2(dc) (fuel consumption costs) has been computed for three
topologies (pre-, post-coupled and switching topology) on two different drive cycles
(NEDC, CADC urban). The results are shown in Fig. 11.7 and the cost function
values are scaled with their maximum values. From observation it followed that for

196

T. Hofman and M. Steinbuch

Fig. 11.7 Combined propulsion system and control design responses for different topologies and
two drive cycles. A Pareto optimal point for w p = wc = 0.5 is indicated with a circle. Pre =
Pre-coupled; Pos = Post-coupled; Swi = Switching topology. F1 = hybrid system cost; F2 = fuel
cost

(cid:21)

any combination of the weighting factors wi with
wi = 1 only a single solution
for the different optimal electric machine and engine sizes (sizes are constraint by
performance requirements, g p) can be found. The circle denotes the particular choice
of w p = wc = 0.5. Moreover, it can be observed that the switching (dynamic)
topology outperforms the static topologies.

For the automated manual transmission (AMT) the fuel beneﬁt from a ﬁxed pre-
or post coupled electric machine as a function of a constant transmission efﬁciency
is computed (on two drive cycles). The results are shown in Fig. 11.8. Moreover,
it can be observed that the optimal topology strongly depends on the transmission
characteristics and driving loads (cycle).

11.4 Conclusions

This work discussed two design frameworks based on bi-level optimization for the
control design with discrete and continuous control variables; and, for the co-design
of the vehicle propulsion system (topology, size, transmission technology) and con-
trol design for a parallel hybrid vehicle. In the last decade, signiﬁcant control perfor-
mance improvement is realized by the transition from heuristic control design meth-
ods (fuzzy, rule based) to methods based on optimal control theory (e.g., equivalent
consumption minimization strategy—ECMS, PMP, DP). Traditionally, the vehicle
propulsion design (technology and topology selection, and sizing of power converter

11 Topology Optimization of Hybrid Power Trains

197

8

6

7

5

4

3
2
1

20

15

10

20

5
0.8

]

W
k
[
 
e
z
i
s
 
e
n
i
h
c
a

M

]

W
k
[
 
e
z
i
s
 
e
n
i
h
c
a

M

8

6

7

5

15

4

10

1

3

F2 x4
2

F2 x4

7

6

5

4

3

2

1

6

4

5

3

2

1

NEDC

6

5
4
F2 x4
3

2

1

F2 x4

F2 x4

F2 x4

CADC urban

1
0.94

4

2

3

1

1

2

0.82

0.84

0.86

0.88

0.9

0.92

0.96

0.98

5
4
3
2

1

1

2

1

1

1

2

3

POS
PRE
Relative improvement [%]

F2 x4
1

F2 x4

5
0.8

0.82

0.84

0.86

0.88

0.9
Transmission efficiency [-]

0.92

0.94

0.96

0.98

1

Fig. 11.8 The optimal topology depending on transmission efﬁciency and electric machine size
(kW)

and energy storage systems) is based on engineering intuition and creativity (heuris-
tics). To handle complexity and reducing the design space effectively, ﬁxed topologies
(with technologies) are ﬁtted on the solution rather than generating complete new
propulsion systems. In future, challenges are seen to develop new efﬁcient design
methods for co-design (by integration of both discussed design problems) includ-
ing topology optimization, which creates the required transition from the (classical)
heuristic approaches to more optimal design based methods improving the overall
system design performance.
Abstract Methods from optimal control theory have been used since the past decade
to design model-based energy management strategies for hybrid electric vehicles
(HEVs). These strategies are usually designed as solutions to a ﬁnite-time horizon,
constrained optimal control problem that guarantees optimality upon perfect knowl-
edge of the driving cycle. Properly adapted these strategies can be used for real-time
implementation (without knowledge of the future driving mission) at the cost of ei-
ther high (sometime prohibitive) computational burden or high memory requirement
to store high-dimensional off-line generated look-up tables. These issues have moti-
vated the research reported in this chapter. We propose to address the optimal energy
management problem over an inﬁnite time horizon by formulating the problem as a
nonlinear, nonquadratic optimization problem. An analytical supervisory controller
is designed that ensures stability, optimality with respect to fuel consumption, ease
of implementation in real-time application, fast execution and low control parameter
sensitivity. The approach generates a drive cycle independent control law without re-
quiring discounted cost or shortest path stochastic dynamic programming introduced
in the prior literature.

12.1 Introduction

In response to the present and future environment and energy challenges worldwide
the automotive industry has been focusing on improving vehicle fuel efﬁciency.
Although there is no “silver-bullet” technology to replace the existing ones, at least
in the near future, one possible answer to the challenges posed by the automotive and
transportation sectors is found in electriﬁcation of both the mobility and transport
systems. New concepts and new technologies are being developed to realize efﬁcient
hybrid and electric vehicles suited for both individual and public mobility and for
goods distribution in urban areas [7]. This chapter deals with the energy management
in HEVs.

12.2 Optimization Problems in HEVs

From a design prospective, a hybrid powertrain is much more complicated than a
conventional powertrain as selection hybrid architecture (e.g., series, paralllel, power-
split [18]) and component sizing, is not always an easy task because of many design
options and the rapidly developing technologies in the automotive industries. Design
optimization tools, such as neural networks, genetic algorithms and particle swarm
optimization, have been successfully used for powertrain optimization design to
maximize fuel economy and minimize emission, weight and cost while guaranteeing
vehicle performance (see, for instance, [17], and references therein).

Given a predeﬁned optimized powertrain, a second problem in a HEV is the power
split on-board of the vehicle. This is generally referred to as energy management
problem or supervisory vehicle control.

Realistic ﬁgures of achievable improvement in fuel economy in HEVs range from
10 % for mild hybrids to more 30 % for full hybridized vehicles [10]. This potential
can be realized only with a sophisticated control system that optimizes energy ﬂow
within the vehicle. The adoption of systematic model-optimization methods using
meaningful objective functions has been the pathway to go in order to achieve near-
optimal results in designing the vehicle energy management system. In this chapter
we focus on model-based energy management strategy design techniques. The chap-
ter is organized as follows. In Sect. 12.3 we present a heavy-duty pre-transmission
hybrid truck model, which is used as a case study. Section 12.4 presents the standard
optimal energy management problem formulation. In Sect.12.5, we review results
from the literature to solve the optimal control problem. In the same section, we
present the basics of Pontryagin’s Minimum Principle (PMP), Equivalent Consump-
tion Minimization Strategy (ECMS) and Adaptive-PMP (A-PMP). Issues related to
the real-time implementation of A-PMP are analyzed that motivate the design of a
new energy management control framework presented in Sect. 12.6. Section 12.7
reports on some mathematical background used later in Sect. 12.8 where an ana-
lytical control law, referred to as nonlinear optimal control strategy (NL-OCS), is
presented. Section 12.9 presents a comparison in simulation of the NL-OCS against
PMP and A-PMP and the effectiveness of the new control design is shown both from
a calibration and implementation standpoint.

12 Model-Based Optimal Energy Management Strategies for Hybrid Electric Vehicles

201

Fig. 12.1 Power ﬂow diagram of pre-transmission parallel HEV

12.3 Case Study: Pre-transmission Parallel Hybrid

A heavy-duty pre-transmission parallel HEV is used as a case study along the chapter.
The vehicle architecture and the power ﬂow among the different components (the
arrowheads denote the positive power sign convention) are illustrated in Fig. 12.1.
The main speciﬁcations of the powertrain components are reported in Table 12.1.
With the clutch closed, the parallel mode of operation uses both the devices, engine
(ice) and motor (mot), to propel the vehicle and their speed is directly determined
by the vehicle velocity. The additional degree of freedom available in this mode is
used to optimize the vehicle energy usage. The torque/power balance equations are:

⎧
⎪

⎨

Tmot (t) + Tice(t) = Tgb(t) + Taccmech(t),
Pbatt (t) = Pmot,e(t) + Paccelec(t),
Φmot (t) = Φice(t) = Φgb(t).

(12.1)

where Tgb, Φgb are the instantaneous gearbox torque and speed; Tmot , Φmot are the
instantaneous electric motor torque and speed; Paccelec is the instantaneous electrical
accessory power and Pmot,e is the instantaneous electrical power at input/output
terminals of the electric motor. The battery power (Pbatt ) can be represented as a
function of engine power (Pice) and the requested power (Pr eq ) as:

⎢

Pbatt (t) = − 1
φmot
Pr eq (t) = Pgb(t) + 1
φmot

Pice(t) + 1
φmot

Pr eq (t),

Paccelec(t) + Paccmech(t).

(12.2)

The vehicle model has been implemented in PSAT (Powertrain Simulation Analysis
Toolkit) environment [1].

An analytical model of the engine fuel consumption, based on Willans line ap-
proximation is used [10], which expresses the engine chemical power (Pchem) as an
afﬁne function of the engine power (Pice) and speed (Φice):

Pchem(t) = e0(Φice(t)) + e1(Φice(t)) · Pice(t)

(12.3)

202

Table 12.1 Vehicle
characteristics

Component

Vehicle mass
Engine capacity
Engine power
Motor power
Battery energy capacity
Electrical accessory
Mechanical accessory

S. Onori

Size

19,878 kg
6.7 L Diesel
194 kW
200 kW
7.5 kWh (27 MJ)
7 kW
4 kW

where Pchem = ˙m f · Q L H V [Q L H V is the lower heating caloriﬁc value of diesel
in (kJ/kg)] is the chemical power input to the engine and Pice = TiceΦice is the
engine power output. The coefﬁcient e0(Φice) represents the engine friction losses
and e1(Φice) the conversion efﬁciency of the machine. A good approximation of the
friction losses and conversion efﬁciency coefﬁcients is given by expressing e0 and
e1 as a quadratic ﬁtting with respect to engine speed [25], as:

⎡

e0(Φice(t)) = e00 + e01 · Φice(t) + e02 · Φ2
ice
e1(Φice(t)) = e10 + e11 · Φice(t) + e12 · Φ2
ice

(t)
(t)

(12.4)

where ei j > 0, i, j = 0, 1, 2 are the constant Willans line coefﬁcients. Hence, the
fuel consumption rate can be written as:

˙m f (t) =

[e0(Φice(t)) + e1(Φice(t)) · Pice(t)]

(12.5)

1
Q L H V

or:

˙m f (t) = p0(Φice(t)) + p1(Φice(t))Pice(t)

(12.6)

e0(Φice(t))
Q L H V

, and p1(Φice(t)) =
with p0(Φice(t)) =
Note: The Willans line fuel consumption rate model, together with a suitable de-
scription of the battery model, is used to reformulate the energy management control
problem as an inﬁnite-time horizon optimal problem including stability in Sect. 12.8.

e1(Φice(t))
.
Q L H V

12.4 Problem Formulation

One important characteristic of the energy management problem is that the control
objectives are mostly integral in nature (for instance, fuel consumption, emissions
per mile of travel, battery life or a combination of the above, [9, 12, 16, 30]), while
the control actions are local in time. In addition to that, the control objectives are
subject to constraints which are both integral or global, such as maintaining battery

12 Model-Based Optimal Energy Management Strategies for Hybrid Electric Vehicles

203

SOC within a prescribed range, and local constraints, such as physical limitation of
the actuators. The very nature of this problem has made the task of ﬁnding a near-
optimal implementable solution a challenging goal motivating a wealth of research
over the past decade [23].

12.4.1 Optimal Energy Management Problem in HEVs

In this chapter, we consider the problem of minimizing the total mass of fuel, m f (g),
during a driving mission. This is equivalent to minimizing the following cost JT :

JT =

˙m f (u(t))dt

(12.7)

T⎣

0

where ˙m f (g/s) is the instantaneous fuel consumption rate, u(t) is the control action,
and T is the optimization horizon. The objective function (12.7) is minimized under
a set of both local and global constraints, as outlined in the following.
System Dynamics. The system dynamics is given in terms of S OC variation with
respect to time according to:

˙S OC(t) = −τ I (t)
Qnom

(12.8)

where τ represents the Coulombic efﬁciency [10]; I (t) (A) is the current ﬂowing
in (positive) and out (negative) of the battery and Qnom (Ah) is the nominal battery
charge capacity. The battery is modeled through the zero-th order equivalent circuit
model [28], whose parameters are: the equivalent resistance, Req and the open circuit
voltage, Voc. For the application at hand, i.e., charge sustaining HEVs, the battery is
used over a range of S OC (typically between 0.5 and 0.8 S OC), where the parameters
are not dependent on S OC [28]. Following the discussion in [28] we can express the
current I (t) as a function of Pbatt (t) and write the system dynamics as:

⎤

Voc −

˙S OC(t) = −τ

(Voc)2 − 4Req Pbatt (t)
2Req Qnom

.

(12.9)

Global Constraints. In a charge sustaining HEV, the net energy from the battery
should be zero over a given driving mission, meaning that the S OC at the end of
the driving cycle, S OC(T ), should be the same as the S OC at the beginning of the
driving cycle, S OC(0), and equal to a reference S OC value, i.e., S OCr e f :

S OC(T ) = S OC(0) = S OCr e f .

(12.10)

204

S. Onori

SOC(t)

SOCmax

SOCref

SOCmin

SOC (0) = SOC (T ) = SOCref

Fig. 12.2 Typical optimal S OC behaviour obtained solving Problem 12.1

Condition (12.10) is justiﬁed mainly as a way to compare the results of different
solutions by guaranteeing that they start and reach the same level of battery energy.
In real vehicles, it is sufﬁcient to keep the S OC between two boundary values.
Local Constraints. Local constraints are imposed on the state and control variables.
These constraints mostly concern physical operation limits, such as the maximum en-
gine torque and speed, the motor power, or the battery S OC. For the pre-transmission
parallel HEV powertrain local constraints are expressed as:

Pbatt,min ≤ Pbatt (t) ≤ Pbatt,max ,
S OCmin ≤ S OC(t) ≤ S OCmax ,
Tx,min ≤ Tx (t) ≤ Tx,max ,
Φx,min ≤ Φx (t) ≤ Φx,max , x = ice, mot.

Tmot,min ≤ Tmot (t) ≤ Tmot,max

(12.11)

where the last two inequalities in (12.11) represent limitations on the instantaneous
engine and motor torque and speed, respectively; (·)min, (·)max are the minimum
and maximum value of power/S OC/torque/speed at each instant. Moreover, at each
instant the supevisory controller ensures that the total power request at the wheels is
satisﬁed.

Problem 12.1 The energy management problem in a charge sustaining HEV con-
sists in ﬁnding the optimal control sequence u∈ that minimizes the cost function (12.7)
while meeting the dynamic state constraint (12.9), the global state constraint (12.10)
and local state and control constraints (12.11).

Problem 12.1 by its very nature is a ﬁnite-time horizon (the cost function (12.7)
is being minimized over a ﬁnite time horizon [0, T ]), constrained (constraints on
the state and control are being enforced at each instant of time), nonlinear [the
system dynamics (12.9) are nonlinear], nonquadratic (the cost function is the fuel
consumption map of the engine), optimal control problem. We refer to Problem 12.1
as the standard HEV energy management problem. A typical S OC behavior resulting
from solving Problem 12.1 is shown in Fig. 12.2.

12 Model-Based Optimal Energy Management Strategies for Hybrid Electric Vehicles

205

12.5 Finite-Time Horizon Energy Management Strategies

Several approaches have been proposed over the years to solve Problem 12.1. Those
can be grouped into [24]:
• non-causal or non-realizable strategies. They require a priori knowledge of the
driving cycle and are not applicable in real conditions [e.g., Dynamic Programming
(DP), PMP];

• causal or realizable strategies. They do not require a priori knowledge of the driving
cycle and are developed with the primary objective of realizability and do not
guarantee optimality [e.g., Adaptive-PMP, Stochastic DP, rule-based, equivalent
consumption minimization strategy (ECMS)].

Although, the primary objective is to design and implement causal strategies
that can be eventually tested on real vehicles, the importance of ﬁnding non-causal
optimal solutions resides in that: (1) they provide a benchmark solution (global
optimum) any causal strategy can be compared against, and (2) properly modiﬁed
they can be used to develop on-line strategies [27, 28]. In [16], for the ﬁrst time,
and in [4, 5] later, results from DP were analyzed with the aim of gaining insights to
generate reproducible rules to design a rule-based strategy capable to mimic the DP
behaviour. Although rule-based energy management strategies are relatively easy to
develop and implement in a real vehicle, a signiﬁcant amount of calibration effort is
required to guarantee performances within a satisfactory range for any driving cycle.
Moreover, rules are not necessarily scalable to different powertrain architectures and
different component sizes. In addition to the DP [6, 31, 32], that ﬁnds the global
solution recursively going backwards in time using Bellman’s principle of optimality
[3], local optimization methods have also been extensively used to ﬁnd the global
optimum. These methods can be used to ﬁnd the optimum, by performing an ofﬂine
optimization when the drive cycle is known, and they are also employed to design
adaptive optimal strategies to achieve near optimal performances when the driving
cycle is unknown. Much of the literature on local optimization methods pertain to
PMP and/or ECMS [8, 27, 29].

The PMP [22] formulates and minimizes the Hamiltonian function (a function of
the instantaneous cost and the state constraint) at each instant to obtain the optimal
solution. PMP conditions, which in principles, are only necessary conditions of
optimality in the case of Problem 12.1 become also sufﬁcient.1 This makes PMP a
design tool to ﬁnd the global optimal solution. Given Problem 12.1, PMP states that
the optimal control solution u∈(t) must satisfy the following conditions:
• u∈(t) minimizes at each instant of time the Hamiltonian associated to the system:

H (u(t), S OC(t), α(t)) = α(t) ·

˙S OC(t) + ˙m f (u(t)))

(12.12)

i.e.:

1 Results from [13] and [14] prove the uniqueness of the solution of the optimal control problem
under the satisﬁed assumption of constant battery efﬁciency over the S OC range of operation.

206

S. Onori

Fig. 12.3 Open-loop PMP-based energy management control scheme

u∈(t) = min
u∞U

H (u(t), S OC(t), α(t))

(12.13)

U is the set of admissible solutions;

• the optimization variable α(t), also known as adjoint state or co-state must satisfy

the dynamic equation along the optimal solution:

˙α(t) = −

⎦
⎦
⎦
⎦

β H
β S OC

u∈,S OC ∈

(12.14)

The optimal control sequence generated by (12.13) operates in open-loop as shown

in Fig. 12.3.

Hence, the optimal solution u∈ can only be obtained in simulation where the
power request is known a-priori. In particular, the optimality of PMP resides in the
perfect knowledge of the optimal co-state α∈ whose value varies from cycle to cycle.
In [29] it is mathematically shown that the minimization of the Hamiltonian H is
equivalent to the minimization of an equivalent fuel consumption function, used in
the ECMS. ECMS, initially proposed by Paganelli et al. [21], is based on accounting
for the use of stored electrical energy, in units of chemical fuel use (g/s), such that
one can deﬁne an equivalent cost function taking into account the cost of electricity:

˙m f,eq (t) = s(t) Ebatt
Qlhv

·

˙S OC(t) + ˙m f (t)

(12.15)

where Ebatt is the battery energy and s(t) is the equivalent factor that assigns a cost
to the use of electricity, and the equivalent cost function ˙m f,eq (t) is equivalent to
the Hamiltonian in PMP. If, on one hand, PMP/ECMS are practical tools to ﬁnd the
optimal solution to Problem 12.1 using a forward looking simulator, they can also
been employed for real-time implementation.

In fact, the only control parameter in the PMP (or ECMS) is the co-state (or equiv-
alent factor), which is cycle-dependent. The key idea to use the PMP (or ECMS) as
a causal strategy resides in adapting the co-state as a function of driving conditions.
From the PMP solution one can observe that the variation of the co-state as driving
conditions change is correlated to the divergence of the actual S OC from its charge-
sustaining reference value [20]. This observation has led to the development of an
adaptation scheme based on feedback from SOC to be used in combination to the
minimization of H [20]. The role of adaptation is to update the value of the co-state
without using past driving information or prediction of future driving behavior, but

12 Model-Based Optimal Energy Management Strategies for Hybrid Electric Vehicles

207

Speed profile − Manhattan cycle

Speed
Evaluated points

200

400

800

1000

1200

600
Time [s]

Hamiltonian function:

Hamiltonian

]
s
/
m

[
 
y
t
i
c
o
e
V

l

15

10

5

0

0

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

−0.1

0

20

40

60

80

100

Normalized control u 

Fig. 12.4 Hamiltonian function H (bottom) evaluated for different instances of a Manhattan driving
cycle (top) [19]

just using information of current S OC. For example, the adaptation can be per-
formed via PI-like controller [15], or via an autoregressive moving average (ARMA)
mechanism of the type [20]:

α(k) =

α(k − 1) − α(k − 2)
2

+ K · (S OCr e f − S OC(k))

(12.16)

which allows the adaptation to take place at regular intervals of duration Ts, (t =
kTs, k = 1, 2, . . .), rather than at each time instant as in the case of PI-like based
correction.

12.6 Motivation for Inﬁnite-Time Horizon Optimization

The real-time controller based on A-PMP (12.16) requires the Hamiltonian function
to be minimized instantaneously. This operation, that needs to be executed on-board
at each tick of the clock, despite being computationally expensive, can lead in some
cases to unpredictable no-optimal results, due to the fact that the Hamiltonian is in
many instances of the driving cycle not a convex function of the control variable,

208

S. Onori

as one can see from Fig. 12.4. Different control values could be in principle equally
suitable in the minimization process, leading to a not unique solution of the optimal
control problem, thus causing undesirable chattering in the control outputs [26].
These issues have suggested to move towards a new research direction to ﬁnd optimal
solutions that would not have such a detrimental behaviour when used in a real-time
setting. Inspired by Bernstein and Haddad’s work [2, 11] on theoretical results on
optimal nonlinear regulation problem involving non quadratic cost functionals, a ﬁrst
attempt to propose a new control framework for the energy management problem
was done in [25]. The authors cast the energy management problem into a nonlinear
optimal regulation problem where the battery S OC is optimally regulated to its
reference target in the case of zero disturbance (Pr eq = 0). Preliminary results
showed the feasibility of the closed-form control law in the simple case of vehicle
at standstill and series hybrid architecture. Reduction in computational complexity
and decreased sensitivity of the control parameter with respect to driving conditions
were also showed. Nonetheless, two issues were not properly addressed in [25]: the
stability deﬁnition and the extension of ﬁnite-time cost function into an inﬁnite-
time functional (needed to formally use the results from [2, 11]). In [19], a rigorous
framework is developed where stability of the energy management state trajectory
is ﬁnally deﬁned while guaranteeing optimality by means of an analytical, cycle-
independent control law. The novel framework is summarized in the next section and
new simulation results comparing the performances of the new analitycal supervisory
controller against PMP (used as a benchmark) and A-PMP (for on-line strategies
comparison) are presented in Sect. 12.9.

12.7 From Finite-Time to Inﬁnite-Time Horizon Optimal

Control Problem

The energy management problem is reformulated as a nonlinear-nonquadratic
inﬁnite-time optimization problem. The new control framework consists in re-
thinking the standard ﬁnite-time optimal control problem in HEV (Problem 12.1)
as an inﬁnite time horizon problem. To ensure optimality of vehicle operation when
t > T , the [0, T ] optimization horizon is extended into the inﬁnite horizon [0, ≈],
leading to a new cost function, J≈ [19]:

J≈ =

˙m f (u(t)) · g(t)dt

(12.17)

≈⎣

0

by means of the scalar positive function, g(t):

12 Model-Based Optimal Energy Management Strategies for Hybrid Electric Vehicles
(cid:3)
q

(cid:2)

209

g(t) =

(cid:2)

0 < τ < 1, q > 0

(12.18)

1 + τ

1 +

t
T
(cid:3)
q

t
T

The role of the function g(t) is to penalize the action of the control u(t) for t > T
in order to approximate the ﬁnite-time cost JT deﬁned in (12.7) to the inﬁnite-time
functional (12.17). The system dynamics is reformulated in order to ﬁt the problem
in the form used in [11] (as discussed in [19] ), where the nonlinear system is required
to be dissipative with respect to a supply rate function.

12.7.1 System Dynamics Reformulation

In the new control framework, a Lyapunov-based approach is used to obtain a state-
feedback control law to ﬁnd the optimal torque/power split where the power requested
(Pr eq ) is regarded as a L2 disturbance. The battery state of energy (S O E), deﬁned
as the amount of battery energy stored at the present time (E(t)) to the maximum
battery energy capacity (Emax ), is used as state variable in this discussion. S O E is
related to S OC by the following relationship [29]:

where VL is the battery terminal voltage and V max
Hence, the SOE dynamics:

oc

the maximum open circuit voltage.

S O E(t) = S OC(t)

VL (t)
V max
oc

=

E(t)
Emax

⎧
⎪

⎨

Pbatt
˙S O E = −φbatt
Emax
Emax = Qmax · V max
oc

(12.19)

(12.20)

Deﬁning k = φbatt
, the battery S O E error γ = S O Er e f − S O E is introduced,
whose dynamics is described as a function of the control input (Pice) and the distur-
bance (Pr eq ) by virtue of Eq. (12.2):

Emax φmot

˙γ = −k Pice + k Pr eq

(12.21)

Note that in parallel mode the power requested is the sum of accessory powers
(Paccelec + Paccmecc) and the gearbox power (Pgb). When the vehicle is not moving
(v = 0), instead, the power requested Pr eq only accounts for the accessory loads
power. Thus, the disturbance power Pr eq is:

210

⎡

Pr eq =

Pgb + φmot Paccelec + Paccmecc v > 0 ≡t ∞ [0, T ]
v = 0 ≡t ∞ [T, ≈]
φmot Paccelec + Paccmecc

S. Onori

(12.22)

Consider an open set Z ≥ R such that γ ∞ Z , a set U ≥ R such that Pice ∞ U ,
and a set W ≥ R such that Pr eq ∞ W and Pr eq in L2. The compact sets for the
control, state and disturbance are:
⎧
⎪

(cid:11)

(cid:10)
Z =
S O Er e f − S O Emax , S O Er e f − S O Emin
(cid:10)
0, P max
U =
ice
W = {Pr eq : Pr eq ∞ L2}

(cid:11)

(12.23)

⎨

Consider the following control system:

⎡

˙γ = −k Pice + k Pr eq ,
z = γ

γ (0) = γ0

(12.24)

where γ = 0 is an equilibrium point of the autonomous system and z is the per-
formance output variable. Also consider the following functional cost [in virtue of
(12.6)]:

J≈ =

˙m f (Pice(t))dt =

p0(Φice) + p1(Φice) · Pice(t)
Q L H V

dt

(12.25)

≈⎣

0

≈⎣

0

Problem 12.2 The inﬁnite-time optimal energy management problem consists
in minimizing the cost function (12.25) under system dynamics (12.24), with state
and control variables lying in the compact sets Z and U , and Pr eq ∞ W .

Deﬁnition 12.1 Consider Problem 12.2 with Pr eq ∗ 0 and let λ(γ (t)) be its opti-
mal solution. Then the origin γ (t) = 0 of the closed-loop system under λ(γ (t)) is
asymptotically stable if γ (t) ⇐ 0 for t ⇐ ≈.

A typical S OC behavior obtained as a solution of Problem 12.2, is shown in Fig. 12.5.
It can be noticed that the global constraint used in Problem 12.1 requiring S OC(T )
to be equal to the reference value S OCr e f is not met in this case as the convergence
of S OC to S OCr e f is guaranteed only as t ⇐ ≈.

12.8 Inﬁnite-Time Nonlinear Optimal Control Strategy

(NL-OCS)

With respect to the system (12.24) and the inﬁnite cost function (12.25) [11] deﬁnes
the Hamiltonian function H as following:

12 Model-Based Optimal Energy Management Strategies for Hybrid Electric Vehicles

211

Fig. 12.5 Typical SOC proﬁle as a solution of a inﬁnite-time optimization problem including
stability

H (γ, Pice, α) = ˙m f (Pice) + ν(γ, Pice) + α · (k Pice)

(12.26)

where ν(γ, Pice) is a positive scalar function (to be selected), and α is the co-state
variable. In order to have the Hamiltonian function zero at the minimum value, as
requested in [11], a shifting of the H is operated as follows:

¯H (γ, Pice, α) = H (γ, Pice, α) − p0(Φice)

(12.27)

Theorem 12.1 Consider the system (12.24) with functional cost (12.25). Then, the
feedback control law P ∈
ice

(γ ) deﬁned as:
⎢

P ∈
ice

= λ(γ ) =

2k2(μ4γ 3)2
(kμ4γ 3− p1(Φice) g(t))ε 2
γ 2

γ > ¯γ ⇒ γ ≤ 0
0 < γ ≤ ¯γ

(12.28)

with ¯γ =

(cid:2)

(cid:3) 1
3

p1(Φice)
kμ4

, is such that:

1.

2.

the solution γ (t) = 0, t ≥ 0 of the closed-loop system is locally asymptotically
stable in accordance to Deﬁnition 12.1.
the adjoint performance functional J (γ, Pice(γ ))

J (γ, Pice) =

(cid:10)
˙m f (Pice) + ν(γ, Pice)

(cid:11)

dt

(12.29)

is minimized.

Proof Consider the candidate Lyapunov function

V (γ ) =

μ4γ 4, μ > 0 ∞ R

(12.30)

≈⎣

0

1
4

212

then we can deﬁne the storage function ν(γ, Pice) and the supply rate function
r (γ, Pr eq ), associated to the system (12.24) and the Lyapunov function (12.30), as:

⎧
⎪

⎨

ν(γ, Pice) =

(cid:2)

(cid:3)
2

1
ε 2

β V
βγ

(cid:4)

(cid:5)

k2 ·

1 + log(P 2
ice

)

r (γ, Pr eq ) = ε 2 P 2
r eq

− γ 2

The proof of Theorem 12.1, following the same reasoning provided in [11], is based
on a series of sufﬁcient conditions that ensure optimality and stability that are shown
to hold true when the optimal feedback control λ(γ ) = P ∈
ice
1. The Lyapunov function V (γ ) assumes its minimum value of 0 at the origin.

(γ ) is used.

V (0) = 0

(12.32)

2. V (γ ) is a positive deﬁnite function because it is a quadratic scalar function with

the minimum at the origin.

3. The optimal feedback control law is zero at the origin, i.e., from (12.28):

4. The optimal control law (12.28) makes the origin γ (t) = 0 asymptotically stable

when Pr eq = 0, equivalently:

P ∈
ice

(0) = 0

β V
βγ

· k P ∈
ice

(γ ) < 0,

γ ∧= 0

In order to show (12.34), without loss of generality we consider Pbatt as new
control variable with Pr eq = 0. Thus:
⎢

P ∈
batt

=

2k2(μ4γ 3)2
(kμ4γ 3−n1(Φmot ) g(t))ε 2

−
−γ 2

γ > ¯γ ∈ ⇒ γ ≤ 0
0 < γ ≤ ¯γ ∈

(12.35)

where ¯γ ∈ =

(cid:3) 1
3

(cid:2)

−

n1(Φmot )
kμ4

, and this makes (12.34) become:

μ4 · γ 3 · k · k P ∈

batt

(γ ) < 0,

γ ∧= 0

In the domain 0 < γ ≤ ¯γ ∈, it is immediate to see that

− μ4 γ 3 k γ 2 < 0

S. Onori

(12.31)

(12.33)

(12.34)

(12.36)

(12.37)

12 Model-Based Optimal Energy Management Strategies for Hybrid Electric Vehicles

213

Preq (t)

(t) = 0

P*

ice( )

NL-OCS law 
(Eq. 1.28) 

= f (P*

ice, Preq )

(t)

Fig. 12.6 Closed-loop energy management control scheme based on the analytical NL-OCL solu-
tion

In the domain γ > ¯γ ∈ ⇒ γ ≤ 0 denominator of (12.36) is positive when γ is
positive and negative otherwise, thus leading to:

⎡

−μ4γ 3k · 2k2(μ4γ 3)2 < 0 γ > ¯γ ∈
γ ≤ 0
μ4γ 3k · 2k2(μ4γ 3)2 < 0

(12.38)

5. The Hamiltonian function (12.27) takes on the minimum value when the optimal

control law (12.28) is applied. The shifted hamiltonian ¯H ,

(cid:2)

(cid:3)

β V
βγ

¯H

γ, P ∈
ice

,

= ˙m f + ν(γ, P ∈
ice

) +

k P ∈
ice

(γ )

(12.39)

becomes

¯H = p1 Pice +

(cid:6)

1
ε 2

k2

(cid:6)

(cid:7)

2

μ4γ 3

1 + log(P 2
ice

)

+ μ4γ 3k Pice

(12.40)

for the system (12.24) and cost function (12.25). It can be easily shown that the
closed-loop controller (12.28) is a minimum of the ¯H (the stationary ﬁrst order
conditions and the second order convexity conditions are veriﬁed).

6. The passivity condition with respect to the disturbance input Pr eq requires that

the following inequality is satisﬁed:
(cid:3)

(cid:2)

β V
βγ

· k · Pr eq ≤ r (γ, Pr eq ) + ˙m f + ν(γ, P ∈
ice

)

(12.41)

β V
βγ

(cid:7)

2

A second order algebraic inequality in Pr eq is obtained which is veriﬁed when
ε ≤ ¯ε = 2.369.
Q.D.E.

In virtue of Theorem 12.1, the origin γ = 0 of the closed-loop system is opti-
mally locally asymptotically stable when Pr eq = 0. Moreover, P ∈
ice is optimal with
respect to the adjoint functional J (γ, Pice(·)), which is an upper bound for J≈.

214

S. Onori

μ

μ
μ
μ
μ
μ

Fig. 12.7 S OC trajectories from: (1) NL-OCS as μ varies (left) and (2) PMP as α varies (right)
for the Manhattan driving cycle

The optimal control law obtained from Theorem 12.1 is referred to as Nonlinear
Optimal Control Strategy (NL-OCS) and it is implemented according to the closed-
loop system scheme shown in Fig. 12.6. To the best knowledge of the author of this
article, this is the ﬁrst time that an analytical supervisory controller is proposed to
solve the energy management problem in HEVs. In the optimal control law (12.28)
that operates from S OC feedback, the values of k, p1(Φice) are known from the
vehicle models, ε is a constant whose upper bound was obtained from the theorem’s
proof, and μ is the only calibration parameter that needs to be selected for on-board
implementation.

12.9 Strategies Comparison: Simulation Results

In this section, we ﬁrst evaluate the novel closed-loop supervisory controller against
the benchmark solution from PMP and then we compare the NL-OCS against the real-
time implementable A-PMP to show the effectiveness of the proposed control-law for
on-board implementation. Ofﬂine simulations are performed to test the sensitivity of
the new model-based strategy against the calibration parameter μ. Results are shown
on the left plot of Fig. 12.7 where different S OC proﬁles from NL-OCS are shown
for different value of μ. On the left plot of Fig. 12.8 the fuel consumption (FC) is
plotted together with ∂S OC = S OC(T ) − S OC(0) (for different driving cycles) to
measure the ability of the control law to guarantee charge-sustainability. On the right
hand side of Fig. 12.7 and Fig. 12.8 we show: (1) the solution obtained from PMP for
different values of the co-state α and, (2) the high sensitivity of charge-sustainability
to the co-state α.

It is well known, in fact, that performance of PMP is highly dependent on the co-
state α, both in terms of charge-sustainability and fuel consumption (see, for instance

12 Model-Based Optimal Energy Management Strategies for Hybrid Electric Vehicles

215

Fig. 12.8 NL-OCS: fuel consumption and ∂S OC = S OC(T ) − S OC(0) as a function of μ for
four different driving cycles (left). PMP: ∂S OC as a function of α for Manhattan driving cycle
(right)

Fig. 12.9 S OC proﬁles from PMP, NL-OCS and A-PMP

[28]). The results of this analysis are used to calibrate the NL-OCS for on-board
implementation. A combined driving cycle obtained by concatenating a Manhattan,
West Virginia Urban (WVU) Interstate, Heavy-Duty UDDS, and Manhattan driving
cycles is used to validate and compare the NL-OCS against the PMP solution and
the real-time controller A-PMP. The three S OC proﬁles are shown in Fig. 12.9 and
a quantitative analysis in terms of fuel economy and engine efﬁciency of the three
control strategies is reported in Table 12.2. Not only does the analytical control law
guarantee optimality (with values within 1 % from the PMP benchmark solution) for a
wide range of values of the control parameter μ (see, Fig. 12.8), but also it guarantees
low sensitivity against driving characteristics, making the performance of the new
strategy driving cycle independent. In addition, the calibrated NL-OCS also shows
better performance in terms of fuel consumption than the real-time A-PMP. Above
all, the main advantage of having an analytical solution is in the fast execution of the
control action as opposed to the computational burden required by the instantaneous
minimization operation of A-PMP. In [19], it is reported that the NL-OCS solution
is up to 5 times faster than the A-PMP. The NL-OCS can be implemented in the

216

Controller

PMP
A-PMP
NL-OCS

Table 12.2 Fuel consumption and engine efﬁciency comparison between the PMP, A-PMP and
NL-OCS solutions

FC m f (kg)

13.11
13.36 (< 2 %)
13.24 (< 1 %)

Norm. fuel cons. %

100
98.13
99.02

S. Onori

ICE eff.

0.319
0.309
0.310

5

x 10

e
c

i

P

15

10

5

0
300

200
ω

ice

100

0

0

1

0.5

ζ

Fig. 12.10 Engine power map: Pice = f (Φice, γ )

form of a look-up table, by mapping the power issued by the control law (12.28) as
a function of γ and the engine speed Φice, as shown in Fig. 12.10.

12.10 Conclusions

In this chapter, we have ﬁrst presented the standard formulation of the energy man-
agement problem in HEVs and reviewed the PMP and A-PMP methods. As a real-
time implementable strategy, if on one hand the A-PMP is very promising as it
performs near to the global optimum, on the other hand, the high computational
burden due to the instantaneous minimization can make the use of this strategy pro-
hibitive for in vehicle operation. A new framework centered around the theory of
nonlinear, nonquadratic optimal control has been developed and presented in this
chapter. An analytical, cycle-independent, state-feedback supervisory controller has
been proposed that achieves optimality with respect to an inﬁnite time horizon perfor-
mance functional while guaranteeing asymptotic stability. The proposed control law
was implemented in a pre-transmission parallel hybrid heavy-duty vehicle and the
performances of the closed-loop system were compared to the benchmark solution

12 Model-Based Optimal Energy Management Strategies for Hybrid Electric Vehicles

217

provided by the PMP and the real-time solution provided by A-PMP. The advantages
offered by the newly designed solutions are: (1) low calibration effort (only one pa-
rameter needs to be calibrated); (2) low sensitivity to the control parameter; (3) fast
execution for on-board applications; (4) close-to-the-optimum performance despite
the driving mission.
Abstract Hybrid-electric vehicles (HEV) has been the subject of intensive research
as a ﬁeld of application of optimal control in the past decade. In particular, researchers
have proven that energy management (or supervisory control) can be effectively
designed using optimal control-based techniques (Guzzella and Sciarretta, Vehicle
Propulsion Systems. Introduction to Modeling and Optimization. Springer, Berlin,
2013. Such methods have been applied to charge-sustaining hybrids implement-
ing various architecture, as well as, more recently, to plug-in hybrids (Stockar
et al. IEEE Trans Vehr Technol, 60(7):2949–2962, 2011; Sivertsson 2012). Plug-
in hybrids (PHEV) are characterized by much higher battery capacities and energies
than charge-sustaining hybrids, thus the proper description of battery behavior plays
an even more fundamental role in energy management design.

13.1 Introduction

Hybrid-electric vehicles (HEV) has been the subject of intensive research as a
ﬁeld of application of optimal control in the past decade. In particular, researchers
have proven that energy management (or supervisory control) can be effectively
designed using optimal control-based techniques [1]. Such methods have been
applied to charge-sustaining hybrids implementing various architecture, as well as,

A. Sciarretta (B) · D. di Domenico · P. Pognant-Gros · G. Zito
IFP Energies nouvelles, Rueil-Malmaison Cedex, France
e-mail: Antonio.Sciarretta@ifpen.fr

D. di Domenico
e-mail: domenico.didomenico@ifpen.fr

P. Pognant-Gros
e-mail: Philippe.Pognant-Gros@ifpen.fr

G. Zito
e-mail: Gianluca.Zito@ifpen.fr

H. Waschl et al. (eds.), Optimization and Optimal Control in Automotive Systems,
Lecture Notes in Control and Information Sciences 455,
DOI: 10.1007/978-3-319-05371-4_13, © Springer International Publishing Switzerland 2014

219

220

A. Sciarretta et al.

more recently, to plug-in hybrids [2, 3]. Plug-in hybrids (PHEV) are characterized
by much higher battery capacities and energies than charge-sustaining hybrids, thus
the proper description of battery behavior plays an even more fundamental role in
energy management design. Usually, energy management aims at minimizing a cost
function that is fuel consumption (or a weighted sum of consumption and regulated
emissions), under a global constraint on the battery state of charge (SOC). Therefore,
battery dynamics is usually described only in terms of macroscopic SOC variation as
a function of current. However, the battery is a crucial component of HEV and PHEV
that affects signiﬁcantly the cost and the performance of the whole system. While
installation cost is a consequence of the battery design, battery end of life induces
replacement costs if not matching vehicle lifetime. Moreover, as battery power and
energy capabilities deteriorate with aging, its buffer role tends to fade, decreasing
the energy efﬁciency of the powertrain with time. Battery aging is thus a key factor,
even more for PHEV, which depends on the design choices but also on the use of the
battery, i.e., on the energy management strategy adopted. Including aging in the cost
function to be minimized needs a proper modeling of the aging factors, particularly
capacity loss and internal resistance increase. A ﬁrst attempt of integrating an aging
model in the cost function of an optimal-control based energy management was
reported in [4]. The aging model there used is sensitive to the current only, similarly
to a few other contributions [5]. However, a more accurate and experimentally vali-
dated model is needed to draw general conclusions. This chapter considers mainly the
capacity loss factor, which has been the subject of several experimental investigations
[6–8]. Such investigations pointed at the importance of both current and temperature
as the main capacity loss factors. The relevance of temperature implies an additional
dynamics, other than that of SOC, to be taken into account in the optimal control
solution. A few researches have dealt with battery temperature variations [9, 10],
without explicitly considering aging. Additional temperature states imply additional
costates in the optimal control solution, which are particularly difﬁcult to treat both
in an online controller and in ofﬂine optimization, as it has been shown for other
thermal states, such as engine or catalyst temperatures [11]. For example, costate
own dynamics are unstable for stable state dynamics and this fact makes the opti-
mal solution very sensitive to the prediction of the costate values (online) or to the
guess of the initial costate values (ofﬂine, e.g., with shooting-like methods). As an
additional complexity, the established capacity loss models exhibit an internal state
that is the total ampere-hour (Ah) throughput, which is an equally undesired feature
from the viewpoint of the optimal control solution.

The contribution of this chapter is a simulation study, albeit based on experi-
mental measures, on the minimization of a mixed fuel consumption–battery aging
cost function during PHEV operation. A validated capacity loss model is modi-
ﬁed in order to eliminate the Ah-throughput state. However, thermal dynamics are
explicitly considered in the optimal control problem and for this purpose a val-
idated lumped-parameter battery thermal model is used. Dynamic programming
(DP) and Pontryagin’s minimum principle (PMP) are compared to numerically com-
pute the optimal solutions, for various scenarii in terms of ambient temperature and

13 Optimal Energy Management of Automotive Battery Systems

221

optimization criterion. A speciﬁc analysis is conducted on the costate variations, in
view of an online implementation of the derived strategies.

13.2 Case Study and Motivation

The case study presented in this chapter is a plug-in parallel hybrid–electric demo car
designed by IFPEN. The baseline vehicle, a gasoline-engine utility vehicle (Renault
Kangoo), has been transformed to a full hybrid vehicle by integrating off-the-shelf
electric components (battery pack, DC–DC converter, and electric motor) and replac-
ing the original manual gearbox with an entry-level automated manual transmission.
The electric motor has been coupled to the primary shaft of the transmission through
a gear reducer, thus ensuring a wide vehicle speed range for the pure electric mode.
A large Li-ion battery allows to obtain a range of about 33 km in zero-emission mode
when running on a NEDC cycle limited to 55 km/h. The characteristics of the main
vehicle components are resumed in Table 13.1.

The on-board vehicle energy management is based on an Equivalent Consumption
Minimization Strategy (ECMS) [1], a technique derived from optimal control theory
and PMP, see Sect. 13.4.2, using the engine fuel consumption as the minimization
criterion. The optimal torque split between the engine and the electric motor is
computed at a low frequency of 5–10 Hz. According to the ECMS, at each time step
the optimal split of the required wheel torque is chosen among a ﬁxed (relatively
small) number of hybrid split values, and one purely electric mode. The optimal
torque split is computed making the assumption that the corresponding driveline
conﬁguration is instantaneously available. This is not generally true, since transient
phases are required to change the driveline conﬁguration as, for example, starting
and clutching the engine or performing a gear change.

Embedded implementation of the ECMS in a vehicle control unit (VCU) has
proved that is possible to approach the minimal fuel consumption whilst integrating
powertrain component limits as well as drivability constraints. Plausibility of ECMS
can be assessed by comparing the fuel consumption measured on an urban mission
proﬁle with an a-posteriori optimization computed with DP, see Sect. 13.4.1) by
imposing the measured wheel torque demanded by the driver, vehicle speed proﬁle,
as well as initial and ﬁnal battery state of charge (SOC). Figure 13.1 shows such
a comparison in terms of fuel energy consumption and SOC. Fuel consumption is
measured from the injection signals in the engine controller. In the DP, engine on/off
state and gear are enforced to match the measured quantities.

It should be noted that the engine torque and motor torque setpoints issued by the
VCU are not always coincident with the raw output of the ECMS, since dynamic
corrections are made downstream of the ECMS to manage driveline transients. Such
corrections are not performed in the DP. However, the result presented shows that, at
least for this particular application, experimental fuel energy consumption and battery
discharge are close to the optimal trajectories found with the DP. That is an inher-
ent effect of the PMP/DP assumptions (quasistatic modeling, absence of transient

222

A. Sciarretta et al.

Table 13.1 Flex hybrid components main characteristics

Component

Speed range (rpm)

Voltage range (V)

Power (kW)

Capacity (Ah)

ICE
Electric motor
Battery
DCDC
Gearbox
Vehicle

0–6,000
0–20,000
–
–

–
400–550
145–216
400–600
AMT (5 gears)
1,700 kg curb weight

63
37
–
40

–
–
39
–

7
x 10

DP
Measure

]
J
[
 
y
g
r
e
n
E

1.5

2

1

0.5

0

 

0

 

 

DP
Measure

]

1
−
0

[
 

C
o
S

0.65

0.6

0.55

0.5

0.45

0.4

 

0

200

400

600

800

1000

1200

200

400

600

800

1000

1200

time [s]

time [s]

Fig. 13.1 Comparison between measured (online ECMS) and DP traces: fuel energy (left); battery
SOC (right)

maneuvers). On the one hand, during transient maneuvers (engine stop/start, gear
change), PMP/DP overestimate fuel consumption because they assume that the pow-
ertrain is instantaneously in its setpoint conﬁguration. On the other hand, PMP/DP
quasistatic modeling underestimates the fuel consumption during transients. These
contrasting effects are partially compensating, which explains the good agreement
of Fig. 13.1.

Standard optimal-based energy management considers only the fuel consumption
in the cost function to be minimized. However, resulting battery current can exhibit
a rather aggressive behavior, as shown in Fig. 13.4. The Root Mean Square (RMS)
of current is of about 40 A in this test, or higher than C1 in terms of C-rate (peak
values are limited to C3). This fact enlightens the relevance of considering the aging
of the battery, of which current RMS is one important factor, in the global powertrain
energy management.

13.3 Optimal Control Problem Formulation

In [4], the fraction of battery life depleted was given as

1
(cid:2)

σ (I (u(t), w(t)), ξ(t), θ (t)) · |I (u(t))|,

(13.1)

13 Optimal Energy Management of Automotive Battery Systems

223

where I is the battery current, u is the set of controlled variables, w(t) is the set
of uncontrolled quantities related to the drive cycle, i.e., the required torque at the
wheels, the vehicle speed, etc., ξ is the battery SOC, θ is the battery temperature,
the function σ (·) is the severity factor, i.e., the relative aging effect with respect to a
nominal cycle, and (cid:2) is the total Ah-throughput corresponding to the nominal cycle.
The severity factor was calculated using a postulated map.

In this chapter, battery life depletion is particularized as capacity loss and
described by the aging factor Y , yielded by a semi-physical model described in
Sect. 13.3.3. Consequently, the severity factor concept is replaced by the rate of
capacity loss, ˙Y . Using such a model, the optimal control problem consists in mini-
mizing the combined criterion

(cid:2)

T

(cid:2)

T

0

0

J = (1 − α)

˙m f (u(t)) · L H V dt + α

β · ˙Y (I (u(t), w(t)), ξ(t), θ (t)) dt,
(13.2)
where β is a transformation coefﬁcient to make the capacity loss rate dimensionally
compatible with the fuel consumption, and α is a weighting factor to adjust the relative
importance of the two cost contributions (α is arbitrary, while β has the meaning of
a physical parameter). For the pre-transmission parallel architecture considered in
this chapter, the variable u(t) is the engine torque.

Neglecting electrochemical and mechanical dynamics, the current I (t) is assumed
to be an algebraic function of u(t), w(t), ξ(t) and θ (t) (the latter two dependencies are
through the battery inner parameters). However, the two variables θ (t) and ξ(t) have
too relevant dynamics to be neglected, and therefore are treated as state variables.
Generally, the state equations are

˙ξ = fξ (I (t)),
˙θ = fθ (ξ(t), θ (t), I (t)).

(13.3)

(13.4)

The next three subsections will describe the models used to calculated the functions
˙m f , I , ˙Y , fξ , and fθ .

Global constraints to the optimal control problem presented are on the initial
and ﬁnal states, i.e., ξ(0) = ξ0, ξ(T ) = ξ f (SOC target value), θ (0) = θ0 (ambient
temperature), while θ (T ) is free. Of course, the state variables and the control variable
u are submitted to physical and drivability-based local constraints.

13.3.1 Powertrain Modeling

The calculations reported in this chapter are performed in an ofﬂine approach, where
a driving cycle is prescribed and assumed to be perfectly followed. The vector w(t)
contains values of wheel torque Tw(t) and wheel speed ωw(t). Gear n(t) is chosen
according to gear shift maps as a function of Tw and ωw. Consequently, the engine

A. Sciarretta et al.

224

140

120

100

80

60

20

]

m
N

[
 
e
u
q
r
o
t
 
e
v
i
t
c
e
f
f
e
 
n
a
e
M

2

7

0

280

40

300

0
1000

2

6

0

2

7

0

3

0

0

0

8

2

3 0 0

400

600

4 0 0

600

2 7 0
2 8 0

3 0 0

260

400

600

0.8
0.8 2
0 . 8
4
0 . 8
0 . 8 6
0 . 8 8

5
0 . 8 7

0.89

0.9

8

0 . 8

0.86

0.85

0.80.8

0.82

0.83

1

0.84

]

m
N

[
 
e
u
q
r
o
T
 
r
o
t
o
M

5
.
0

6
.
0

0.7

30

20

10

0

−10

0

.

7

0

.

6

0

.

5

−20

−30

0

2000

3000

4000

5000

6000

Engine speed [rpm]

5

10

15

20

Motor Speed [krpm]

Fig. 13.2 Engine fuel map (right, [g/kWh]) and motor efﬁciency map (left) used in this study

speed is ωe(t) = Rt (n(t))·ωw(t) and the motor speed is ωm(t) = Rm·Rt (n(t))·ωw(t),
where Rm is the motor reduction gear ratio and Rt the variable transmission ratio
including gearbox and ﬁnal gear.

Engine torque Te(t) coincides with the controlled variable u(t) for this architec-

ture. Fuel consumption rate is evaluated from a quasistatic engine fuel map,

˙m f (Te, ωe) = ˙m f (u, w),

(13.5)

whose tabulated data are shown in Fig. 13.2. Engine torque and wheel torque demand
deﬁne motor torque,

(cid:2)

Tm(t) = 1
Rm

Tw(t)
Rt (n(t))ηsign(Tw(t))

t

(cid:3)

− Te(t)

,

(13.6)

where ηt is the transmission efﬁciency. Motor electric power is evaluated from from
an efﬁciency map Pm(Tm, ωm) = Pm(u, w), whose tabulated data are shown in
Fig. 13.2.

Battery SOC and temperature, as well as aging factor rate, are evaluated from
the battery power Pb(t) = Pm(t), according to the battery models described in the
next sections. Note that, although the original democar presented in Sect. 13.2 is
equipped with a SAFT module of 54 series-arranged cells, the model considered in
this chapter refers to an A123 System Li-ion cell, for which a sufﬁcient amount of
experimental data was available. In order to match the original pack’s energy and
power, the number of cells arranged in series and parallel has been set to Ns = 58,
N p = 17.

13 Optimal Energy Management of Automotive Battery Systems

225

13.3.2 Battery Modeling

The state dynamics are described by modeling the cell with an equivalent circuit
approach. The state of charge ξ is computed based on the equivalence between the
electrochemical and electric charge, by means of an ampere-hour counting

˙ξ = fξ (I (t)) = − I (t)
Cnom

,

(13.7)

where Cnom is the cell nominal capacity (in C).

The cell current I (t) is evaluated from the deﬁnition of battery power Pb(t) =

I (t) · V (t) and the following model for the battery voltage:

V (t) = U0(ξ(t)) + R(ξ(t), θ (t)) · I (t),

(13.8)

where the open circuit voltage U0 is a function of the state of charge and the internal
resistance R, capturing the ohmic, charge transfert and diffusion effects, is a function
of state of charge and temperature.

Thermal dynamics are described with a lumped-parameter thermal balance that

˙θ = fθ (ξ(t), θ (t), I (t)) =

qgen − qtra − qcool
MC

,

(13.9)

reads

where

qgen(ξ(t), θ (t), I (t)) = R · I (t)2 + θ (t) · I (t) · dU
dθ
qtra(θ (t)) = h · A · (θ (t) − θ0),

(ξ(t)),

(13.10)

(13.11)

are the heat generated by the cell and the heat exchanged with the ambient, θ0 the
ambient absolute temperature, qcool is the heat provided by the cooling system, M
is bulk mass, C is caloriﬁc thermal capacity, h the heat transfer coefﬁcient, A the
thermal exchange surface, dU
dθ the entropic heat. The time constant of such dynamics
is thus of the order of MC/ h A which, for the cell considered, amounts to about
800 s. This value makes the thermal dynamics comparable with that of SOC (that is
almost a pure integrator).

The cooling system is modeled as it is realized in the original democar battery. A
thermostatic controller activates liquid coolant circulation when the measured surface
battery temperature reaches an upper value. However, the electricity consumption of
the water pump is neglected in this study.

Battery pack characteristics are scaled from the corresponding cell values that
were identiﬁed experimentally on a commercial 2.3 Ah A123 System LiFePO4 Li-
ion cell. In particular, U0 = Ns · U0,cell , R = Rcell · Ns/N p, M = Mcell · Ns · N p,
A = Acell · Ns · N p, dU/dθ = (dU/dθ )cell · Ns. Figure 13.3 shows the dependence

A. Sciarretta et al.

226

]

V

[
 

l
l

e
c
,
0

U

3.5

3.4

3.3

3.2

3.1

3

 

0

 

]

/

K
V
m

[
 

)
θ
d
/
U
d
(

l
l

e
c

0.2

0.1

0

−0.1

−0.2

−0.3

−10°C
20°C
40°C

0.2

0.4

0.6

0.8

1

0

0.2

0.4

0.6

0.8

1

SOC [−]

SOC [−]

Fig. 13.3 Open-circuit voltage (left) and entropic heat (right) of the A123 cell as a function of
SOC

of U0,cell and
parameter identiﬁcation can be found in [12, 13].

cell , respectively, on the SOC [12]. More details on model and

(cid:4)

(cid:5)

dU
dθ

13.3.3 Battery Aging Modeling

Due to several microscopic aging phenomena, Li-ion cells suffer a progressive
performance degradation, that usually implies cell capacity loss and impedance
increasing.The mechanisms leading to the capacity fade include the contact loss
of active material particle, metallic lithium plating, cracking formation in particles
and Solid Electrolyte Interphase (SEI) formation [13]. The relative impact of each
mechanism varies with the cell technology and usage [14]. In [6], a large experimen-
tal test campaign on the A123 System LiFePO4 Li-ion cell is described, consisting in
a large range of constant C-rates and temperatures charges and discharges. It shows
that the loss of active lithium associated with the anode degradation is a primary
cause of capacity fade for this technology of Li-ion of cell. An empirical cycle-life
model is also identiﬁed and validated on the experimental data. It assumes that the
percent of capacity loss is a function of temperature and C-rate (or, equivalently,
current), and can be expressed as

where B0 and Ea are functions of C-rate, z = 0.55 is a constant parameter, and Ah
is the ampere-hour throughput, representing the amount of charge delivered by the
cell during cycling, that is

Qloss = B0 · exp

(cid:7)

(cid:6)
− Ea
Rθ

· Ahz

(cid:2)

Ah =

|I |
3,600 · Cnom

dt.

(13.12)

(13.13)

The range of applicability of the proposed model correspond to experimental
test conditions, i.e. constant C-rate and constant temperature. For the purpose of

As

it is

13 Optimal Energy Management of Automotive Battery Systems

227

this chapter, a generalization of life model to time-varying temperature and current
is necessary. The literature on this topic is still quite poor. RMS of current and
temperature over the cycle are used in [15]. Similarly, in [7] an effective temperature
and SOC are deﬁned, taking the place of constant values.

Here a different approach is proposed. The Eq. (13.12) assumes that I and θ are

constant. It can be derived with respect to the time, giving
(cid:7)

(cid:6)

d Qloss
dt

= B0 · exp

− Ea
Rθ

· d(Ahz)
dt

= z · B0 · exp

(cid:7)

(cid:6)
− Ea
Rθ

(z−1) · d(Ah)

.

· Ah

dt
(13.14)

(13.15)

d(Ah)
dt

=

|I |
3,600

,

d Qloss
dt

= z · B0 ·

(cid:6)

(cid:7)

|I |
3,600

· exp

− Ea
Rθ

· Ah

(z−1),

(13.16)

that is proposed here as a general differential life model. A similar differential
approach has been proposed in [8], where the aging model has been experimen-
tally validated on several vehicle usage scenarios. Unfortunately, considering this
aging model for the optimization problem, introduces explicitly the Ah in the objec-
tive function, making the optimal control solution very computationally intensive.
As a consequence, in order to simplify the problem, the Eq. (13.12) is modiﬁed by
deﬁning an auxiliary variable

Y = z · Q

1
z
loss

1
= z · B
z
0

· exp

(cid:6)

(cid:7)

− Ea
z Rθ

· Ah.

Applying the argumentations developed from Eqs. (13.14) to (13.16) to the new

variable Y , gives

1
˙Y = z · B
z
0

·

|I |
3,600

· exp

(cid:6)
− Ea
z Rθ

(cid:7)

,

which allows to deﬁne an approximated capacity loss as

˜Qloss = Y z =

(cid:6)(cid:2)

(cid:6)

1
z · B
z
0

·

|I |
3,600

· exp

− Ea
z Rθ

(cid:7)

(cid:7)

z

dt

.

Figure 13.4 compares Qloss as it predicted by (13.16) to ˜Qloss predicted by
(13.19). The results refer to the cell current proﬁle measured during the test dis-
cussed in Sect. 13.2. For the sake of completeness, the RMS approach is also shown
in the ﬁgure. The relationship between Qloss and ˜Qloss appears to be monotonic.
Moreover, a sufﬁcient quantitative agreement is observed between the reference and
the approximated capacity loss (a relative divergence of about 6 % is observed after

(13.17)

(13.18)

(13.19)

reference
approximation
RMS

228

0.2

0.15

0.1

0.05

]

%

[
 

s
s
o

l

Q

0

 

0

A. Sciarretta et al.

 

 

150

100

50

0

−50

]

A

[
 
t
n
e
r
r
u
C

 

−100

 

0

200

400

600

800

1000

1200

Time [s]

200

400

800

1000

1200

600
time [s]

Fig. 13.4 Comparison between reference capacity loss Qloss and approximated capacity loss ˜Qloss
(left) for a measured cell current proﬁle (right)

Measure
RMS

1,200 s). These considerations allow the use of the aging factor Y as an optimization
criterion in the rest of this study.

13.4 Optimal Control Problem Solution

The optimal control problem formulated in Sect. 13.3 is ofﬂine solved using two
different numerical techniques: dynamic programming and Pontryagin’s minimum
principle. While DP generally approaches better the global optimum (at least for
single-state problems), its computational burden increases dramatically with the
number of states. On the other hand, PMP needs initial values of the costates, which
however can be pre-tuned from the DP results, and its structure is closer to that of
an online-implementable solution.

13.4.1 Dynamic Programming

Dynamic programming is implemented following the DPM algorithm [16]. Time
step is 1 s. For the SOC state, 200 grid points equally spaced between 0 and 70 % are
deﬁned. A hard constraint on the ﬁnal SOC ξ f is implemented, with a tolerance of
±1 %. For the temperature state, 100 grid points equally spaced between θ0 − 5 and
θ0 + 10 are deﬁned. Final temperature is free. The control variable u is engine torque
and it is discretized in 23 values as follows. 20 values are equally spaced between the
engine minimum and maximum torque corresponding to the engine speed at current
time step. Additional three values are for ICE-only torque, zero torque, and ZEV
mode (both latter terms are zero, but in the ZEV case the engine speed is also set to
zero).

Discrete states, i.e., engine on/off state and gear engaged, are not considered in
the optimization in order to avoid excessive computational effort. Therefore, too
frequent engine start and stops cannot be regulated or avoided. This is a critical
point that has to be veriﬁed a posteriori and possibly treated using PMP. The gear
ratio is imposed with the drive cycle assuming the engine is on. If, however, the DP
chooses the ZEV mode, the engine is disengaged (its speed is set to zero) and the

13 Optimal Energy Management of Automotive Battery Systems

229

gearbox is set to the second gear. The gear shift laws are pre-computed as a function
of vehicle speed and acceleration pedal position. The latter is reconstructed from
the drive cycle by computing the wheel torque demand and using information on
maximum and minimum torque available from the powertrain at the current vehicle
speed.

Dynamic programming is executed either with both states (DP2) or with SOC
state only (DP1). In the latter case, ﬁrst DP is executed using a temperature constant
and equal to θ0. The energy management law u(t) calculated in this way is then run
against the complete model with variable temperature, and results are accordingly
recorded.

13.4.2 PMP

Pontryagin’s Minimum Principle (PMP) is used in order to ﬁnd a real-time imple-
mentable optimal solution to the energy management problem. The principle states
that the optimal control u(t) minimizes at each instant the Hamiltonian function,
which is derived from the criterion (13.2) and the state functions (13.3) as

H (u, w, ξ, θ, λξ , λθ ) = (1 − α) · ˙m f (u, w) · L H V + α · β · ˙Y (u, w, ξ, θ)

+ λξ Pech(u, w, ξ, θ) + λθ Pth(u, w, ξ, θ).

(13.20)

In this deﬁnition of the Hamiltonian, the terms fξ and fθ are converted into
power units by multiplication by the factors −CnomU0 and −MC, respectively,
resulting in the battery electrochemical power Pech = U0 · I and thermal power
Pth = −(qgen − qtra − qcool ), see Sect. 13.3.2.

Consequently, the adjoint state dynamics are given by the following equations:

CnomU0

˙λξ = ∂ H
MC ˙λθ = ∂ H

∂ξ = α · β · ∂ ˙Y
∂θ = α · β · ∂ ˙Y

∂ξ + λξ
∂θ + λξ

∂ Pech
∂ξ + λθ
∂ Pech
∂θ + λθ

∂ Pth
∂ξ ,
∂ Pth
∂θ .

(13.21)

(13.22)

PMP is executed either with both states (PMP2) or with SOC state only (PMP1).
In the latter case, λθ is identically set to zero. Moreover, the residual variation of λξ
is neglected, in order to recover the usual implementation of 1-state PMP, where λξ
is constant [1]. This approximation corresponds to neglect the inﬂuence of SOC on
the battery dynamics, see (13.21). As for the inﬂuence of SOC on the SOC dynamics
), it is usually neglected in the literature (e.g., in [5]) by virtue of
itself (the term
the fact that charge-sustaining HEV only use a small amount of battery charge. In the
case of this chapter, however, the application under study is a PHEV that, by its very
nature, is designed to operate the battery over a wide range of SOC. Therefore, the
validity of the aforementioned assumption will be checked a posteriori by observing
∂ ˙Y
∂ξ is justiﬁed here by the particular
the DP results, Sect. 13.5.1. Neglecting the term
model used (13.18), where the dependency of the parameters on SOC was shown in

∂ Pech
∂ξ

230

]
s
/
m

[
 

d
e
e
p
s
 

l

i

e
c
h
e
V

30

20

10

0

0

A. Sciarretta et al.

]

m
N

[
 

e
u
q
r
o

t
 
l

e
e
h
W

2000

1500

1000

500

0

−500

200

400

600

800

1000

1200

0

200

400

600

800

1000

1200

time [s]

time [s]

Fig. 13.5 Vehicle speed (left) and wheel torque (right) for the driving cycle considered in this
study

[6] to be negligible. The same is not necessarily true for other battery chemistries.
In those cases, (13.21) must be integrated as done in [4].

Similarly to DP, the energy management laws calculated with both PMP1 and
PMP2 are later run against the complete model with variable temperature, and results
are accordingly recorded.

13.5 Optimal Control Problem Results

Simulation results will be presented in the next two sections for several scenarii in
terms of θ0 and α. The driving cycle is the same for all simulations and it consists of
a 15 km-long fraction of a driving proﬁle recorded in the Italian Alps, with altitude
variations [17]. Vehicle speed and wheel torque demand are shown in Fig. 13.5,
together with gear setpoint. The latter quantity is calculated from gear shift laws and
actually realized if the energy management strategy chooses the engine to be on (as
explained in Sect. 13.4.1). The initial SOC is set to 60 %, while the target SOC is
20 %.

13.5.1 Dynamic Programming Results

Table 13.2 summarizes the results obtained with DP1 and DP2 for an ambient tem-
perature θ0 = 20 ◦C. Besides the values of α that deﬁne each single scenario, the
table lists three metrics and four additional quantities. The three metrics are the total
cost J and its two components, namely, the fuel energy E f and the aging factor Y
weighted by the transformation coefﬁcient β = 1 × 109. Since the ﬁnal SOC is not
exactly the same for all the tests (a tolerance of ±1 % was enforced in the DP coding),
raw results outputted by the DP corrected to compensate for SOC deviations from
the target value of 20 %. The correction rules are

13 Optimal Energy Management of Automotive Battery Systems

231

Table 13.2 Simulation results obtained with the DP for an ambient temperature of 20 ◦C
α

λ1(0)

λ2(0) max (cid:12)θ R M S(Pb)

DP J

E f
(MJ)

βY (cid:12)J
(%)
(MJ)

(MJ)

q f
((cid:13)/hkm)

Qloss
(%/hkm)

(kW)

1
0
0
2
1/3 1
1/3 2
2/3 1
2/3 2
1
1
2
1

7.2
35.7 35.7 19.9
0.2 7.2
35.7 35.7 20.4
7.3
30.0 35.9 18.3
0.1 7.3
30.0 36.2 17.7
23.6 37.0 16.9
7.5
23.5 37.5 16.5 −0.3 7.6
16.6 41.3 16.6
8.4
16.2 41.4 16.2 −2.2 8.4

0.75
0.76
0.72
0.70
0.69
0.68
0.68
0.67

(◦C)
6.4
2.09 –
6.7
2.13 0.45
0.92 –
5.8
0.61 −2.52 5.6
−0.19 –
5.4
−0.77 −5.26 5.0
−1.34 –
5.3
−2.17 −8.06 4.5

14.9
15.1
14.5
14.3
14.0
13.7
13.9
13.1

E f = E f,raw + λα=0
βY = (βY )raw + λα=1

ξ

ξ

(0) · (0.2 − ξ(T )) · (CnomU0(ξ0, θ0)),

(0) · (0.2 − ξ(T )) · (CnomU0(ξ0, θ0)),

(13.23)

(13.24)

where the costate values λα=0
(0) are the quantities shown in the table
for the scenarii α = 0 and, respectively, α = 1. The costate traces are calculated
from the value function outputted by the DP algorithm, according to their deﬁnition

(0) and λα=1

ξ

ξ

λξ (t) = −

λθ (t) = −

∂ V (t, ξ, θ)
∂ξ
∂ V (t, ξ, θ)
∂θ

(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)

·

1
CnomU0(ξ0, θ0)
· 1
MC

,

t,ξ ∗(t),θ ∗(t)

t,ξ ∗(t),θ ∗(t)

(13.25)

(13.26)

where the partial derivatives are calculated along the optimal state trace denoted by
starred variables and the scaling factors that make the costates non-dimensional are
added in the right-hand sides.

Together with the absolute value of the cost J , also shown are the relative variations
when switching from DP1 to DP2. The last quantities listed in Table 13.2 are the
maximum rise of the battery temperature during the test, and the RMS of the battery
power, both being the main factors that increase capacity loss. Figure 13.6 shows
time variations of the two states and the two costates obtained with DP2 and the four
values of α considered.

Several considerations arise from the analysis of these results. Firstly, it is evident
that the weighting factor α plays a fundamental role in modifying the nature of the
solution. An increase of α clearly yields a decrease of βY , with a simultaneous
increase of E f . The transition from more fuel-efﬁcient strategies (α = 0) to more
aging-reducing strategies (α = 1) is accompanied by a reduction of temperature
increase (max (cid:12)θ), also visible in Fig. 13.6, and a reduction of the root mean square
of the battery power (R M S(Pb)), as expected. Not shown in the table, the average
engine efﬁciency generally decrease with an increase of α. Starting from a baseline
strategy that is only sensitive to fuel consumption (α = 0), a signiﬁcant reduction

232

]

−

[
 
ξ

0.8

0.6

0.4

0.2

0

 

0

6

4

2

0

−2

−4

 

0

]

−

[
 

ξ

λ

α=0
α=1/3
α=2/3
α=1

A. Sciarretta et al.

 

 

α=0
α=1/3
α=2/3
α=1

α=0
α=1/3
α=2/3
α=1

DP1
DP2

α=0
α=1/3
α=2/3
α=1

]

C
°
[
 
θ

 

 

28

26

24

22

20

 

0

5

0

−5

−10

 

0

]

−

[
 

θ

λ

]
J
M

[
 

Y
 
β

20

19

18

17

16

200

400

600

800

1000

1200

200

400

600

800

1000

1200

time [s]

time [s]

200

400

600

800

1000

1200

200

400

600

800

1000

1200

time [s]

time [s]

Fig. 13.6 Traces of SOC (top-left), temperature (top-right), SOC costate (bottom-left), and tem-
perature costate (bottom-right) obtained with DP2

Fig. 13.7 Fuel energy versus
aging factor as calculated with
DP1 and DP2 (θ0 = 20 ◦C)

34

36

38

40

42

E

fuel

 [MJ]

of the aging factor is possible with increasing α, only with a relatively small fuel-
economy penalty. For example, switching to α = 1/3, βY can be decreased of about
10 %, while E f increases only of 1.4 %. The SOC costate λξ is almost constant during
the cycle, which justiﬁes the assumption introduced in Sect. 13.4.2 for the PMP
solution. Variations toward the cycle end are due to numerical reasons (unfeasible
states) and the emergence of regenerative braking (SOC is no longer regulated by the
control variable but by the disturbance). Its initial value decreases with an increase of
α and becomes negative for aging-reducing strategies. In fact, while fuel consumption
rate generally varies in the opposite direction as electric power consumption with
respect to u, aging factor rate exhibits the same trend (i.e., it is lowered by a lesser use
of the battery). The optimal compromise when the aging factor is the predominant
criterion is then found for negative values of the costate. The temperature costate λθ
has larger variations than the SOC costate and converges to zero at the end of the
cycle as predicted by the fact that terminal temperature is not constrained.

The effect of α on the two optimization criteria is made more visible in Fig. 13.7
that shows the curves E f –βY obtained with DP1 and DP2, respectively (note that

13 Optimal Energy Management of Automotive Battery Systems

233

Fig. 13.8 Variation of the
aging factor as a function of
battery temperature

200

150

100

50

]

W
k
[
 
t
d
/
Y
d
 
β

0

0

10

20

40

50

60

30
θ [°C]

the data concerning DP1 are much numerous than those shown in Table 13.2). The
ﬁgure clearly shows the asymptotic behavior of E f and βY for α tending to 1 and
0, respectively. In contrast to charge-sustaining HEV [4, 5], the asymptotic value
for βY does not approach zero because a positive net battery use is imposed by the
charge-depleting PHEV operation. The DP2 curve should be deemed as the Pareto
frontier of the multi-objective minimization of fuel energy and aging factor, in the
sense that points below the curve cannot be found in principle. The DP1 curve is
an approximation of the DP2 curve obtained with a simpler algorithm. It should be
reminded that what differs between these two cases is only how DP evaluates the
energy management strategy. Once the latter is evaluated, ﬁnal metrics such as E f
and βY are calculated by the two-state version of the system model in both cases.
Figure 13.7 and Table 13.2 show a very limited improvement with using DP2, facing
a much higher computational effort (for reference, running DP1 over the cycle takes
about 1 min on a 2.60 GHz personal computer, while DP2 takes approximately three
hours). The largest discrepancy is obtained for α = 1, where an improvement of
2–2.5 % is obtained in the cost J with DP2.

This result can be explained with the following considerations. Denote J [U, Θ]
the functional dependency of the cost function on the energy management law and the
temperature proﬁle (inﬂuence of SOC proﬁle is neglected in this analysis). Denote
Uk, Θk, k = {1, 2} the proﬁles obtained with DP1 and DP2, while Θ0 is the con-
stant temperature proﬁle. Consider the difference J [Uk, Θk] − J [Uk, Θ0]. When
α = 0, it vanishes since J = J [U ]. But such a difference increases for large α,
consequently to the variation of ˙Y with θ (illustrated in Fig. 13.8 for given values
of C-rate and SOC) and can reach, e.g., 20 % for 20 ◦C. To explain why the differ-
ence J [U2, Θ2] − [U1, Θ1] is much lower, it can be analyzed as the sum of two
effects, (J [U2, Θ2] − J [U2, Θ1]) + (J [U2, Θ1] − J [U1, Θ1]). The ﬁrst difference
is typically negative for α > 0 (controlled temperature proﬁles induce less aging).
However, the second term is typically positive for α > 0. In other terms, the beneﬁt
obtained with the former effect is partially compensated by the latter, which can
explain the relatively low gains of using DP2 instead of DP1.

On the other hand, as DP2 is intrinsically less robust than DP1, and very sensitive
to the gridding parameters, interpolation functions, etc. [18], the “true" two-state
optimum may not be reached. Such a consideration motivates the use of a different
technique, namely, PMP, to verify the two-state case.

234

A. Sciarretta et al.

PMP1−5°C
PMP2−5°C
PMP1−20°C
PMP2−20°C
PMP1−35°C
PMP2−35°C
PMP1−45°C
PMP2−45°C

]

−

[
 

Y
Y

/

f

e
r

1.3

1.25

1.2

1.15

1.1

1.05

1

0.95

32

34

36

38

40

42

44

E

fuel

 [MJ]

Fig. 13.9 Relative differences in aging factor versus fuel energy as calculated by PMP1 and PMP2

13.5.2 PMP Results

As described in Sect. 13.4.2, the difﬁculty in executing PMP resides in the evaluation
of the values λξ (for PMP1 and PMP2) and λθ (0) (for PMP2) for each scenario. In
this study, the calibration of λθ (0) follows from the DP2 result, while λξ is evaluated
with a root-ﬁnding algorithm targeting the condition ξ(T ) = 0.2.

Figure 13.9 summarizes the optimization results obtained with PMP. The ﬁgure
shows the Pareto frontiers for four ambient temperatures, namely, 5, 20, 35, and 45 ◦C,
with PMP1 and PMP2, respectively. Results are qualitatively and quantitatively close
to those shown in Sect. 13.5.1, for instance, the addition of a second state is as more
beneﬁcial as the weighting factor α increases. Two additional conclusions can be
drawn from these results. Firstly, larger relative improvements, with PMP2 with
respect to PMP1, are obtained for colder conditions. For example, the reduction
of βY with α = 1 is of only 1.5 % at 45 ◦C, which is likely below the precision
of the model forecast, but increases to about 5 % at 5 ◦C. The latter point is easily
explained observing the dependency of the aging factor rate ˙Y on the temperature θ ,
θ 2 exp(−1/θ),
which is ∝ exp(−1/θ). Consequently, the relative variation 1
˙Y
which is a decreasing function of θ . A second conclusion is that also the slope of the
Pareto frontier in the neighborhood of the baseline strategy α = 0 decreases as the
temperature increases. In other terms, the ratio of aging reduction on consumption
increase is worse at larger temperatures.

∂ ˙Y
∂θ ∝ 1

Figure 13.10 shows the variation of the initial values of the costates λξ (0) and
λθ (0) as a function of θ and α, both with PMP1 and PMP2. As already observed,
an increase of α induces a less aggressive use of the battery and, consequently, the
SOC target is obtained with a smaller λξ (which, per se, favors battery discharge).
An increase of θ0 induces higher aging and thus is also accompanied by a decrease
of λξ , again to compensate battery underuse. Only slight differences can be observed
between the values of λξ calculated with PMP1 and PMP2. A similar trend is observed
for λθ (0), whose values are generally larger (in absolute value).

235

λ
θ(0)

−

3

0

13 Optimal Energy Management of Automotive Battery Systems

−

2

−

2

−

1

−

5

λ
ξ(0)−PMP1
λ
ξ(0)−PMP2

−

8

−

5

−

1

0

−

2

0

]

−

[
 

α

−

1

0

0

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

1
1

2

0

5

−

1

0

0

1
1

−

2

−2

−1

−1

0

0

1
1

2

2

2

2

25
θ [°C]

−

2

]

−

[
 

α

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

5

−

5

−

5

−
1

−

2

−1
0
0

1
1

2

2

10

15

20

30

35

40

45

10

15

20

−

5

−

1

0

−

2

0

−2

0

−5

−2

0
30

25
θ [°C]

−10

−5

−2

35

40

0
45

Fig. 13.10 Costates (initial values) as a function of temperature and α

13.6 Conclusions

The study presented in this chapters has shown that energy management in HEV and
PHEV can be made sensitive to battery aging. Using a proper deﬁnition, an aging
factor can be adjoint to the fuel consumption into a combined cost function to be
minimized by the energy management law. By varying the relative weight of the
two cost functions, a more fuel-efﬁcient or a less battery-aggressive strategy can be
obtained. For PHEV, a substantial improvement in battery aging is expected to be
obtained at the expense of a few percent deterioration of fuel economy.

The chapter has also discussed the nature of the optimal control solutions. The
comparison of single-state (SOC only) versus two-state (SOC and temperature) solu-
tions has shown that the former is sufﬁcient in most cases, while the computational-
intensive addition of the temperature state has an added value only in the case of an
extremely aging-biased cost function. An explanation for this somehow surprising
evidence has been attempted. This result would suggest the use of single-state strate-
gies even to treat scenarios when minimization of aging is relevant. The behavior of
both costates has been explored as well. While the SOC costate is essentially constant
for an optimal solution, the temperature costate varies substantially in time, tending
to zero. Initial values of both costates have been shown to be monotonic functions
of ambient temperature, a property that could be useful in view of their estimation
in a real-time implementation of optimal control-based energy management.

The analyses and results presented have been computed for a given battery chem-
istry. Although not quantitatively generalizable to other battery systems, the main
trends shown are expected to remain valid. In particular, some simplifying assump-
tions introduced are expected to need reconsideration when treating the case of
chemistries with strongly SOC-dependent aging, combined with wide variations of
the SOC itself (as in PHEV).
Abstract This study presents an integrated energy and emission management strat-
egy for a Euro-VI diesel engine with Waste Heat Recovery (WHR) system. This
Integrated Powertrain Control (IPC) strategy optimizes the CO2-NOx trade-off by
minimizing the operational costs associated with fuel and AdBlue consumption,
while satisfying tailpipe emission constraints. The main contribution of this work is
that the optimal solution is determined numerically for a given cycle and is compared
with a real-time implementable strategy. Also, the WHR dynamics are explicitly in-
cluded in the control design. In a simulation study, the potential of this IPC strategy
is demonstrated over the World Harmonized Transient Cycle. It is shown that the
real-time strategy can be applied with negligible loss of optimality. Using IPC, an
additional 3.5 % CO2 reduction is achieved, while complying with the NOx emission
limit, when compared to a baseline strategy.
With the introduction of Euro-VI emission targets, current heavy-duty diesel engines
meet ultra-low emission levels. Although vehicles have become extremely clean,
fuel consumption levels have remained stable for the last two decades. To reduce fuel
consumption and to meet upcoming CO2 targets, heavy-duty diesel engines equipped
with Waste Heat Recovery (WHR) systems seem very promising, especially for long-
haul truck applications. This WHR system allows energy to be recovered from heat
ﬂows and to be converted into useful mechanical energy for propulsion. Up to 6 %
fuel consumption reduction has been demonstrated in [1, 2].

Most literature on WHR control focusses on low-level control, see, e.g., [3–7].
Only very few studies concentrate on energy management strategies for the complete
engine [8, 9]. For heavy-duty diesel engines with WHR system, studies that opti-
mize overall engine-aftertreatment-WHR system performance by minimizing total
operational costs and that explicitly deal with tailpipe emission constraints set by leg-
islation are lacking. We, therefore, present a cost-based optimization strategy, which
integrates energy and emission management: so-called Integrated Powertrain Control
(IPC). Contrary to earlier work on IPC in [10, 11], the optimal solution of Pontrya-
gin’s Minimum Principle is computed numerically and used as a benchmark for a
real-time implementable IPC strategy. Furthermore, WHR dynamics are explicitly
incorporated in the control model.

This work is organized as follows. First, the studied powertrain and applied mod-
els are presented in Sect. 14.2. Sections 14.3 and 14.4 discuss the developed IPC
strategies and their calibration, respectively. The results of these IPC strategies are
compared with the results of a baseline control strategy over a World Harmonized
Transient Cycle in Sect. 14.5. Finally, conclusions are drawn and directions for future
research are sketched.

14.2 System Description

Figure 14.1 shows a scheme of the examined engine platform. It is based on a state-of-
the-art 6 cylinder, 13 l, 340 kW Euro-VI diesel engine. This engine is equipped with
a turbocharger with Variable Turbine Geometry (VTG) and a high pressure Exhaust
Gas Recirculation (EGR) system with an EGR valve and EGR cooler. Furthermore,
an exhaust gas aftertreatment system is installed. This system consists of a Diesel
Oxidation Catalyst (DOC), a Diesel Particulate Filter (DPF) and an urea-based Se-
lective Catalytic Reduction (SCR) system. The DPF system ﬁlters the particulates
out of the exhaust ﬂow. To avoid clogging of the ﬁlter, the trapped particulates are
burned by periodically injecting fuel upstream of the DOC (DPF regeneration). The
remaining NOx emissions downstream of the DPF system are converted into harm-
less products over the Cu-Zeolite SCR catalyst. For this catalytic process, ammonia
(NH3) is required. This is formed upstream of the catalyst by decomposition of the

14 Optimal Control of Diesel Engines

239

Fig. 14.1 Studied Euro-VI engine with WHR system

injected aqueous urea solution (tradename: AdBlue) in the hot exhaust gases. To
avoid unacceptable NH3 slip, an ammonia oxidation (AMOX) catalyst is installed.
The Euro-VI engine platform is extended with a Waste Heat Recovery (WHR)
system. This system is based on a Rankine cycle and recovers thermal energy from
both the EGR and exhaust gas ﬂow using two evaporators. Note that the EGR evapo-
rator replaces the original EGR cooler. The expander converts this recovered thermal
energy into mechanical energy. It drives the two pumps and is directly connected
to the crank shaft, such that the recovered energy can be transmitted to the engine.
By using two bypass valves, the working ﬂuid ﬂow through the evaporators can be
individually controlled, such that the working ﬂuid is in vapor state downstream of
the evaporators. Furthermore, an expander valve is present to bypass the expander
in case no engine torque is requested (e.g., during braking or gear shifting) and to
avoid damage of the expander (when the working ﬂuid is in ﬂuid or two phase state).
In what follows, a distinction is made between the simulation model, which aims
at describing the main system characteristics, and the control model, which is a
simpliﬁed version of the simulation model allowing for a real-time implementation
of the control strategy. By using simpliﬁed control models, the proposed control
strategy is assumed to be robust with respect to unmodeled dynamics.

14.2.1 Simulation Model

The simulation model, which is used in this chapter to model the powertrain, con-
sists of models of an engine, a high-ﬁdelity aftertreatment system and a waste heat
recovery system. These models are described below in more detail.

240

14.2.1.1 Engine

F. Willems et al.

To describe the behavior of the exhaust gas mass ﬂow ˙mexh, the exhaust gas tem-
perature Texh, and the engine out NOx mass ﬂow ˙mNOx , steady-state engine maps
are used. These four-dimensional maps f (Ne, Φe, uEGR, uVTG) are constructed using
a validated mean-value engine model. For varying combinations of EGR valve po-
sition uEGR and VTG position uVTG, the fuel mass ˙mf is varied such that the engine
torque Φe is realized (for constant engine speed Ne [rpm]).

14.2.1.2 Aftertreatment System

A high-ﬁdelity aftertreatment model is implemented to simulate the DOC/DPF and
SCR system. This modular model is built up using one-dimensional submodels of a
pipe with urea decomposition, DOC, DPF, SCR, and AMOX catalyst. All catalyst
models are based on ﬁrst principle modeling and consist of mass and energy balances.
By dividing the catalyst in various segments, these validated models describe the
spatial distribution of pressure, temperature and chemical components. More details
on the model approach and accuracy can be found in [12].

14.2.1.3 Waste Heat Recovery System

Assuming an ideal low-level WHR control system, the WHR system dynamics are
described by a ﬁrst-order model with constant overall efﬁciency φWHR. This is in-
spired by the observed thermal dynamics in the studied engine. The recovered thermal
energy from both the EGR and exhaust gas ﬂow is given by:

d ˙QWF
dt

(cid:2)

= 1

τWHR

˙QEGR,g + ˙Qexh,g − ˙QWF

(cid:3)

and the EGR and exhaust gas heat ﬂows are deﬁned by, respectively:

˙QEGR,g = ˙mEGR · cp,EGR · (TEGR,in − TEGR,out)
˙Qexh,g = ˙mexh · cp,exh · (TSCR − Ttp)

This thermal energy is ﬁnally converted into mechanical power at the expander shaft:
⎧

PWHR = ΦWHR · αWHR =

φWHR · ˙QWF Φd,req > 0
Φd,req ≤ 0
0

with total required torque Φd,req and WHR output torque ΦWHR [see also Eq. (14.7)]. In
case no power is requested from the WHR system, the expander bypass is activated,
such that PWHR = 0.

(14.1)

(14.2)

(14.3)

(14.4)

14 Optimal Control of Diesel Engines

241

Table 14.1 Control model
parameters

Value

Constant Unit
Deﬁnition
cp,exh
kg−1
CDOC
cp,exh
kg−1
CSCR
s × kg−1
h
CSCR
Jg−1 K−1 φWHR · cp,EGR 100
Jg−1 K−1 φWHR · cp,exh 100

c1
c2
c3
c4
c5

0.1163
0.0512
7.692 × 10−4

Based on engine dynamometer data, a constant overall efﬁciency φWHR = 0.10,
a time constant τWHR = 60 s, and a constant post-WHR exhaust gas temperature
Ttp = 110 ◦C are chosen. Moreover, the values of TEGR,in and TEGR,out follow from
four-dimensional engine maps.

14.2.2 Control Model

This section presents the control model that is used in the optimal control strategy
of Sect. 14.3. For real-world implementation, this simpliﬁed model has to represent
the main system characteristics and has to be evaluated in real-time. Compared to
the simulation model, the main difference lies in the description of the aftertreatment
system. More precisely, the control model uses a simpliﬁed aftertreatment model,
which will be discussed below. Identical engine maps and a identical WHR model
as in the simulation model are used.

The thermal behavior of the total DOC-DPF-SCR-AMOX system is described by
two coupled differential equations, see Eq. (14.6). For the SCR conversion efﬁciency
φSCR, a combination of three stationary maps is used, which are determined for
= [0, 0.5, 1.0] and a speciﬁed
different pre-SCR concentration ratios CNO2
ammonia slip level. The individual SCR efﬁciency maps depend on the average SCR
◦C and space velocity SV 1/h:
catalyst temperature TSCR

/CNOx

SV = 3600

˙mexh
βexhVcat

(14.5)

with normal condition exhaust gas density βexh [g/m3] and SCR catalyst volume
Vcat [m3]. Using the predicted CNO2 /CNOx ratio from a stationary DOC efﬁciency
map, the NOx conversion efﬁciency φSCR is computed by interpolation. Finally, the
control model incorporates the WHR dynamics, which are given by Eqs. (14.1)–
(14.4).

In summary, the control model is written in state space form ˙x = f (x, u, t):

242

F. Willems et al.

Fig. 14.2 Scheme of the engine control system

⎪

⎨
⎨
⎢

˙x =

(cid:2)

1
τWHR

(cid:2)

(cid:3)

(cid:2)
c2 ˙mexh
(cid:2)
˙mNOx

(cid:3)

c1 ˙mexh
TDOC − TSCR
1 − φSCR(TSCR, SV , CNO2

Texh − TDOC
− c3

(cid:3)
TSCR − Tamb
(cid:3)
)
/CNOx

(cid:2)

⎡

⎣
⎣
⎤

(cid:3)

c4 ˙mEGR(TEGR,in − TEGR,out) + c5 ˙mexh(TSCR − Ttp) − PWHR

(14.6)
with state variables x = [TDOC TSCR mNOx,tpPWHR]T , in which TDOC and TSCR denote
the DOC/DPF and SCR temperatures, respectively, mNOx,tp denotes the cumulative
tailpipe NOx mass, and PWHR denotes the WHR power. The model parameter values
that are used in this chapter are speciﬁed in Table 14.1.

14.3 Control Strategy

Figure 14.2 shows a scheme of the proposed engine control system. The main objec-
tive of this control system is to determine the settings for the inputs ˙mf , ˙ma, uEGR and
uVTG, such that fuel consumption is minimized within the constraints set by emission
legislation. By assuming ideal torque management, the requested engine torque is
determined from:

Φe,req = Φd,req − ΦWHR.

(14.7)

In this control system, two subsystems can be distinguished: a supervisory con-
troller, which is described in this section, and a low-level SCR controller. Details
about this model-based ammonia storage controller can be found in [11].

To select suitable values for the aforementioned inputs, the Integrated Powertrain
Control (IPC) approach, which was ﬁrst introduced in [13], is used. This model-based
approach integrates energy and emission management by exploiting the synergy
between the engine, WHR and aftertreatment system. The developed IPC strategy
is compared with a baseline engine control strategy and with the optimal solution to

14 Optimal Control of Diesel Engines

243

the control problem, which serves as a benchmark. The examined control strategies
are described below.

14.3.1 An Optimal Control Approach to IPC

Following the IPC approach, the studied control problem is formulated in the optimal
control framework. We propose to minimize the total operational costs associated
with fuel and AdBlue consumption and active DPF regeneration, which can be ex-
pressed as follows:

⎦

te

min
u∈U

0

γf ˙mf + γa ˙ma + γPM ˙mPM dt

(14.8)

subject to Eqs. (14.6) and (14.7). In Eq. (14.8), u = [uEGR uVTG]T is the vector with
EGR and VTG valve positions, and U is the set of its allowable values. Moreover,
the following end point constraint on tailpipe NOx emission is imposed:

⎦

te

0

⎦

te

0

˙mNOx,tp dt ≤ ZNOx

1

3.6×106 Pd dt

(14.9)

In these expressions, the diesel price γf = 1.34 × 10−3 [Euro/g], AdBlue price
γa = 0.50 × 10−3 [Euro/g], and fuel costs associated with active DPF regeneration
per gram of accumulated soot γPM = 7.10 × 10−2 [Euro/g] are used. By explicitly
taking into account the operational costs, it is easy to deal with variations in fuel and
AdBlue prices. Moreover, the AdBlue mass ﬂow ˙ma is determined by assuming that
all injected urea decomposes in ammonia and is available for NOx conversion. As
such, the desired AdBlue dosage ˙ma g/s in Eq. (14.8) is given by:

˙ma = 2.0067 · φSCR(TSCR, SV , CNO2

/CNOx

) · ˙mNOx

(14.10)

Finally, the engine-out NOx emission ˙mNOx , the fuel mass ﬂow ˙mf , and the (equiv-
alent) cost of active DPF regeneration ˙mPM are determined by four-dimensional
steady-state maps.

14.3.2 Optimal IPC Trategy

The optimal control problem presented in Sect. 14.3.1 can be solved by applying
Pontryagin’s Minimum Principle, see, e.g., [14]. This principle relies on a Hamil-
tonian, which entails the (integrand of the) objective function from Eq. (14.8), aug-
mented with Lagrange multipliers λ and the state dynamics f (x, u, t) from Eq. (14.6):

244

F. Willems et al.

H(x, λ, u, t) = γf ˙mf (u, t) + γa ˙ma(x, u, t) + γPM ˙mPM (x, u, t) + λT f (x, u, t)

(14.11)
The Pontryagin’s Minimum Principle gives two necessary (and, under some as-
sumptions on the objective function, also sufﬁcient) conditions for uν ∈ U to be the
optimal control input along the optimal state trajectory xν. In particular, the optimal
uν ∈ U satisﬁes:

H(xν, λν, uν, t) ≤ H(xν, λν, u, t),

for all u ∈ U

(14.12)

where ˙λ = − εH
minimising Eq. (14.11) over all u ∈ U . The solutions to λ satisfy:

εx subject to λT (te)∂x(te) = 0. Note that Eq. (14.12) can be solved by

˙λ1 = c1 ˙mexhλ1 − c2 ˙mexhλ2 + dφSCR
dTDOC
˙λ2 = (c2 ˙mexh + c3)λ2 + dφSCR
˙mNOx
dTSCR
˙λ3 = 0
˙λ4 = 1
τWHR

λ4 − d ˙mf
dPWHR

γf − d ˙ma
dPWHR

(cid:2)

(cid:3)

λ3 − c6γa
(cid:3)

˙mNOx
(cid:2)
λ3 − c6γa

− c5 ˙mexh
τWHR

λ4

γa − d ˙mPM
dPWHR

γPM

(14.13a)

(14.13b)

(14.13c)

(14.13d)

subject to λ1(te) = λ2(te) = λ4(te) = 0. From Eq. (14.13a)–(14.13d), it can be
observed that the dynamics of λ1, λ2 and λ4 are unstable. Moreover, they have end-
point constraints. These two facts make the solution to this optimal control problem
difﬁcult to implement in practice, as it requires the entire drive cycle to be known a
priori. Still, the optimal solution, given by Eq. (14.12) and (14.13a)–(14.13d), will
be studied in this work to benchmark the approximate and real-time implementable
solution that we will propose below. Note that λ3 is an undetermined constant (as
˙λ3 = 0, while no end-point constraint is given), which has to be tuned over a drive
cycle to ensure that Eq. (14.9) is satisﬁed.

14.3.3 Real-Time IPC Strategy

As mentioned before, the optimal solution to the control problem is difﬁcult to imple-
ment in real time (as the drive cycle has to be known a priori). In particular, the main
difﬁculty lies in solving Eq. (14.13a)–(14.13d), not in solving Eq. (14.12). Namely,
the latter is a minimisation problem that can be solved using standard nonlinear pro-
gramming routines. Therefore, a real-time implementable IPC strategy is proposed
that is based on approximating Eq. (14.13a)–(14.13d), such that it can be computed
using real-time available information.

In the approximate solution that we propose in this chapter, the expression for
Eq. (14.13c) is kept and its value is tuned over representative drive cycles (with
cold and hot starts), and the solutions to Eqs. (14.13a), (14.13b), (14.13d) are ap-
proximated. In particular, the expression for Eq. (14.13d) subject to λ4(te) = 0 is
approximated by a suitably chosen (possibly nonzero) constant, which is also tuned

14 Optimal Control of Diesel Engines

245

Fig. 14.3 Heuristic rule for
λ1 and λ2 [15]

over representative drive cycles. The expressions for Eqs. (14.13a), (14.13b) are
replaced by the heuristic, postulated rule that was proposed in [15]. This rule is il-
lustrated in Fig. 14.3 and is parameterized by λT , ψT1 and ψT2. It will be shown in
Sect. 14.5 that these approximations, which are essential for arriving at a real-time
implementable IPC strategy, will cause only minor loss of optimality.

The rationale of the parametrization of Fig. 14.3 is that the effort taken to heat up
the aftertreatment system should be proportional to the SCR conversion inefﬁciency.
In case the DOC temperature is not signiﬁcantly higher than the SCR temperature, it
seems better to invest in raising the engine-out exhaust temperature rather than pro-
moting heat convection from the DOC/DPF to the SCR system (which corresponds
to a large λ1). The converse holds when the DOC/DPF temperature is signiﬁcantly
higher than the SCR temperature (which corresponds to a large λ2).

14.3.4 Baseline Strategy

In order to compare the results from the optimal control formulation, a baseline
engine control strategy is proposed that mimics a state-of-the-art air management
strategy for a standard Euro-VI engine conﬁguration (without WHR system). As in
[11, 15], this strategy is characterized by switching between two control modes:

1. Thermal management mode (M1) for rapid heat-up of the aftertreatment system

(TSCR < 200 ◦C);

2. Low NOx mode (M2) for normal operation (TSCR ≥ 250 ◦C).

A fundamental difference with IPC is that the baseline strategy relies on ﬁxed
control settings u for each engine operating point (Ne, Φe). For both modes, these
settings are pre-determined in an off-line optimization procedure, which is often
based on stationary test conditions.

As we want to use the same control structure for both strategies in simulations,
two different sets of constant λ are used for the control modes (see Table 14.2). As
engine calibration is mainly optimized using steady state-measurements, anticipated
steady-state TDOC and TSCR values from the engine maps are used in the Hamiltonian
to evaluate the SCR efﬁciency maps.

246

F. Willems et al.

Table 14.2 Selected control parameters

Control strategy

Baseline(-WHR)
Recal-WHR

Real-time

Optimal

Control parameters
−λ1,M1
1.40 × 10−3
1.36 × 10−3
ψT1
123
λ3,cold
2.76 × 10−2

−λ1,M2
0
0
ψT2
142
λ3,hot
8.53 × 10−3

14.4 Control Design

λ2
0
0
−λT
8.07 × 10−4

λ3
0.218
0.200
λ3
1.13 × 10−2

λ4
0
0
−λ4
2.97 × 10−6

This section discusses the calibration procedure of the optimal and real-time IPC
strategies. An overview of the selected control parameters is given in Table 14.2. For
details on the calibration of the baseline strategies, the interested reader is referred
to [11, 15]. Note that the baseline strategy will be applied to three cases:
• Conventional powertrain without WHR system (Baseline);
• Powertrain with WHR system using the same control strategy (Baseline-WHR);
• Powertrain with WHR system using a recalibrated control strategy (Recal-WHR).

As a result, two different sets of calibration parameters are used.

14.4.1 Optimal IPC Strategy

The optimal IPC strategy is completely determined by Eq. (14.12) and (14.13a)–
(14.13d). Because of this, and because λ1(te) = λ2(te) = λ4(te) = 0, only a value
for λ3 needs to be determined, such that Eq. (14.9) is satisﬁed for a given value for
ZNOx . This can be done, e.g., by performing a line search resulting in a cost-NOx
tradeoff curve (see also left-hand graph of Fig. 14.5). Note that, contrary to the real-
time IPC strategy, the optimal IPC strategy is not restricted to have the same λ3 for
both the cold and hot WHTC. The λ3 values that are given in Table 14.2 are tuned,
= 0.41 g/kWh is achieved for both the cold
such that the Euro-VI target of ZNOx
and hot WHTC.

Despite the fact that the optimal solution does not require much tuning, numer-
ically obtaining a solution to the optimal control problem is more difﬁcult. This is
due to the fact that the dynamics for λ1, λ2 and λ4 are unstable and have end-point
constraints. Numerically ﬁnding solutions to unstable differential equations is a te-
dious task, as not just the solution to the differential equation grows, but also the
approximation error of the numerical integration schemes. Therefore, the optimal
solution is computed using an iterative procedure: the so-called forward–backward

14 Optimal Control of Diesel Engines

247

sweeping method, which is adopted from [16]. For a given λ3 value, this iterative
procedure consists of repeatedly executing the following two steps:
(1) For given λ1, λ2, λ4, solve Eq. (14.6) with Eq. (14.12) from t = 0 to t = te
(2) For the x and u resulting from the previous step, solve Eq. (14.13a)–(14.13d) from

t = te to t = 0

The procedure has to be initialised with some λ1, λ2, λ4. Here, they are chosen to
be equal to zero. Under certain conditions, see [16], the algorithm converges, which
means that the optimal solution has been found. Note that the numerical complexity
of this iterative procedure is large, which is another reason why the optimal IPC
strategy is difﬁcult to implement in real-time.

14.4.2 Real-Time IPC Strategy

The real-time implementable IPC strategy is tuned using a numerical programming
routine. In this chapter, we use the Nelder-Mead simplex algorithm. The objective is
to ﬁnd the control parameters ψT1, ψT2, λT and λ3, such that the operational costs
are minimised over the hot WHTC. Simultaneously, the speciﬁed NOx engineering
target of 0.41 g/kWh has to be met for the weighted WHTC (where the cold and hot
cycle are weighted by 16 % and 84 %, respectively).

14.5 Simulation Results

To evaluate the performance of the controllers, simulations are done for the World
Harmonized Transient Cycle (WHTC). This test cycle speciﬁes the requested engine
speed Ne and torque Φd,req, see Fig. 14.4. Three parts can be distinguished: urban
driving conditions (0–900 s), rural driving conditions (900–1380 s), and highway
driving conditions. As we focus on Euro-VI legislation, results have to be generated
for cold as well as hot cycle conditions. In case of a cold cycle, the initial SCR
catalyst temperature is set to 20 ◦C, whereas 200 ◦C is used at the start of the hot
cycle; engine and WHR system heat up are not modeled yet.

In this study, we focus on the results of the optimal and real-time IPC strategy.
For reference, also the results for the baseline strategies are presented. All cases are
compared with the standard Euro-VI engine without WHR system (Baseline). The
main results are summarized in Table 14.3.

248

F. Willems et al.

World Harmonized Transient Cycle

0

200

400

600

800

1000

1200

1400

1600

1800

]

m
N

[
 
e
u
q
r
o
T

2000

1000

0

-1000

]

m
p
r
[
 
d
e
e
p
s
 
e
n
g
n
e

i

1500

1000

500

0

200

400

600

800

1000

1200

1400

1600

1800

time [s]

Fig. 14.4 World Harmonized Transient Cycle: speciﬁed torque Φd,req and engine speed Ne

]
o
r
u
e
[
 
t
s
o
C

 
l
a
t
o
T

9.55

9.5

9.45

9.4

9.35

9.3

optimal, cold WHTC
optimal, hot WHTC
realtime, cold WHTC
realtime, hot WHTC

]

%

[

 
2
O
C

100

98

96

94

92

90

baseline
baseline WHR
recal WHR
realtime
optimal

0.35

0.4

0.45

0.5
NOx tailpipe [g/kWh]

0.55

0.6

0.65

96

97

98

99

100

NOx tailpipe [%]

Fig. 14.5 Total operational cost-NOx,tp tradeoff for optimal IPC strategy (left) and CO2–NOx,tp
tradeoff for weighted WHTC (right)

14.5.1 Overall Powertrain Results

Following the procedure described in Sect. 14.4.1, the total operational cost-NOx,tp
trade-off curves for the optimal IPC strategy are determined (see left-hand graph
of Fig. 14.5). In the remainder of this section, simulation results are shown that
correspond to a tailpipe NOx emission of 0.41 g/kWh for both cold and hot WHTC.
The diamonds in this ﬁgure indicate the results after tuning the real-time IPC strategy.
For the weighted WHTC results, the CO2–NOx,tp tradeoff is shown in the
right-hand graph of Fig. 14.5. All results are compared with the baseline (without

14 Optimal Control of Diesel Engines

249

Table 14.3 Overview of WHTC results

Quantity

Baseline

Baseline
WHR

Control strategy
Recal
WHR

Real-time
WHR

Optimal
WHR

NOx,eo(g/kWh)
Hot
Cold
Weighted
NOx,tp(g/kWh)
Hot
Cold
Weighted
NH3,max(ppm)
Hot
Cold
CO2 %
Hot
Cold
Weighted
Hot WHTC costs %
Fuel
AdBlue
PM
Total

3.67
3.80
3.69

0.353
0.708
0.410

2
2

100
100
100

97.1
1.1
1.8
100.0

3.55
3.67
3.57

0.342
0.691
0.398

2
2

96.9
97.0
96.9

94.1
1.1
1.8
97.0

3.63
3.74
3.65

0.354
0.702
0.410

2
2

96.7
97.0
96.8

93.9
1.1
1.7
96.7

5.42
5.42
5.42

0.376
0.586
0.410

2
2

93.2
93.4
93.3

90.5
1.8
0.8
93.1

5.62
4.61
5.46

0.411
0.410
0.410

1
2

93.0
94.5
93.3

90.3
1.9
0.8
93.0

WHR). This ﬁgure shows that simply adding a WHR system to the existing engine
(Baseline-WHR) results in 3.1 % CO2 reduction. However, only a minor perfor-
mance improvement is possible by exploiting the margin in tailpipe NOx emission
(Recal-WHR): additional 0.1 % CO2 reduction, which is due to the reduced fuel
consumption over the hot cycle (see Table 14.3). Both the real-time and optimal IPC
strategy are able to reduce CO2 emissions by an additional 3.5 %. From these results,
it is concluded that the real-time strategy is a promising practical implementation of
the optimal strategy. In total, the CO2 saving potential of the WHR system sums up
to 6.7 %.

14.5.2 Cold Cycle Results

To better understand the differences between the studied strategies, time traces of the
results are shown in Fig. 14.6. We focus on the cold cycle, since this cycle is more
challenging and the differences are more distinct here. For the baseline strategies,
EGR valve and VTG settings are ﬁxed for each operating point (Ne, Φe) and each
engine mode. As can be seen from the SCR temperature plot, the controller switches

250

]
g
[
 

 

o
e

,
x

O
N

]
g
[
 
 

p
t
,
x
O
N

 
 
 
 
 
 
 
]

C
 
s
e
e
r
g
e
d

[
 
 

R
C
S

T

]

%

[
 

d
P

 
/
 

e
P

200

100

0

0

20

10

0

0

400

200

0

0

100

50

0

0

F. Willems et al.

Baseline
Baseline-WHR
Recal-WHR
Real-time
Optimal

500

1000

1500

500

1000

1500

500

1000

1500

500

1000

1500

500

1000

1500

0

500

1000

1500

]

%

[
 
l
e
u
F

 

]

%

l

[
 
e
u
B
d
A

 

]

%

[
 
t
s
o
C

 

10

0

-10

0

100

0

-100

0

10

0

-10

]

%

[

 
r
v
a
,
e

2

1

0

-1

0

500

1000

1500

500

1000

1500

Time [s]

Time [s]

Fig. 14.6 Cold WHTC results. Cumulative emission results and SCR temperature (left). Opera-
tional costs, fuel and AdBlue consumption and engine efﬁciency relative to the baseline (right)

from thermal management to low NOx mode around t = 550 s, when TSCR ≥ 250 ◦C
(see also λ1 in Fig. 14.7). This leads to similar cumulative engine-out and tailpipe
NOx emissions for the three baseline strategies.

Based on the actual state of the engine, aftertreatment and WHR system, the
adaptive IPC strategy selects on-line the EGR valve and VTG settings that gives the
lowest operational cost. In the ﬁrst part of the cold WHTC, this results in low engine
out NOx emissions due to relatively high EGR rates. After t = 600 s and especially
during the highway part, high SCR conversion efﬁciencies can be realized, so engine-
out NOx,eo emissions can be relaxed by reducing EGR ﬂow: so-called EGR-SCR
balancing (see upper left-hand graphs in Fig. 14.6). This leads to a considerable
increase in engine out NOx,eo emissions, but the tailpipe NOx,tp emission target is
still met. This effect is even more pronounced for the optimal strategy.

In the bottom left-hand graph of Fig. 14.6, the engine power-to-total power ratio
Pe/Pd is plotted. Although EGR and exhaust mass ﬂows and temperatures differ for
the studied control strategies, the observed differences are small. As expected, the
WHR contribution is largest in the high way part: average power output of PWHR =

14 Optimal Control of Diesel Engines

251

x 10-4

x 10-4

Baseline
Baseline-WHR
Recal-WHR
Realtime
Optimal

500

1000

1500

500

1000

1500

          

x 10-6
 
 

 

 

0

-5

]

K
/
o
r
u
e
[

-10

 
2

-15

-20

0

]

W
/
o
r
u
e
[

 
4

1

0

-1

-2

-3

-4

-5

-6

0

-5

 
]

K
/
o
r
u
e
[

 
1

-10

-15

0

0.3

0.2

0.1

0

]
g
/
o
r
u
e
[

 
3

-0.1

0

500

1000
Time [s]

1500

0

500

1500

1000
Time [s]

Fig. 14.7 Lagrange multipliers (cold WHTC)

4.9 kW for the IPC strategy. During the urban and rural part, the WHR system is
seen to be switched off frequently, according to Eq. (14.4).

The right-hand graphs of Fig. 14.6 show the corresponding fuel and AdBlue
consumption as well as the resulting operational costs over time. These results are
given relative to the baseline. At every time instant tk, the relative fuel consumption
is determined by:

ψFuel(tk) = 100 ×

(14.14)

(cid:10)

tk
0

˙mf − ˙mf ,Baseline dt
(cid:10)
tk
˙mf ,Baseline dt
0

In a similar way, the relative AdBlue and total operational costs are computed. As seen
from this ﬁgure, AdBlue injection starts around t = 400 s, when TSCR > 180 ◦C. In
the bottom right-hand graph, the moving average of the difference between engine
efﬁciency and baseline engine efﬁciency is shown:

ψφe,avg(tk) = φe,avg(tk) − φe,avg,Baseline(tk)

(14.15)

where:

φe,avg(tk) =

(cid:10)
tk
0 Pe dt
(cid:10)
tk
0 Pfuel dt

252

F. Willems et al.

with Pfuel = ˙mf × QLHV and the lower heating value QLHV of diesel.

As shown in the upper right-hand graphs of Fig. 14.6, implementation of the WHR
system reduces fuel consumption in all studied cases. For the baseline strategies, this
is achieved with only small changes in AdBlue consumption. The IPC strategies can
further reduce fuel consumption and total operational costs. By on-line adaptation of
the EGR valve and VTG settings, a cost optimal balance is found; although AdBlue
consumption is signiﬁcantly increased, it only has a small (absolute) contribution
to the total operational cost due to its relatively low mass ﬂow and cost. The cor-
responding high SCR efﬁciencies φSCR allow for high engine-out NOx emissions,
which are associated with reduced fuel consumption. Consequently, the reduced fuel
(and PM) costs compensate for the increased AdBlue costs. Results for the engine
efﬁciency illustrate that the adapted EGR-VTG settings in the IPC strategy lead to
1.0–1.5 % increase in engine efﬁciency compared to the baseline. This effect is most
dominant during the highway part. For the baseline strategies with WHR system,
efﬁciency improvements are negligible over the cold WHTC.

Figure 14.7 shows the resulting Lagrange multipliers for the examined strategies.
For the three baseline strategies, these values are chosen to be (switching) constants.
Note that λ4 = 0 for the baseline strategies, as the WHR dynamics are neglected in
these cases. Comparison of the IPC strategies learns that the chosen λ4 value in the
real-time strategy is a good approximation of the co-state dynamics associated with
the optimal case. This also holds for the λ1 dynamics. However, the implemented
heuristics for λ2 are not capable to approximate the corresponding optimal co-state
dynamics. In the optimal strategy, λ2 > λ1, which means that heat convection is
promoted to heat up the aftertreatment system. This only holds for short periods in
the real-time strategy; focus is on raising the exhaust gas temperature for most of
the time. Based on these results, this Lagrange multiplier is believed to have only a
minor effect on overall powertrain performance.

14.6 Conclusions and Future Work

Optimal control of a Euro-VI heavy-duty diesel engine with Waste Heat Recovery
(WHR) system is challenging due to the high number of sub systems, interactions
and requirements set by emission legislation. To optimize overall performance, an
integrated approach is required which combines energy and emission management.
Based on the Integrated Powertrain Control (IPC) approach, an optimal control strat-
egy is presented, which minimizes total operational costs and explicitly deals with
the tailpipe NOx emission constraint. Following Pontryagin’s Minimal Principle,
the optimal solution for a cold and hot WHTC is numerically determined using a
forward–backward sweeping method. Alternatively, a real-time implementable strat-
egy is proposed. From simulation results over the WHTC, it is concluded that the
optimal IPC strategy can be replaced by the proposed real-time strategy with negli-
gible loss of optimality. This IPC strategy outperforms the current baseline engine
control strategy: an additional 3.5 % CO2 reduction within the tailpipe NOx limit.

14 Optimal Control of Diesel Engines

253

Current research concentrates on the robustness of the IPC strategy performance
for model uncertainties and varying duty cycles. Tests will be performed on an engine
dynamometer to demonstrate the potential of the proposed control strategy.
Abstract In this chapter we consider a class of optimization problems arising in the
process of automotive engine mapping and calibration. Fast optimization algorithms
applicable to high ﬁdelity simulation models or experimental engines can reduce the
time, effort and costs required for calibration. Our approach to these problems is based
on iterations between local model identiﬁcation and calibration parameter (set-points
and actuator settings) improvements based on the learned surrogate model. Several
approaches to algorithm implementation are considered. In the ﬁrst approach, the
surrogate model is deﬁned in a linear incremental form and its identiﬁcation reduces
to Jacobian Learning. Then quadratic programming is applied to adjust the calibration
parameters. In the second approach, we consider a predictor-corrector algorithm that
estimates the change in the minimizer based on changing operating conditions before
correcting it. Case studies are described that illustrate the applications of algorithms.

15.1 Introduction

The chapter is concerned with automating the process of internal combustion engine
mapping and calibration using real-time optimization techniques. As the engine com-
plexity is growing to meet more stringent fuel economy and emissions regulations
and increasing customer demands for improved drivability, the interest in techniques
for reducing engine calibration time and effort has been rapidly increasing [4, 11–13,
18–21, 25].

The engine mapping process involves engine characterization to identify compo-
nent static response and calibration optimization which refers to determining optimal
set-points and actuator settings given current engine operating conditions. The set-
points are stored in look-up tables in the strategy or incorporated into the regression
models.

Several approaches have been proposed to address engine calibration optimiza-
tion. In more traditional approaches, the data are ﬁrst collected from the engine, then
regressed and the optimization is performed on the resulting regression models to
ﬁnd the optimal set-points and actuator settings. Extremum seeking, based on var-
ious types of optimization algorithms running in real-time on the engine, has been
exploited in [11, 13, 20, 21, 25]. Finally, techniques where transient data are rapidly
collected to identify a dynamic model and this dynamic model is used for static
calibration optimization have been recently developed [3]. Besides automotive
engines, calibration optimization of aircraft gas turbine engines has been also
considered [17].

In this chapter we discuss another approach to engine calibration which is based
on iteratively combining the local identiﬁcation and local optimization steps. This
approach follows [7] (see also [8, 23]). Speciﬁcally, we employ real-time learning of a
surrogate model to locally characterize engine response around the current operating
point and then we perform an optimization update to improve the parameters and
actuator settings with respect to the identiﬁed surrogate model, see Fig. 15.1.

If the surrogate model is deﬁned as a linear incremental form, the surrogate model
identiﬁcation reduces to estimating the Jacobian and we employ the Jacobian Learn-
ing (JL) technique proposed in [7]. See also [8] for a related approach.

The approach of [7] has not been previously applied to engine calibration and
optimization problems. In this chapter, we present its extension to the case when
there are constraints, and we demonstrate its capability to rapidly ﬁnd minimizers
based on a high ﬁdelity GT-Power engine model.

A further extension of the algorithm is presented to achieve high accuracy in ﬁlling
the calibration tables when operating conditions are (slowly) varying. This extension
is based on treating the calibration optimization as a parameter-dependent optimiza-
tion problem [2, 6, 9, 19, 22], and applying a predictor-corrector approach. The

15 Learning Based Approaches to Engine Mapping and Calibration Optimization

259

predictor part of the algorithm feed-forward compensates for changes in the mini-
mizer with changing engine operating conditions while the corrector part improves on
the predicted minimizer. As an illustration, the application of the predictor-corrector
algorithm to a series HEV model is considered.

The chapter is organized as follows. In Sect. 15.2, we highlight the mathematical
problem formulation. In Sect. 15.3, the JL-based optimization algorithm of [7] is
described. The results of applying this approach to a high ﬁdelity engine model in
GT-Power using the co-simulation approach are presented in Sect. 15.4. Another
case study is considered in Sect. 15.5, where engine fuel consumption minimiza-
tion is performed on-board of a simulated series hybrid vehicle when the generator
power is maintained at a constant value during the learning and optimization phase.
In Sect. 15.6, we present the predictor-corrector algorithm and in Sect. 15.7 we
illustrate its application to engine fuel consumption minimization on-board of a sim-
ulated series hybrid vehicle when the generator power is slowly varying. Concluding
remarks are presented in Sect. 15.8.

15.2 Mathematical Problem Formulation

From a calibration perspective, a typical engine can be considered as a MIMO nonlin-
ear system with adjustable actuator settings and/or modes of operation as inputs, and
performance characteristics as outputs. The steady-state input-output relationship at
different steady state operating conditions can be described as

y = F(u, p),

(15.1)

where the input vector u includes adjustable actuator settings—spark retard, intake
valve opening/closing (IVO/IVC) and exhaust valve opening/closing (EVO/EVC)
settings of the VCT actuator, throttle and wastegate settings, exhaust gas recircula-
tion valve opening (EGR), air-to-fuel ratio, etc.; output vector y consists of engine
performance characteristics—brake torque (equivalently, engine load), brake spe-
ciﬁc fuel consumption (BSFC), Crank Angle 50 (CA50), etc. and p is a vector of
operating conditions, e.g. engine speed and target engine brake torque (equivalently,
target engine load).

Many engine-related calibration problems can be reduced to minimizing a certain

function with respect to a part of variables:

Minimize Q(u, p) with respect to u,

(15.2)

and often the function Q(u, p) can be speciﬁed as

Q(u, p) = ||F(u, p) − yt ||2

Ω = (F(u, p) − yt )TΩ(F(u, p) − yt ),

(15.3)

260

D. Filev et al.

where yt is the vector of target values for the output vector, y, Ω = Ω T ≥ 0 is
weighting matrix, and for a vector z, ||z||2

Ω = zTΩz.

In ﬁlling the calibration tables, the minimizer in (15.2) is sought in the form

dependent on p, i.e., in the form,

u = u∗( p).

(15.4)

For instance, Q can represent a weighted sum of BSFC squared (for which the
corresponding BSFC target is zero) and squares of the deviation between some of
the components of the output vector y and a corresponding set of target values of
engine load, e.g. engine load and its target value, CA50 and its target, etc. We note
that we do not assume that the targets are achievable.

There are several distinct characteristics of the optimization problem (15.2) for
static engine calibration. Firstly, if the optimization is performed directly on an
experimental engine, the measurements of the function Q are uncertain due to sen-
sor measurement noise and due to deviations of engine operation from steady-state.
The latter source of noise is exacerbated if it is desirable to move rapidly through
the operating conditions, p, without waiting for engine to completely reach the
steady-state. This latter source of noise is also present if the optimization is
performed on an engine model, such as a high ﬁdelity GT-Power engine model, where
in addition the evaluation of the function Q can be expensive due to slow model sim-
ulations. Consequently, special care is required in the application of the optimization
algorithms and techniques to engine-related optimization problems (15.2).

15.3 Jacobian Learning Based Optimization Algorithm

In this section we focus on the problem of engine mapping at steady state, for given
operating conditions, i.e. assuming p = const in (15.1). In this case, F is assumed
to be nonlinear but smooth, the output vector, y, represents a set of performance vari-
ables, e.g., Brake Speciﬁc Fuel Consumption (BSFC), engine load, Crank Angle 50
(CA50), etc. The engine mapping problem is decomposed to a set of local mappings
obtained at speciﬁc operating conditions, p,

y = ˜F(u) = F(u, p),

(15.5)

where u is an r -dimensional vector, and y is a q-dimensional vector. We are interested
in an approach for solving problem (15.2) that exhibits fast convergence so that it
can be repeatedly applied at different p.

We consider a local surrogate model based on a linearized time-varying (Jacobian)

approximation of the nonlinear input-output mapping ˜F in (15.5),

Δy(k) = J (k)Δu(k)

(15.6)

15 Learning Based Approaches to Engine Mapping and Calibration Optimization

261

where

Δu(k) = u(k) − u(k − 1), Δy(k) = y(k) − y(k − 1),

and J (k) is the q × r Jacobian matrix deﬁned by

Js, j (k) =

(k), 1 ≤ j ≤ r, 1 ≤ s ≤ q.

∂ ys
∂u j

The surrogate model takes the form,

ˆy(k) = y(k − 1) + ˆJ (k − 1)(u(k) − u(k − 1)),

(15.7)

where ˆJ (k) is the estimate of the Jacobian of ˜F at the time instant (k − 1). The
optimization algorithm solves the following Quadratic Programming (QP) problem,

u(k) = argmin(||yt − ˆy(k)||2

Ω + ||u(k) − u(k − 1)||2

Γ ),

(15.8)

subject to (15.7) and the constraints on the range of actuator settings,

umin ≤ u(k) ≤ umax .

(15.9)

Note that (15.8) includes a penalty on the increments of u which prevents the opti-
mization algorithm from taking too large steps that render the Jacobian approximation
ˆJ (k − 1) inaccurate. In our numerical experiments, we typically used Ω = I and
Γ = γ I, where γ is a tunable parameter in (15.8).

We note that the problem (15.8) with the simple box-like constraints (15.9) is a
low dimensional quadratic programming problem that can be easily solved using any
quadratic programming solver. In our numerical experiments, we use the functions
quadprog.m and lsqlin.m of Matlab. We also note that (15.8) without the constraints
on the ranges (15.9) is easily solvable and leads to an update of the form

u(k) = u(k − 1) +

ˆJ T(k − 1)Ω ˆJ (k − 1) + Γ

ˆJ T(k − 1)Ω(yt − y(k − 1))

(cid:2)

(cid:3)−1

= u(k − 1) + K (k − 1)(yt − y(k − 1)).

(15.10)

Since

ˆJ T( ˆJ ˆJ T + ρ Iq×q )−1 = ( ˆJ T ˆJ + ρ Ir ×r )−1 ˆJ T,

the updates in (15.10) are similar to the one studied in [7] for the case r ≥ q, which
had the form,

u(k) = u(k − 1) + ˆJ T(k − 1)H

ˆJ (k − 1) ˆJ T(k − 1) + ρ Iq×q

(yt − y(k − 1))

(cid:2)

(cid:3)−1

= u(k − 1) + ˜K (k − 1)(yt − y(k − 1)),

(15.11)

262

D. Filev et al.

where ρ > 0 and H is a diagonal q × q gain matrix. Note that both (15.10) and
(15.11) are variants of Levenberg-Marquardt optimization algorithm. The diagonal
matrix Γ > 0 in (15.10), typically chosen as Γ = ρ Ir ×r , where Ir ×r is the r × r
identity matrix, or the term ρ Iq×q in (15.11), where I is the q × q identity matrix,
play the role of the Tikhonov regularization matrices [24]. Their use improves the
numerical conditioning of the underlying inverse problem.

We employ the Kalman ﬁltering for recursively learning ˆJ . Speciﬁcally, let Js
denote the sth row of the Jacobian, J, 1 ≤ s ≤ q. The following model is assumed
as a basis for estimating ˆJs,

Js(k + 1) = Js(k) + ws(k),

Δys(k) = Js(k)Δu(k) + vs(k),

(15.12)

where ws(k) is the process noise representing the imprecision of the linearized model
with zero mean and the covariance matrix, Qs ≥ 0, and vs(k) is the measurement
noise with zero mean and covariance matrix, Rs > 0. The Kalman ﬁlter updates take
the following form,

ˆJs(k) = ˆJs(k − 1) + L s(k)
(cid:2)

(cid:2)

Δys(k) − ˆJs(k − 1)Δu(k)

(cid:3)

,
(cid:3)−1

L s(k) = Ps(k − 1)Δu(k)

Rs + ΔuT(k)Ps(k − 1)Δu(k)

,

(15.13)

Ps(k) = Ps(k − 1) − L s(k)ΔuT(k)Ps(k − 1) + Qs.

The matrix Qs is a drift factor that is analogous to the forgetting factor in the com-
monly used form of the Recursive Least Squares (RLS) [1] and can be estimated from
the expected changes in the Jacobian. The advantage of using the drift factor versus
the exponentially forgetting factor is in the cases when the system is not excited
[7, 16]. It forces the covariance matrix, Ps (which essentially controls the variable
learning rate of the Kalman ﬁlter) to grow linearly rather than exponentially.

The advantage of (15.13) versus alternative techniques for estimating the Jaco-
bian (e.g., based on the center differences) is that it can be used with general input
excitation sequences; in many practical cases, the Jacobian can be estimated from
the optimization algorithm iterates. The use of nonlinear surrogate model rather than
(15.6) can be advantageous in speciﬁc problems; however, we found that (15.6) rep-
resents an effective choice, in general. Further comments on exploiting nonlinear
surrogate models are made in Sect. 15.6.

15 Learning Based Approaches to Engine Mapping and Calibration Optimization

263

15.4 Case Study 1: Application to Engine Mapping

In order to reduce the development time and costs, engine models are used more and
more frequently to evaluate engine designs without building the actual hardware. A
two step procedure is typically used to compare different engine designs: (1) optimal
settings of all actuators at different engine conditions (speed/load) are determined
that result in the best performance (e.g., minimum fuel consumption) at each con-
dition; (2) the overall performance is compared as quantiﬁed by a weighted sum of
performances at different engine conditions where the weighting factors may reﬂect
the time spent at a particular operating condition over a drive cycle. For Step 1, Design
of Experiments (DoE) based sweeping of actuator settings, followed by off-line data
processing is employed to ﬁnd the optimal actuator settings at each engine conditions.
This approach is not very efﬁcient, especially as new engine technologies are intro-
ducing signiﬁcant numbers of new actuators. At the same time, more detailed engine
models that more accurately predict the response of the new engines are becoming
more complex and take increasingly longer time to simulate. Even though improve-
ments in computing hardware and parallel computing are alleviating the problem to
some extent, fast and smart searching/optimization methods applicable to simulation
models are highly desired to speed up this process.

For our case study, the JL-based algorithm described in Sect. 15.3 has been applied
to rapidly determine the actuator settings that are optimal for each steady-state oper-
ating condition based on an engine model implemented in GT-Power. The GT-Power
is a well established engine CAE tool provided by Gamma Technologies and is a
popular modeling software package used by engine designers and system developers.
Our algorithm has been implemented in Simulink and co-simulated with the engine
model running in GT-Power. The co-simulation environment has been setup so that
the engine model runs continuously, and model steady-state output data are sent to
the optimization algorithm, which then updates the Jacobian estimate (i.e., surrogate
model), and, consequently, the actuator settings as discussed in Sect. 15.3.

In this case study, the nonlinear vector function, F in (15.1), represents Brake
Speciﬁc Fuel Consumption (BSFC), Engine Load, and CA50 (deﬁned as the crank
angle after top dead center at which 50 % of fuel is burnt). The input vector u
represents throttle position, spark timing, intake cam timing, and exhaust cam timing.
The target vector yt for y prescribes the target of 0 for BSFC, the target load the
engine should be running at, and the target value for CA50 based on the standard
correlation between CA50 location and best fuel efﬁciency. The parameter vector p
comprises engine speed and target engine load.

Table 15.1 summarizes the results of an exemplar algorithm application. Our
engine model is running at ﬁxed speed of 3,000 rpm. The CA50 target at this engine
speed is 5.54◦. The target engine load values are 0.2, 0.5, and 0.8, which change every
time algorithm convergence is achieved. The targets, found optimal actuator settings,
achieved values of engine load, CA50 and BSFC, and the number of optimization
iterations are given for three load targets in Table 15.1.

264

D. Filev et al.

des

Table 15.1 Calibrated engine variables for 3,000 rpm and target engine loads of 0.2, 0.5 and 0.8
Rpm Load CA50 Throttle Spark
Iterations
Spark
−75.00
27.00 34.88
−39.91
9.00 39.00
−26.95 −32.30 39.00

Exhaust Load CA50 BSFC
cam

1106.74 16
285.62
4
253.77 10

3,000 0.2
3,000 0.5
3,000 0.8

7.15
15.62
90.00

0.20
0.50
0.80

5.66
5.63
5.51

5.54
5.54
5.54

Intake
cam

des

Adaptive rErI
Adaptive aErI

Adaptive rEaI
Fully Advanced

Intake
Adaptive aEaI
Fully Retarded

Adaptive rErI
Adaptive aErI

Exhaust
Adaptive aEaI
Fully Retarded

Adaptive rEaI
Fully Advanced

)
g
e
d
(
 

O
V

I

390.00
380.00
370.00
360.00
350.00
340.00
330.00
320.00

)
g
e
d
(
 

C
V
E

410.00
400.00
390.00
380.00
370.00
360.00
350.00
340.00
330.00

0.2

0.3

0.7

0.8

0.2

0.3

0.7

0.8

0.4
0.5
0.6
Target Load

0.4
0.5
0.6
Target Load

Fig. 15.2 Optimized intake and exhaust cam timings at different loads, when initialized at four
different combinations (both retarded, both advanced, and one retarded/one advanced)

Table 15.2 The intake and exhaust cam timings that deliver the best BSFC at different loads

Load

Intake
Exhaust

0.2

387
391.9614

0.3

387
399

0.4

327
399

0.5

327
399

0.6

327
399

0.7

366.8997
383.7112

0.8

327
391.9786

We note that the cam timing optimization is challenging because the effects of cam
timing on the BSFC are not monotonic, and dependent on the engine torque outputs,
as shown in [14]. Therefore, applying the algorithm with different initial conditions
of the cam timings will yield local minimizers (that may not necessarily be global
minimizers). The conventional approach is to run a sweep of the intake/exhaust cam
timings to ﬁnd the best BSFC, which is very time consuming. In this work, we
applied our JL-based algorithm but initialized the cam timings at several different
values; we then selected the actuator settings that gave the best BSFC over these
runs. Figure 15.2 shows the best IVO and EVC at different loads all at 3,000 rpm,
when initialized at four different initial values.

Combining all the results, the best intake and exhaust cam timings at each loads

are summarized in Table 15.2.

The results show that the optimal exhaust cam should be fully retarded or close
to being fully retarded for all the cases. The optimal intake cam is retarded at lower
loads, and advanced at higher loads. These results are consistent with [14].

The algorithm was applied next to the same engine model to complete a full map
that ﬁnds the best throttle/spark/intake cam timing/exhaust cam timing settings. The

15 Learning Based Approaches to Engine Mapping and Calibration Optimization

265

400

390

380

370

360

350

340

)
g
e
d
(
 

C
V
E

330

320

330

340

360
350
IVO (deg)

370

380

390

Fig. 15.3 Identifying a smooth CAM track through clustering the optimized CAM settings

algorithm runs fast and converges at all conditions, except for a high speed low load
target that is not a feasible operating point for this engine. It takes on average 12
iterations at each point.

The results of optimal CAM settings across all the speed/load points can be
summarized in Fig. 15.3. By clustering the CAM settings, we can obtain the CAM
track that can be implemented in production strategy so the actual CAM positions
are not commanded to change signiﬁcantly during normal operations.

15.5 Case Study 2: On-board Fuel Consumption

Optimization in Series HEV

As another case study, we consider ﬁnding online engine operating points that min-
imize fuel consumption for the speciﬁed constant engine/generator power request,
Pr eq
eng in a series hybrid electric vehicle. We note that in hybrid electric vehicles, the
battery power can complement engine power during such a learning phase to ensure
the requested time-varying electric motor power at the wheels; thus learning of opti-
mal operating points can be performed on-board without causing driver disturbance.
As in [10], an estimate of the engine power can be used that is generated by an input
observer based on the measurements of the engine speed and generator power, where
the latter is estimated based on the measurements of the current in the generator. The
battery power output is controlled as to ensure that the wheel power matches the
driver demand by complimenting the estimated generator power. After learning is
completed, the optimal operating points can be used in the power smoothing strategy
proposed in [5, 15].

266

Fig. 15.4 The time history of
BSFC improvement in a series
HEV

D. Filev et al.

We consider the case when the engine has to meet the target of ﬁxed engine
power, Pr eq
eng while minimizing the BSFC. The vector u consists of throttle angle,
spark timing, engine speed, intake valve opening and exhaust valve closing timing.
Note that the engine speed is varied by the optimization algorithm, and therefore,
the actual torque target varies with it, as shown in Fig. 15.5. With the assumption of
constant Pr eq
eng , the application of the Jacobian Learning based optimization algorithm
of Sect. 15.3 yields the responses shown in Figs. 15.4, 15.5, 15.6, 15.7. The plots
show the power target is tracked and BSFC is minimized, while all actuators converge
to the optimal values.

In order to reduce battery State of Charge ﬂuctuations during on-board learning
and reduce learning time, it is desirable to track the fuel consumption minimizer in
slow transients, i.e., when Pr eq
eng is slowly-varying. To realize such a functionality,
predictor-corrector algorithms are considered next.

15.6 Predictor-Corrector Algorithm

The updates in Sect. 15.3 can be generalized to the case of the parameter-dependent
optimization (15.2), (15.3) when parameters are slowly varying. With the surrogate
model based on estimated Jacobians, we assume that

Δy = ˆJuΔu + ˆJpΔp.

(15.14)

This leads to the following update in the case of no control bounds,

(cid:2)

u(k) = u(k − 1) +
(cid:2)

ˆJ T
u

(k − 1)Ω ˆJu(k − 1) + Γ

ˆJ T
u

Ω

(cid:3)−1

(cid:3)

×

− ˆJp(k − 1)( p(k) − p(k − 1)) + yt − y(k − 1)

.

(15.15)

15 Learning Based Approaches to Engine Mapping and Calibration Optimization

267

Fig. 15.5 The time history of engine power (top, left), engine torque and torque set-point (top,
right), and engine speed (bottom). Engine torque set-point is generated to achieve desired power

Fig. 15.6 The time history of spark timing and throttle position

Note that the update (15.15) incorporates prediction for the change in the solution
due to the parameter change which is due to the term, ˆJp(k − 1)( p(k) − p(k − 1)).
The Jacobian ˆJp is estimated with the Kalman ﬁlter using the same approach as for
ˆJu in Sect. 15.3.

In the case of constraints,

yc = g(u, p) ≤ 0,

(15.16)

268

D. Filev et al.

Fig. 15.7 The time history of intake valve opening and exhaust valve closing

Jacobian Learning can be applied also to constraint learning based on a surrogate
constraint model,

Δyc = ˆguΔu + ˆg pΔp.

(15.17)

By denoting the vector of active constraints by superscript a, the update is based on
solving a system of linear algebraic equations,

(k − 1)Ω ˆJp(k − 1)( p(k) − p(k − 1))

ˆJ T
u

(k − 1)Ω Ju(k − 1) + Γ )(u(k) − u(k − 1))
(k − 1))T(λa(k) − λa(k − 1)) = 0

(k − 1)Ω(y(k − 1) − yt ) + ˆJ T
u
+ (J T
u
+ ( ˆga
u
ˆga(u(k − 1), p(k − 1)) + ˆgu(k − 1)(u(k) − u(k − 1))
+ ˆga
p

(k − 1)( p(k) − p(k − 1)) = 0,

(15.18)

with respect to u(k) and the vector of Lagrange multipliers of the active constraints,
λa(k). Care needs to be taken to handle changes in the set of active constraints. The
change in the set of active constraints can be detected if as a result of the update
(15.18) some of the components of the vector λa(k) become zero or negative or if
some of the constrained outputs predicted according to (15.17) change sign. In such
a case, (15.18) is applied with ˜p(k) = αp(k) + (1 − α) p(k − 1) replacing p(k),
where 0 < α <1 corresponds to the ﬁrst predicted change in the sign of any of
Lagrange multipliers or constrained outputs (15.16); the corresponding ˜λa(k) and
˜u(k) are determined based on (15.18); (15.18) is re-conﬁgured for a different set
of active constraints; and the process is repeated with p(k − 1) replaced by ˜p(k),
λa(k − 1) replaced by ˜λa(k) and u(k − 1) replaced by ˜u(k).

As another extension, the surrogate model (15.14) can be replaced by a more gen-
eral nonlinear model and the minimization problem (15.2) can involve an arbitrary,
sufﬁciently smooth function Q(u, p), i.e., not necessarily (15.3). A more general
form of the predictor-corrector algorithm for minimizing the function Q(u, p) with
respect to u in the unconstrained case can be based on Newton’s method,

15 Learning Based Approaches to Engine Mapping and Calibration Optimization

269

u(k) = u(k−1)+ ˆQ−1
uu

(k−1)(− ˆQu(k−1)− ˆQup(k−1)( p(k)− p(k−1))), (15.19)

where the partial derivatives are evaluated at u(k−1) and p(k−1). The update (15.19)
requires that the Hessians of Q be estimated on-line. Under appropriate assumptions
and if gradients and Hessians of Q are accurately known, constants α > 0 and β > 0
can be found such that the tracking error of the minimizer satisﬁes a relation of the
form,

||u(k +1)−u∗( p(k +1))|| ≤ α||u(k)−u∗( p(k))||2 +β|| p(k +1)− p(k)||. (15.20)

This relation suggests strong, quadratic convergence properties to the minimizer if
p(k) stays constant and strong tracking properties of the minimizer if the parameter
p(k) is slowly-varying. In the constrained case, the Newton’s method can be applied
to the root ﬁnding problem resulting from KKT conditions augmented with an extra
equality constraint. We discuss a case study where this approach was followed in the
next section and leave it to future work to explore its details and properties further.

15.7 Case Study 2 (Cont’d): On-board Fuel Consumption

Optimization in Series HEV

The application of (15.19) to identiﬁcation of Optimal Operating Points (OOP) line,
i.e., engine speed and engine torque values that minimize BSFC for a given Pr eq
gen , is
shown in Figs.15.8, 15.9. Here u is the engine speed and p = Pr eq
gen is slowly varying
as shown in Fig.15.8. The advantage of handling slowly varying Pr eq
gen during learning
is that battery SoC ﬂuctuations are reduced. The function Q is the BSFC and the
surrogate model for it is assumed to be second order in the two variables (engine
speed u and p = Pr eq
gen ). Small amplitude random excitation has been added to u(k)
and p(k) to facilitate the identiﬁcation of surrogate model parameters. The algorithm
is able to rapidly converge to OOL and follow it as the generator power is varied.
See [10] for further details. We note that a version of HEV model in Simulink was
used for experimentation with (15.19) differently from GT-Power model which we
used for the results in Sect. 15.5. The OOL is required for implementation of the
power smoothing strategy [5, 15], and as our results demonstrate, it can be learned
on-board without creating driver disturbance.

15.8 Concluding Remarks

In this chapter we have considered an iterative optimization approach that combines
the steps of real-time learning of a surrogate model and then performing optimization
with respect to the identiﬁed model. In the case when the surrogate model is given in a

270

Fig. 15.8 The time history of
engine/generator power

D. Filev et al.

Peturbed Profile
Actual Profile

70

60

50

40

30

20

)

W
k
(
 
r
e
w
o
P
 
e
n
g
n
E

i

10

0

50

100

150
Time (sec)

200

250

230

220

205

250

200

150

100

50

)

m
N

(
 
e
u
q
r
o
T
 
e
n
g
n
E

i

240

250
260

400

500

210

220

230

250

260

270

280

290

300

Engine BSFC Map
Predicted Optimum Operating Points
OOL
Maximum Engine Torque

600

700

800

900

1000

0
1000

1500

2000

2500

3000

3500

4000

4500

Engine Speed (RPM)

Fig. 15.9 The engine speed and torque superimposed on engine map

linear incremental form, we refer to such a method as Jacobian Learning (JL)-based.
The algorithm derivation has been presented and we demonstrated its application to
a case study of mapping an engine represented by a detailed GT-Power simulation
model. Results have shown that the proposed algorithm can be used as an efﬁcient,
robust, and generic tool for fast engine calibration optimization in the case of ﬁxed
operating conditions providing the optimal actuator settings in less than 20 iterations
for the engine model considered. Since the surrogate model is learned from data and
no assumption on the type of engine model is made, the methodology can be applied

15 Learning Based Approaches to Engine Mapping and Calibration Optimization

271

to virtually any type of engine, including diesel engines and aircraft gas turbine
engines.

We have also presented a case study showing that such an approach can be applied
on-board in an HEV, and considered its various extensions, including a potentially
faster predictor-corrector form of the algorithm, and the treatment of more general
types of surrogate models. These will be further considered in the future work.
Abstract Nonlinear system identiﬁcation requires informative data obtained from
experiments in order to parameterise a model of the underlying process. As an
example for the automotive industry, good models for NOx and smoke emissions
are required to effectively calibrate modern combustion engines. With continuously
increasing complexity in terms of the number of variation channels available in the
engines the experimental effort provides a growing challenge for efﬁcient calibra-
tion. Design of Experiments (DoE) refers to optimal excitation of the system in order
to maximise the knowledge gained for a process under investigation from a limited
amount of measurements. We introduce a methodology that omits measurements
unrelevant for calibration via pre-speciﬁcation of restrictions on the inputs as well as
the outputs. Output restriction to a certain target region is obtained via a supervising
online model that is trained during the workﬂow. The distribution of input samples
obtained via this method is non-uniform over the pre-image of the target region. The
effectiveness of this concept is demonstrated for the modeling of NOx and smoke
emissions of a diesel engine.
Stationary optimisation of combustion engines is an important task especially at the
beginning of a calibration project. For heavy-duty engines it at the same time provides
the basis for stationary legislative testruns (e.g. ESC, the European Stationary Cycle).
For transient emission cycles representative stationary operating points form the base
for dynamic modeling procedures.

The increasing number of control parameters brings along new challenges for data
collecting procedures. Test-plans for the system exciting parameters are required to
minimise the amount of measurements while maximising the informative value of
the experiments. The goal of these experiments is usually to gain knowledge on emis-
sions such as NOx and smoke, or other variables, e.g. fuel consumption. Legislative
constraints however usually restrict emissions below some bounds, making large
amounts of combinations of control variables redundant for the experiment. In this
context online DoE is considered to be a very effective method in order to acceler-
ate the workﬂow of engine calibration. The term online refers to an adaptive process
where the experiment is planned during the workﬂow according to the current knowl-
edge obtained by the measurements. More speciﬁcally, an online evolving model is
used as it has been proposed in [1]. Here, the workﬂow is accompanied with the online
training of efﬁcient methods to estimate the input-output relation, see Fig. 16.1 for
an illustration. This enables us to restrict a number of outputs to predeﬁned, cus-
tom output ranges (COR) [2]. In each iteration step we invert the currently trained
model to ﬁnd the pre-image of the COR regions. The design for future experiments
is then chosen to some distribution over this pre-image. Maximin-Euclidian-distance
designs would converge to a uniform distribution. Designs according to the input–
output distance lead to a distribution that is less dense for ﬂat output behavior. The
model is re-trained after each measurement, thereby improving the model quality in
areas that are most relevant for calibration, see [3].

The procedure is demonstrated on veriﬁcation results for NOx and smoke emis-
sions as well as fuel consumption. In Sect. 16.2 we introduce the problem we faced
using the state of the art DoE approaches. We give a precise description of our meth-
ods in Sects. 16.3 and 16.4. Sections 16.5 and 16.6 demonstrate model improvements
after applying the so called COR DoE procedure.

16.2 State of the Art Development Approach

To assess the beneﬁts of the new method, which will be described in the following
sections, consider the following example of the a test plan evaluation of a modern
passenger car diesel engine in a single operating point. One standard optimisation
task on such common-rail engines is to optimise the fuel consumption while keeping
the legislative limits for NOx and soot emissions within the prescribed driving cycle.

16 Online Design of Experiments in the Relevant Output Range

275

Online DoE

Iterative DoE strategy:
sample selection in COR
from a candidate set

new design point

Application of
design point to
system input

new training data

current model, cf. equations

Incrementation of k

OnlineTraining

Structure evolution and
parameter optimization

Set of applied data
from previous cycle

Fig. 16.1 Interaction between online DoE and online training for COR

Fig. 16.2 AVL CAMEO™ DoE screening procedure

The optimisation was performed w.r.t. to ﬁve varying control parameters (variation
parameters henceforth) within the ECU (engine control unit):

• Rail Pressure
• Main Injection Timing
• Boost Pressure
• EGR (Exhaust Gas Recirculation)
• Swirl Position.

To take into account constraints on the drivability, such as component tempera-
tures, cylinder peak pressure, combustion stability etc., we use the DoE-Screening
technique [4]. Here, the engine starts from a stable center point and changes the
ECU-settings step by step in starlike directions until system limits are reached or a
limit violation occurs. In case that a limit occurs, the strategy offers different reac-
tions and measures the variation point as near as possible to this limit, see Fig. 16.2
for an illustration. The ecu variations within the convex hull of the drivable points
and possibly within some external input restrictions then constitute the candidate
input set. The task for the DoE strategies is now to ﬁnd the ecu variations within this
set that have maximum informative value for our purposes. Our measurements are

276

N. Didcock et al.

Fig. 16.3 NOx and soot output estimation for random and pareto optimal inputs

double-checked via repetition measurements. This guarantees that we can assure the
quality of our measurement devises and a stable workﬂow of the engine.

As state of the art DoE method a D-optimal design (see e.g. [5]) was calculated
for the ﬁve variation parameters and measured using AVL CAMEO™, see [6]. Using
these 59 variation points (plus 8 repetition points) output models were built and the
output estimates for NOx and soot were calculated, see Fig. 16.3. The ﬁgure shows
how the output behaves for random sampling of input variations. Obviously, we are
most interested in the pareto optimal values in the bottom left area. A large amount
of input variations is therefore negleglible for calibration purpose and should be
avoided during the test run.

We performed additional measurements to verify the model quality for the opti-
mised input variations. As can be seen in Figs. 16.5 and 16.6, the fuel consumption
and NOx emissions for the veriﬁcation variations (solid, gray points) can be pre-
dicted with the same quality the training data (circles). The achieved residuals are
at the same time comparable with the variance of the measured repetition points
(solid, black points) which indicates the model error is mainly measurement error.
However, evaluating the smoke emissions, it can be seen in ﬁgure Fig. 16.6 that for
some optimisation points the model underestimates the smoke values signiﬁcantly.
Since these regions are highly relevant for calibration the model quality needs to be
particularly improved here. This motivated the development of a strategic DoE that
aims to improve model quality for relevant output areas. We performed additional
measurements to verify the model quality for the optimised input variations. As can
be seen in Figs. 16.5 and 16.4, the fuel consumption (BSFC) and NOx emissions for

16 Online Design of Experiments in the Relevant Output Range

277

Fig. 16.4 Measured versus predicted plot for break speciﬁc fuel consumption (BSFC) after a D-
optimal design

the veriﬁcation variations (solid gray points) can be predicted with the same quality
the training data (circles). The achieved residuals are at the same time comparable
with the variance of the measured repetition points (full, black points) which indi-
cates the model error is mainly measurement error. However, evaluating the smoke
emissions, it can be seen in ﬁgure Fig. 16.6 that for some optimisation points the
model underestimates the smoke values signiﬁcantly. Since these regions are highly
relevant for calibration the model quality needs to be particularly improved here. This
motivated the development of a strategic DoE that aims to improve model quality
for relevant output areas.

16.3 Mathematical Background of the COR Design

We now present a general framework for model based DoE where the estimated
model is to be kept as general as possible. We commence with the task to draw a
ﬁnite sample from an input space U . We are interested in the estimation of the map
: u ≤∈ y for some one dimensional output such as NOx , soot or BSFC. Let uk
f

278

N. Didcock et al.

Fig. 16.5 Measured versus predicted plot for NOx after a D-optimal design

and yk denote the measurements of inputs and outputs, respectively. We assume that
the output has the form

yk = y(uk) = f (uk, θ ) + ε(uk) = fk + εk

Let fk denote the deterministic component, depending on the parameters θ , and εk
the non-systematic measurement error. The parametric form of the model component
has to be chosen appropriately for the data. Examples are the linear-in-parameters
θ for some regression vector ϕ and parame-
regression model fk = ϕ(uk)T θ = ϕT
k
ters θ , neural networks or local linear models, see e.g. [7]. Noise is assumed to be
independent and identically distributed with zero mean and equal variance σ 2. The
model component is estimated from a sample S = [s1 . . . sn] where n denotes the
number of samples and sk denotes the index for the kth sample. The error covariance
depends heavily on the input design US = [us1
] where we use the equivalent
notations yS and εS. The output estimator ˆyk = f (uk, ˆθ ) depends on the parame-
ter estimator ˆθ . The parameter variance and therefore the model variance depend
heavily on the inputs usk . In the OLS/GLS model the parameter covariance depends
exclusively on the inputs.

. . . usn

16 Online Design of Experiments in the Relevant Output Range

279

Fig. 16.6 Measured versus predicted plot for smoke emissions after a D-optimal design

16.3.1 A Local Model Architecture

We brieﬂy present a local model architecture that we have used for the estimation of
the mappings in the application example presented. We use a Takagi-Sugeno fuzzy
model architecture as in [8]. Locally, in a region indexed by j, the output for uk is
modeled as a full quadratic function of the input, the local estimate shall be denoted
ˆy j,k = ˆy j (uk). The validity function η j,k = η j (uk) denotes the proportion of the
local model estimate relative to the overall estimate which is then composed as the
weighted sum of I local outputs,

ˆyk =

η j,k ˆy j,k

I(cid:2)

j=1

The coefﬁcients θ j according to the regressor of the jth local model can be
estimated as the WLS estimator weights η j . The weights correspond to a partitioning
of the input space in regions that are dominated by one local model each. With a
growing number of observations the parameters of the model are updated and, if
necessary, the number of local models is increased incrementally, see [8] for details.
Note, however, that our proposed concepts are not restricted to this speciﬁc type of
model.

280

N. Didcock et al.

16.3.2 State of the Art Designs

Ideal designs of input excitation signals maximise the information content of our
experiments. However it is not obvious what should be regarded as the informa-
tion content. Model based DoE maximises the information gain w.r.t. the precision
of the estimated parameters of some model structure, see [9] and [10] for details.
Model based DoE is basically related to Fisher’s concept of information. The Fisher
Information matrix in its general form is deﬁned as
(cid:3)(cid:4)
(cid:4)

(cid:5)(cid:6)

(cid:5)

IF (θ, S) = E

∂ log p(YS|US, θ )
∂θ

T

∂ log p(YS|US, θ )
∂θ

S

...ysn

Where YS = [ys1

] denotes the sample output. Its inverse, the Cramer-Rao-
Bound, is an upper bound for the covariance of any unbiased parameter estimator.
Optimal designs are based on optimising some functional on the Fisher matrix SF =
J (I (θ, S)) such as the determinant (D-optimality), the trace (A-optimality)
arg max
or the maximum value of the diagonal entry (G-optimality). In [11] it is pointed out
that D-optimal designs tend to lie on boundaries which we ﬁnd mischievous since
the boundaries of our inputs tend to become undrivable. In comparison, so called
maximin designs use a distance measure to the design space as the informative value
or the experiment, e.g. the Euclidian distance,

(cid:7)

d2(uk, u j ) =

(uk − u j )T (uk − u j )

Maximin designs then fulﬁll

Smax min = arg max

min
uk ∞=ul ≈US

d2(uk, ul

)

S

See [11] for a general introduction to maximin designs. In particular it should be
noted that Euclidian maximin distance designs converge to a uniform distribution
over the input space. In [12] the equivalence between D-optimality and maximin
designs is shown when the distance measure is chosen appropriately.

16.3.3 Online Procedures

Our method differs substantially from these state-of-the-art DoE procedures. We
are not primarily interested in the training a model or a uniform coverage of the
input space. Our aim is to collect testbed data that is relevant for application and
we therefore need a procedure that incorporates knowledge on outputs such as NOx
emissions or exhaust temperature that are, more likely than inputs, constrained to
lie in some region of interest. In [13–16], DoE methods w.r.t. relevant output levels

16 Online Design of Experiments in the Relevant Output Range

281

are presented. Here, one is interested in a certain (single) level set of the output, e.g.
where some system failure occurs. Model accuracies are improved for this critical
value of interest. We do not restrict our target outputs to one speciﬁc value but to an
applicable set of values. Moreover, the distribution of the design points in the input
space is not asymptotically uniform, but depends on the output as well. With our
method we obtain measurements that are more dense where the output is less ﬂat.

We train our model with measurements from a standard initial design such as a
central composite designs (CCF) and a DoE screening procedure. These methods are
useful for determining the input space as the drivable area of the engine. After the
initial design we run an online design procedure where the measurements inﬂuence
the position of the following design points. At each time step we augment the sample
St by a number of observations such that St ≡ St+1 and USt
≡ USt+1 . The proposed
designs in Sect. 16.3.2 do not take into account the measurements YS since the
distance criteria in general depend on the inputs only. We ﬁnd it important for our
design to leave out regions that are of no particular interest. Take for instance the
modeling of smoke particles then we are less interested in regions where the emission
rate is low but model accuracy in high emission areas becomes crucial.

16.4 Design Strategies

Although maximin designs in the input space are easy to calculate they suffer from
the drawback of entirely ignoring the structure of the model. Our work involves the
estimation of various output components of combustion engines where we found this
strategy inefﬁcient due to the existence of trivial output areas that need not be explored
exhaustively. In order to reduce the number of observations to a minimum we want to
reject experiments that yield little information. We focus on two extensions to state
of the art methods. First, we want to omit design points in areas where the output
becomes trivial to avoid unnecessary costs. When the output is comparably ﬂat we
need fewer observations than when the mapping is more complex. Second, bearing
legislative constraints in mind we constrain the experiment to yield measurements
in a relevant region. In the following we discuss the two extensions in detail.

16.4.1 A Distance Criterion in the Product Space

We modify the distance criterion according to [17]. We use a distance design with
respect to the inputs as well as the output. The method proved to measure the output
dynamics more efﬁciently than other concepts. Let X denote the product space of
) ≈ X and X S the set
inputs and estimated outputs U × ˆy with elements xk = (uk, ˆyk
which ﬁrst components are the sample inputs. We deﬁne the input–output distance
as

282

N. Didcock et al.

(cid:7)

dI O (xk, x j ) =

(xk − x j )T (xk − x j )

and the input output maximin design as

SI O−max min = arg max

min
xk ∞=xl ≈X S

dI O (xk, xl

)

S

This simple extension helps to concentrate the design in areas where the output is
less ﬂat. Take for example an input region where the output grows fast with respect
to the input, then the distances will become comparably large. Therefore maximin
distances will concentrate on regions with higher output escalation, that is, where
the output either increases or decreases relatively fast. By reducing the number of
observations made in trivial regions we raise the relevant model performance relative
to the number of measurements.

16.4.2 The Custom Output Region (COR)

Second, we try to force the output measurement to lie in a given region of interest.
The calibration of combustion engines is subject to fulﬁll legislative constraints
and we therefore ﬁnd high estimation precision required in the drivable areas with
relevant emission rates. Again, the design procedure depends on the estimated output
since we need to have an idea where the relevant emissions are located. Running an
online strategy we use the latest trained model to identify the inverse image of the
output region of interest. We force the design to be placed in this region in the next
design step. We commence from the candidate in put set uk ≈ U cand e.g. from the
previously described screening procedure, a model estimate ˆyk as well as the Custom
Output Region, for example an interval COR = [ymin, ymax]. Next, we compute the
candidate set that is expected to lie in the COR and result in the ﬁnal candidate set
Ucand,COR = {uk|uk ≈ Ucand, ˆyk ≈ COR}. Finally, we calculate an input-output-
maximin design strategy over this set.

16.4.3 The iDoE Strategy

The methodology is illustrated on a simple academic example in Fig. 16.7. Large parts
of the input space map to a constant output that—by assumption—is not of interest.
In contrast, the relatively small areas where there is more ﬂuctuation in the output
are considered highly relevant. A standard Maximin DoE Procedure is compared to
the IO-Maximin DoE procedure after the online application of ten design points. The
standard space ﬁlling approach fails to measure in the areas where the output shows
its characteristic behavior. Contrarily, if we apply a COR DoE and deﬁne the COR
region between 0.2 and 1 the points are distributed more in the non-trivial areas,
providing the model is good enough to estimate a precise pre-image of the COR.

16 Online Design of Experiments in the Relevant Output Range

283

(a)
y

1
0.8
0.6
0.4
0.2
0
-0.2

four local models
system
model
10
u11

four local models
system
model
10
u11

(b)
y

1
0.8
0.6
0.4
0.2
0
-0.2

8

6

4

2

3

2

1

0
Φ

.
q
e
r
F

1

0

x

u

0
Φ

.
q
e
r
F

3
2
1
0

x

u

0

0.2

0.4

0.6

0.8

1

0

0.2

0.4

0.6

0.8

1

Fig. 16.7 Comparison of model and process after the online application design points with different
DoE

What can also be observed is that the distribution of the applied points is not uniform
in the input space. It is due to the modiﬁed distance criterion that design points are
applied evenly on the output graph.

We call the combination of these two extensions the iterative DoE (iDoE) strategy,
see [18]. The term iterative stresses the fact that the design sequence is updated after
every measurement through the estimation update of the output ˆy. Although both
extensions - the augmented distance criterion as well as the COR procedure—work
independently, we combine the tools to generate a powerful strategy that

• avoids unnecessary repetition points,
• favors areas with less ﬂat output behavior
• generates outputs in a desired output range.

16.5 Improved Development Approach using the COR Design

We now demonstrate the usefulness of our methodology using the same diesel engine
as in Sect. 16.2. Since model building and therefore our online procedure requires
data, the method needs an initial design. A CCF (Central Composite Faced) design
which consisted of 42 variation points (plus 7 repetition points) was chosen. This
initial design was measured using the screening strategy, giving one measurement at
the variation point or near the drivability limit plus a second measurement on the way
back to the center point. Based on these 91 measurements a model was calculated
and online re-iterated during the iDoE test. The necessary measurement time for
the automated test was approximately 10 % higher compared to the state of the art
procedure. see Table 16.1. But after the application of only ten iterative design points
an acceptable model quality can be achieved for all relevant output regions.

284

N. Didcock et al.

Table 16.1 Measurement time comparison for D-optimal design and COR DoE: additional time
spent on the online procedure can be seen as negligible

# Variation points Time/measurement (min) Total measurement time (min)

D-optimal
Repetition points

59
8

Startdesign
42
2nd measurement 42
7
Repetition points
iDoE
10
2nd measurement 10

4
1

4
1
1
4
1

236
8
244
168
42
7
40
10
267

Fig. 16.8 Measured versus predicted plot for smoke emissions after a COR design

Using the state of the art D-optimal design the veriﬁcation measurements of the
optimised points resulted in residuals of up to 1.5 FSN (see Fig. 16.6). Using iDoE
and COR design, the highest residuals of the same veriﬁcation measurements could
be reduced by 66 % to a maximum of 0.5 FSN (see Fig. 16.8) whereas the repetition
measurement of the (more stable) center point showed a measurement deviation of
±0.2 FSN.

16 Online Design of Experiments in the Relevant Output Range

285

Fig. 16.9 Modeled ECU variation parameters

16.6 Further Improvement

Further improvement of the model accuracy for all models can be achieved when a D-
optimal initial design is chosen. For this example 47 measurements were performed
which is the suggested amount of points for 5 variation parameters expecting a 3rd
oder polynomial behavior.

Model accuracy can be improved if the ECU variation parameters are not directly
used as input channels for model estimation. Instead, we use channels that are,
from a physical understanding of the combustion process, more likely to explain
the response variables. E.g. the estimated ECU channels for boost-pressure, injec-
tion timing and EGR were exchanged by the measured intake-manifold pressure, the
MFB 50 % (mass fraction burned 50 %) which can be measured with an indicating
device (AVL IndiCom™) and the EGR rate, measured with an emission bench. The
necessary values for the according ECU channels are still available after the optimi-
sation in case models are calculated for them. This means that these original ECU
variation parameters are not seen as variation channels any more but as response chan-
nels during the optimisation. Usually already simple 2nd order polynomial model
approaches can ﬁt their behavior well, this is illustrated in Fig. 16.9.

Finally, the model quality can be increased continuously when adding additional
iterative design points as described in Sect. 16.5. As a measure of model ﬁt we
calculate a leave one out estimator, denoted R2 pred (predicted). During the testrun,
the R2 pred does not change signiﬁcantly which shows that the model structure is
ﬂexible enough for ﬁtting the measurement data, see Fig. 16.10. A second measure,
the root mean squared error on veriﬁcation points, denoted RMSE*, decreases the
more iterative points are measured. We see that the model quality in the relevant area

286

N. Didcock et al.

Fig. 16.10 R2 and RMSE* for modeled smoke calculated for different numbers of iDoE points

Fig. 16.11 Model quality for smoke using physical variation parameters and 30 iterative design
points

becomes more accurate during the test. In this example, 30 iterative design points
would be sufﬁcient to decrease the RMSE* to less than 0.2 FSN.
The measured versus predicted plot is shown in Fig. 16.11. The residual for the
worst veriﬁcation point in this case is 0.3 FSN which means an improvement by
80 % compared to the state of the art procedure. The necessary measurement time
increases by ≥ 60 % (see Table 16.2) which is still reasonable and so 9 stationary

16 Online Design of Experiments in the Relevant Output Range

287

Table 16.2 Measurement time comparison for D-optimal design and COR DoE with 30 iDoE
points

# Variation points Time/measurement (min) Total measurement time (min)

D-optimal
Repetition points

59
8

Startdesign
47
2nd measurement 47
7
Repetition points
iDoE
30
2nd measurement 30

4
1

4
1
1
4
1

236
8
244
188
47
7
120
30
392

Fig. 16.12 Model quality for BSFC using physical variation parameters and 30 iterative design
points

operating points (with 5 variation parameters) can be measured fully automatically
during one weekend.

288

N. Didcock et al.

Fig. 16.13 Model quality for NOx using physical variation parameters and 30 iterative design
points

At the same time also all other models get improved in the relevant area by adding
iterative variation points. The result for the fuel consumption and NOx emission is
shown in Figs. 16.12 and 16.13.

16.7 Conclusion

We presented a procedure that calculates the optimal design of an experiment online
during the workﬂow. It proved especially useful for the calibration of combustion
engines where legislative restrictions require certain output values to be bounded. The
training of online estimators of these outputs allows us to improve model quality in
areas that are relevant for further steps. Pre-knowledge of the calibration engineer can
be entered in the early stage of the test design for achieving an adequate measurement
point distribution in critical areas which is a prerequisite for gaining realistic models
reﬂecting the real engine behavior.

16 Online Design of Experiments in the Relevant Output Range

289

Another technique for improving the model quality is the usage of physical vari-
ation parameters which can be modeled with much higher accuracy. At the same
time all models like fuel consumption, emissions, pressures, temperatures, etc. are
improved and therefore very accurate estimations can be expected as result of the
optimisation. The original ECU variation parameters are treated as response channels
so that they are also outputs of the optimisation and can directly be used e.g. for the
calibration of ECU maps.
Abstract HCCI (Homogeneous Charge Compression Ignition) is a very control-
intensive combustion concept which has been studied for over a decade because
of its favorable combination of high efﬁciency and low emissions. Various optimal
control methods have been applied to HCCI and this chapter gives an overview of
them. Optimal control of HCCI can be divided into model based and non-model
based where MPC is an example of model based and extremum seeking control is
an example of non-model based control. The model-based methods can be divided
based on whether they use physics based or black box models. Finally a division
can be made based on whether the control aims for optimal set-point tracking of e.g.
combustion timing or whether it attempts to optimize an overall design criterion such
as fuel consumption. This chapter presents and characterizes a number of published
methods for optimal HCCI control and characterizes them according to the above
criteria.

17.1 Introduction

HCCI (Homogeneous Charge Compression Ignition) combustion has been studied
intensely for more than a decade because of its ability to combine high efﬁciency
with low emissions of particularly nitric oxides (NOx) and soot. One great difﬁculty
with HCCI is however, that it lacks direct control of ignition. Unlike spark ignition
combustion which is ignited by a spark and diesel combustion where ignition is
triggered by fuel injection, HCCI combustion has spontaneous ignition of a homo-
geneous charge which means that the charge conditions have to be very accurately
controlled in order to assure ignition at the right time.
The problem with controlling HCCI combustion timing has been recognized by
many researchers [1, 2] and many different control methods have been devised. A
majority of the published solutions have applied linear control e.g. PID [3] or linear
state feedback [4] with simple, low-level, control objectives such as tracking a desired
combustion timing trajectory. The main merits with these linear control methods are
low complexity, robustness and tunability.

Perfect tracking of combustion timing is however, not interesting in itself but rather
a tool to achieve other goals. Such goals could be low fuel consumption and/or low
emissions. This is recognized by some of the optimal control methods where the
optimality criterion is speciﬁed directly in terms of e.g. fuel consumption. Another
shortcoming of the linear control methods is constraint handling. Constraints are
nonlinear artifacts and as such can not be handled by truly linear controllers. For this
reason special constraint handling is added e.g. integrator windup protection, often
with less than satisfactory results.

Constraint handling is thus another reason to apply optimal control methods
such as MPC (model predictive control) which is essentially online constrained
optimization. With MPC the constraints can be explicitly taken into account in the
optimization and thus there is no need to add separate constraint handling. This
chapter presents examples of extremum seeking control as well as MPC control to
illuminate the issues mentioned above.

17.2 Optimal Control of HCCI

17.2.1 Multi-output MPC of HCCI

In [4], Bengtsson et al. show the ﬁrst example of MPC (Model Predictive Control)
applied to control of HCCI combustion. The modeling approach is system identiﬁca-
tion of cylinder individual MIMO models using the subspace identiﬁcation method.
Excitation was provided by individually designed PRBS (Pseudo-Random Binary
Sequence) signals on each input.

The test engine had a dual-fuel port injection system capable of injecting indi-
vidual quantities of ethanol and n-heptane to each cylinder. It also had a cylinder-
individual VVT (variable valve timing) system capable of changing the (IVC) intake
valve closing angle from cycle to cycle which was not used in this control imple-
mentation.

The input/output selections for the HCCI cylinder models are illustrated in
Fig. 17.1. The inputs selected for the cylinder models were fuel mass per cycle
(Wf ), fraction of ethanol (Rf ), inlet temperature (Ti) and engine speed (n). The out-
puts were combustion timing (α50), load (IMEPn) and maximum pressure derivative
(dp/dθ ). dp/dθ represents the combustion noise and a reasonable limit for the heavy
duty test engine in the study is 15 bar/CAD (crank angle degree).

17 Optimal Control of HCCI

Fig. 17.1 The
multi-input/multi-output
HCCI engine cylinder model
used for multi-output MPC
control design [4]

Rf
Win
Tin
n

HCCI engine

293

α

50
IMEPn
dp
dθ

The MPC design took a fairly simplistic approach where α50 was kept as close
to TDC (top dead center) as possible in order to minimize HC (hydrocarbon) and
CO (carbon monoxide) emissions. The tracking error of IMEPn was also included
in the cost function. Hard constraints were applied on inputs and soft constraints on
outputs, most importantly dp/dθ which was given a soft constraint of 15 bar/CAD.
Figure 17.2 shows an experiment where multiple stepwise load changes are
applied. It can be seen that α50 is delayed when necessary to satisfy the constraint.
When it is impossible to delay α50 further the IMEPn tracking is sacriﬁced by reduc-
ing the fuel mass.

17.2.1.1 Discussion

The strength of this approach is that it can minimize a cost function subject to
multiple constraints which can be both simple input saturation constraints and output
constraints. In this example the cost function was very simple. A more complicated
cost function would have made the optimization problem more complex and the
computation time would have increased substantially.

17.2.2 Physics-Based MPC of HCCI Combustion Timing

In [6] Widd et al. takes a physics based approach to MPC control of HCCI com-
bustion. A central part is a sub-model describing the heat transfer between cylinder
gas, cylinder walls and engine coolant. The continuous heat transfer is modeled as
taking place at three speciﬁc time instances in each cycle: after intake/mixing, after
combustion and after the exhaust stroke. The heat transfer model is illustrated in Fig.
17.3. The individual durations of the heat transfer events were tuning parameters.

Ignition was modeled using a simpliﬁed Arrhenius rate threshold model were the
temperature was approximated by the TDC temperature. Compression and expan-
sion were modeled as isentropic processes and IMEPn could be derived from cycle
temperatures using ideal cycle analysis.

The inputs to the model were the inlet valve closing angle (θIVC) and Ti and the
outputs were IMEPn and combustion timing (θ50). The resulting model is of second
order and a linearization was used for the MPC design. The control objective was θ50
tracking but a small weight was introduced on θ r
IVC is a reference

− θIVC, where θ r

IVC

294

P. Tunestål

2000

1500

1000

]
J
[

n
i

W

500

0

f

R

0.5

0

0

1

4

2

0

5

4

3

2

1

]

D
A
C

[

0
5

α

]
r
a
b
[

n
P
E
M

I

]

D
A
C

/
r
a
b
[

p
d

θ
d

20

15

10

5

100

200

300

400

500

600

700

Engine cycles

100

200

300

400

500

600

700

Engine cycles

0

100

200

500

600

700

400

300
Engine cycles

0

100

200

500

600

700

400

300
Engine cycles

0

100

200

500

600

700

300
400
Engine cycles

Fig. 17.2 Multiple load step changes illustrating the characteristics of the multi-output MPC con-
troller [5]

crank angle in the middle of the controllable range of the inlet valve closing angle,
in order to achieve a midranging [7] effect since Ti and θIVC are to some extent
redundant. Midranging is a heuristic control design method that can be used when
two control inputs affect the same output. If one of the control inputs has a high

17 Optimal Control of HCCI

295

Fig. 17.3 Illustration of the heat transfer model used for physics based MPC control of HCCI
combustion [6]

Fig. 17.4 Illustration of the disturbance rejecting characteristics of the physics-based MPC con-
troller with respect to disturbances in engine speed, fuel enginery and EGR level [6]

bandwidth and the other one has a wide range, the slow control input can be used
to push the fast one towards the middle of its range and thus make sure that high
bandwidth control is always possible.

Due to the low model order short prediction and control horizons could be used
which kept the computational load at a reasonable level. Figure 17.4 shows a distur-
bance rejection experiment with the physics based MPC controller which is able to
reject disturbances in engine speed, fuel mass and EGR level.

17.2.2.1 Discussion

The physics-based approach to MPC is attractive since it provides modularity and
a component-based structure. E.g. if material of the cylinder liner is changed in
the presented example, only the heat-transfer part of the entire model is affected

296

P. Tunestål

and everything else stays the same. For an identiﬁed black-box model, the entire
identiﬁcation would have to be repeated with the new hardware.

In this example the inlet valve closing timing and the inlet temperature are some-
what redundant in controlling the combustion phasing and then a midranging func-
tionality can be obtained by adding a weak penalty to deviations in the intake valve
closing timing from a reference value in the middle of its range, thus assuring maneu-
verability at all times.

17.2.3 Hybrid MPC of Exhaust Recompression HCCI

In [8] Widd et al. take a similar physics based modeling approach is in [6] but
without the heat transfer model. The reason for omitting the heat transfer is that the
engine used in this case operates with exhaust recompression with a considerable
amount of burned gas retained from one cycle to the next. The heat transfer then
has a minor inﬂuence on the charge temperature and instead focus is on the effect of
NVO (negative valve overlap). NVO is the crank angle interval when both exhaust
valves and inlet valves are closed around gas exchange TDC. By varying the NVO,
the amount of retained burned gas and thus the charge temperature can be controlled.
As in [6], the model is of second order. In [8] it is noted that the combustion timing
behavior is quite different for early and late combustion timings respectively (see
Fig. 17.5) with more cycle-cycle variation and less damping in the case of late
combustion. For this reason different linearizations are used for early, mid and late
combustion timings respectively in order to improve the control performance.

Tracking control of θ50 is implemented both using switching LQ design and using
hybrid MPC and a comparison for a large setpoint change is shown in Fig. 17.6. It
can be seen that the hybrid MPC controller handles the setpoint change signiﬁ-
cantly better and the reason is believed to be the fact that the hybrid MPC controller
can anticipate the system behavior by using the correct linearization when jumping
between early, mid and late combustion timing. The LQ controller can however, only
use one linearization at a time based on the present combustion timing.

17.2.3.1 Discussion

The hybrid MPC is suitable for cases when the operating range can be partitioned
into a small number of regions with similar system behavior within each region.
The MPC can then perform nearly optimally throughout the operating range and
even during transitions between regions. It can still be used for systems where the
necessary number of regions is larger but the memory requirement as well as the
identiﬁcation effort will scale with the number of regions.

17 Optimal Control of HCCI

297

Open Loop Early Phasing Operations

]

g
e
D
[
0 
5

θ

380

375

370

365

360

355

380

375

370

]
g
e
D

[

0
5

365

θ

360

355

0

0

50

100

150

200

Cycle Index [−]

Open Loop Late Phasing Operations

50

100

150

200

Cycle Index [−]

Fig. 17.5 Combustion timing behavior at early and late combustion timing respectively [8]

17.2.4 Optimizing Gains and Fuel Consumption of HCCI Using

Extremum Seeking

In [9] a completely non-model based approach is taken where extremum seeking
control is used for both tuning of controller gains for combustion timing control
and subsequently for fuel consumption minimization by optimizing the combustion
timing. The extremum seeking control is deﬁned in Fig. 17.7 and minimizes the cost
function J(θ ) with respect to the parameter θ .

Extremum seeking calibration of the control parameters is achieved by deﬁning
the cost function as the tracking error and performing repeated positive and negative
step changes of the combustion timing (CA50) setpoint. Figure 17.8 illustrates how
PI parameters and a feed forward gain are optimized in 1600 s using this approach.
Using the calibrated CA50 controller extremum seeking control of CA50 was
subsequently applied in order to minimize fuel consumption. Figure 17.9 shows how
the fuel-optimal CA50 is found in approximately 2,000 s.

17.2.4.1 Discussion

Extremum seeking is attractive since it does not require a system model. It can also
handle any type of cost function without local optima. The drawbacks with extremum
seeking is that it usually requires artiﬁcial excitation and the excitation normally
has to be of signiﬁcantly lower frequency than the bandwidth of the system. Each

298

P. Tunestål

Data
Set Point

Data
Set Point

(a)

]
g
e
D
[
0 
5

θ

380

375

370

365

360

355

(b)

380

]
g
e
D
[
0 
5

θ

375

370

365

360

0

5

10
Cycle Index [−]

15

20

0

5

10
Cycle Index [−]

15

20

Fig. 17.6 Comparison of large setpoint changes for MPC and LQ controllers [6]

Fig. 17.7 Discrete extremum seeking control with sinusoidal excitation and optimization of the
cost function J(θ) [9]

additional parameter to be optimized requires its own excitation frequency which
means slower convergence.

17.3 Conclusions

Four different optimal HCCI control methods have been presented of which three are
based on MPC. MPC is valuable for HCCI control mainly because of its ability to
explicitly handle constraints. MPC can be applied both to black-box models based on
system identiﬁcation and to linearized physics-based models. When using piece-wise
linear models MPC can anticipate model switching which can greatly improve the
dynamic behavior for e.g. large setpoint changes. Second order models and relatively
short prediction and control horizons have been sufﬁcient for the presented cases and
thus the resulting MPC designs have reasonable computational demands. Extremum

17 Optimal Control of HCCI

299

Fig. 17.8 Extremum seeking calibration of PI and feedforward gains [9]

Fig. 17.9 Fuel consumption minimization using extremum seeking control of combustion
timing [7]

seeking control provides a completely non-model based alternative. The advantage
compared to MPC is that there is no need to derive and calibrate models but extremum
seeking is essentially to be considered as a steady-state calibration method since the
closed-loop bandwidth is a few orders of magnitude lower than for the presented
MPC methods.
Abstract Time and fuel optimal control of an articulated wheel loader is studied
during the lift and transport sections of the short loading cycle. A wheel loader model
is developed including engine (with turbo dynamics), torque converter, transmission
and vehicle kinematics, lifting hydraulics and articulated steering. The modeling is
performed with the aim to use the models for formulating and solving optimal control
problems. The considered problem is the lift and transport section of the wheel loader
that operates in the short loading cycle, with several different load receiver positions,
while the considered criteria are minimum time and minimum fuel. The problem
is separated into four phases to avoid solving a mixed integer problem imposed by
the gearshifting discontinuities. Furthermore, two different load lifting patterns are
studied one with the lifting free and one with the lifting performed only in the last
30 % of the transport. The results show that the optimal paths to the load receiver are
identical for both minimum time and minimum fuel cycles and do not change when
the loading lifting pattern is altered. A power break-down during the wheel loader
operation is presented for the selected cycles of normal and delayed lifting where it
is shown that the cycle time remains almost unchanged when lifting is delayed while
the fuel consumption slightly decreases in minimum time transients.
cycle can signiﬁcantly reduce the total production cost. This is therefore an interest-
ing application where optimal control can guide engineers in the development of an
efﬁcient vehicle and users in how to utilize it efﬁciently.

A WL is a complex system, consisting of several subsystems with a power produc-
ing engine and several power consumers that compete about the power. Consumers
are for example lifting system, powertrain with torque converter and gearbox for
propulsion, as well as steering system which interacts with the powertrain in per-
forming an efﬁcient transport mission. Optimal control of such a system provides
valuable knowledge about the optimum usage of the system dynamics. For example
minimum fuel (Min M f ) and minimum time (Min T ) operation solutions provide
valuable information, and enables manufacturers to point out bottle necks as well as
potential for improvements in the system design. Furthermore control algorithms and
strategies of autonomous WL control systems can also be developed and improved
by the optimal control results, see e.g. [7, 8, 11].

In this chapter, a WL is modeled as a nonlinear dynamic system with 9 states and 4
control inputs. The insight of modeling is to develop a model suitable for calculating
the optimal controls of the WL in the short loading cycle. The short loading cycle,
depicted in Fig. 18.1 is a frequent application of WLs where the optimal control
analysis of the vehicle operation gives much insight into reducing fuel costs and cycle
operation times. Different studies have been carried out to calculate the optimal WL
working path proﬁle (trajectory) in a loading cycle [1, 6, 18, 19, 21]. Another path
is followed in [13] and [14] where optimal control is used for a ﬁxed length short
loading cycle where the major dynamics (engine, lifting, powertrain, and longitudinal
motion) of the WL operation in the short loading cycle is studied. The results here

18 Optimal Lifting and Path Proﬁles

303

extend the results in [13, 14] to also cover and solve the optimal WL path from
loading point to load receiver. The emphasis in the modeling section is to model
the components that have the largest power consumption during the WL operation,
while still using models that are compact enough for utilization in optimal control
problem formulation.

18.1.1 Outline

Section 18.2 describes the model of the wheel loader. The model is used, in Sect. 18.3,
to formulate two optimal control problems Min M f and Min T . These are formulated
so that they can be solved to obtain the trajectory and transients of the WL system. The
properties and requirements of the loading cycle and WL components are represented
as boundary conditions and path constraints in the problem. The change of gear ratio
during the WL operation introduces a discontinuity into the optimal control problem
which is remedied by dividing the cycle into multiple phases with constant gear ratio.
In Sect. 18.4 the solutions from the multi-phase optimal control problem, for sev-
eral different load receiver positions are presented. Optimal trajectories, with control
inputs and states are analyzed for the loading cycles. The power consumption by
different components during the WL operation is calculated and the power distri-
bution between various components is analyzed. The effect of changing the load
lifting strategy on the fuel consumption, cycle time and power distribution is also
studied. Finally the conclusions are given in Sect. 18.5. The symbols, parameters
and constants used in the following are summarized in the Tables 18.1, 18.2.

18.2 System Model

The WL model consists of three main sub systems namely powertrain, steering and
lifting, see Fig. 18.2. Vertical bucket acceleration Uab is selected as the control input to
the lifting system, and correlates to the hydraulic forces in the lifting cylinders which
are adjusted by the hydraulic valves. In the submodels for fuel injection, braking and
steering the control inputs are selected as fuel mass injected per combustion cycle
Um f , braking torque Ub, and the derivative of steering angle Ustr .

The state variables are selected to be engine speed ωice, intake manifold pressure
Pim, bucket height Hbuc, bucket lifting velocity Vbuc, steering angle δ, vehicle speed
V , heading angle θ and positions in X and Y directions determined by the differential
equations in (18.1)–(18.5).

Table 18.1 List of symbols

V. Nezhadali and L. Eriksson

304

Parameter
ωice
Tice
Um f
Uab
Ustr
Ub
Hbuc
Vbuc
θ
δ
V
X
Y
Pim
Pstr
Ptrac
Pli f t
Pm
Ftrac
Fr oll
˙ma
˙m f
Tig
T f ric
λ
φλ
φ
ωgb
Tpump
Ttur bine
Tgb
Tw
R
σ
Fload
L cyl
Acyl
Pcyl
Pcyl,max
Q pump
vcyl,max
Vli f t,max

Description

Engine speed
Engine torque
Injected fuel per combustion cycle
Vertical lifting acceleration
Derivative of steering angle
Torque from service brakes
Height of the bucket
Vertical speed of the bucket
Wheel loader heading angle
Steering angle
Wheel loader speed
Wheel loader position in X
Wheel loader position in Y
Intake manifold pressure
Power consumed for steering
Power consumed for traction
Power consumed for lifting
Intake manifold pressure model
Traction force
Rolling resistance force
Air mass ﬂow
Fuel mass ﬂow
Combustion generated torque
Engine friction torque
Air to fuel ratio indicator
Smoke limit
Speed ratio in torque converter
Gearbox rotational speed
Torque on pump side of torque converter
Torque on turbine side of torque converter
Torque at gearbox input
Torque at wheels
Turning radius
path curvature
Required force for load lifting
Length of lift cylinder
Cross section area of lift cylinder
Pressure in lift cylinders
Maximum pressure in lift cylinders
Hydraulic pump ﬂow
Maximum lift cylinder speed
Maximum lifting speed

Unit

rps
Nm
kg/cycle
m/s2
rad/s
Nm
m
m/s
rad
rad
m/s
m
m
Pa
W
W
W
Pa
N
N
kg/s
kg/s
Nm
Nm
-
-
-
rps
Nm
Nm
Nm
Nm
m
1/m
N
m
m2
Pa
Pa
m3/s
m2
m2
(continued)

18 Optimal Lifting and Path Proﬁles

Table 18.1 (continued)

Parameter

Description

Boom weight
Applied force on lift pistons
Angular acceleration of boom
Sum of torques applied on boom
Total mass of consumed fuel
Cycle duration
Phase duration (i ∈ {1, 2, 3})
State derivative
Load receiver position in X
Load receiver position in Y
Power losses in gearbox
Power losses in torque converter
Power required for engine acceleration

Table 18.2 Parameters and constants used in the model and optimal control problem formulation

Description

Mass of bucket
Efﬁciency of lift pump
Volumetric efﬁciency of the lift pump
Mechanical efﬁciency of the lift cylinder
Efﬁciency of gearbox
Rolling resistance
Minimum air to fuel ratio
Stoichiometric air to fuel ratio
Steering power parameter
Intake manifold pressure parameter
Intake manifold pressure parameter
Intake manifold pressure parameter
Intake manifold pressure parameter
Time constant parameter
Time constant parameter
Gas constant, air
Ambient temperature
Ambient pressure
Volumetric efﬁciency of diesel engine
Mass of wheel loader
Wheel inertia
Wheel radius
Mass of wheels

Value

10,000
0.9
0.98
0.95
0.9
0.03
1.2
14.57
3e4
−0.328
−121.519
0.057
97,179.699
38.5857
−0.6869
287
300
101.57
0.9
32,000
100
0.7
w)
4 ∗ Jw/(r 2

Fw
Fp
α
Mo
M f
T
ti
˙si
Xend
Yend
Ploss,G B
Ploss,T C
Peng,acc

Parameter

Mbuc
ηli f t
ηvolumetric
ηcycl,l
ηgb
cr
λmin
(A/F)s
c p
c p,1
c p,2
c p,3
c p,4
ct,1
ct,2
Ra
Tamb
Pamb
ηvol, eng
Mveh
Jw
rw
Mwheels

305

Unit

N
N
rad/s2
Nm
kg
s
s
-
m
m
W
W
W

Unit

kg
–
–
–
–
–
–
–
–
–
–
–
–
–
–
J/kg K
K
kPa
–
kg
kg m2
m
kg

(continued)

Table 18.2 (continued)

Parameter

Description

V. Nezhadali and L. Eriksson

306

Iice
ηgb
ncyl
Vd
γ
c f r1
c f r2
c f r3
qlhv
nr
ηig,ch
rc
γcyl
D pump
r
r1
xc
yc
G
r pist
rr od
Pcyl,max
Ustr,min
Ustr,max
Ub,max
Um f,max
Uab,min
Uab,max
ωice,min
ωice,max

Engine inertia
Gearbox efﬁciency
Number of cylinders
Engine displacement volume
Gearbox gear ratio
Engine friction coefﬁcient
Engine friction coefﬁcient
Engine friction coefﬁcient
Heating value, diesel
Engine rev. per power cycle
Combustion chamber efﬁciency
diesel engine compression ratio
Speciﬁc heat capacity ratio of cyl. gas
Hydraulic pump displacement
boom length
boom length
dimension
dimension
dimension
lift piston radius
lift rod radius
max lift cylinder pressure
lower limit on Ustr
higher limit on Ustr
higher limit on Ub
higher limit on Um f
lower limit on Uab
higher limit on Uab
lower limit on ωice
higher limit on ωice

Value

3
0.9
6
13e-3
[ −60, 0, 60]
0.7196
−0.1414
0.3590
42.9 e6
2
0.6877
17.3
1.35004
220/1,900
2.9
1.7
0.19
−0.3
2.3
0.19/2
0.09/2
34
−1
1
2e5
265
−5
5
57
230.38

(cid:2)

dωice
dt

= 1
Jice

Tice(Um f , ωice)

−

Pli f t (Uab, Vbuc) + Pstr (Ustr ) + Ptrans(ωice, V )
ωice

(cid:3)

d Pim
dt
d Hbuc
dt

d V
dt
dδ
dt

=

1
τm(ωice)

= Vbuc,

sign(V )

=

= Ustr ,

(Pm(ωice, Tice) − Pim)

= Uab

d Vbuc
dt
(cid:2)
Ftrac(Ub, ωice) − Fr oll

(cid:3)

Mtot

dθ
dt

= V
R(δ)

,

d X
dt

= V cos(θ),

= V sin(θ)

(18.5)

dY
dt

Unit
kg m2
–
–
m3
–
–
–
–
J/kg
–
–
–
–
L/round
m
m
m
m
m
m
m
MPa
rad/s
rad/s
Nm
–
m/s2
m/s2
rps
rps

(18.1)

(18.2)

(18.3)

(18.4)

18 Optimal Lifting and Path Proﬁles

307

Lifting System

Uab

Plift 

Ptrans 

Tgb 

gb 

Torque 
Converter 

Ub

Tw 

Gearbox

Wheels 

Ustr

Psteer 

Powertrain

Steering 
System

Umf

Tice 
ice 

ice 

Engine

Turbocharger 
Effect

Fig. 18.2 Building blocks of the WL system model and the interdependence between components.
States in red, control inputs in blue

In the following sections, the component models of the WL system are presented.
Using the sign function in (18.4), same differential equation can be used during the
reversing (sign(V ) = −1) and forwarding (sign(V ) = +1) phases of the cycle.

18.2.1 Powertrain and Longitudinal Dynamics

The powertrain delivers the torque for vehicle traction to the wheels of the WL. The
powertrain model consists of sub models for diesel engine, torque converter (TC),
gearbox and the wheel that connects the powertrain to the longitudinal dynamics, see
Fig. 18.2. The control inputs to the powertrain model are fuel injection per combustion
cycle Um f and braking torque Ub, the states of the components are engine speed ωice,
intake manifold pressure Pim and vehicle speed V.

18.2.1.1 Diesel Engine

The engine model is a simpliﬁed version of the model in [22] which represents a 12
Liter 6 cylinder turbocharged diesel engine. The power required for lifting, steering
and traction in the WL model is generated by the engine. The engine dynamics are
represented by ωice and Pim, while the control input to the engine model being Um f .
The mass ﬂows into the engine model stated in [kg/s] are air ˙ma and injected fuel
˙m f

˙ma =

ηvol, eng Vd ωice Pim
4π Ra Tamb

,

˙m f = 10−6
4 π

Um f ωice ncyl

(18.6)

Engine gross indicated torque Tig is calculated based on the fuel mass per combustion
cycle and engine friction torque is modeled as a polynomial of engine speed.

308

V. Nezhadali and L. Eriksson

ηig qhv ncyl Um f 10−6
4 π

Tig(Um f ) =
T f ric(ωice) = Vd 105
4π
Tice(Um f , ωice) = Tig(Um f ) − T f ric(ωice)

c f r 1 ωice

(cid:2)

2 + c f r 2 ωice + c f r 3

(cid:3)

(18.7)

(18.8)

(18.9)

The increase in the intake manifold pressure depends on the mass ﬂow over the
compressor which is strongly dependent on the turbocharger speed. When the driver
hits the accelerator pedal in a turbocharged diesel engine, the engine torque increases
transiently due to slower speed dynamics of the turbocharger [3]. The time that it
takes for the turbocharger speed build up is called turbo lag and it is accounted for
by modeling the intake manifold pressure as a function of engine speed and torque
including a variable time constant τm which depends on the engine speed.

Pm(ωice, Tice) = c p,1 ω2
ice
τm(ωice) = ct,1 ωct,2
ice

+ c p,2 Tice + c p,4 (Tice ωice)2 + c p,3

(18.10)

(18.11)

where the tuning parameters are c p,1,2,3,4, ct,1 and ct,2. The dynamics of the intake
manifold pressure is then described by the following differential equation

d Pim
dt

=

1
τm(ωice)

(Pm(ωice, Tice) − Pim)

(18.12)

The relative air to fuel ratio λ is deﬁned by

λ =

( ˙ma/ ˙m f )
(A/F)s

(18.13)

In order to avoid division by zero in (18.13) when fuel is cut off (Um f = 0), φλ is
deﬁned as

φλ = ˙ma − ˙m f (A/F)s λmin

(18.14)

where the λmin is set according to the smoke limits during the engine operation.

18.2.1.2 Torque Converter, Gearbox and Longitudinal Dynamics

TCs are used instead of using mechanical clutches to improve the drivability of
vehicles at the cost of adding an additional efﬁciency into the powertrain. A TC
transfers the engine torque to the wheels by means of a hydrodynamic coupling
between pump and turbine sides where the stator blades multiply the magnitude of
the transferred torque. When the TC transients are to be studied, differential equations
are used to describe the TC dynamics [10], however, for powertrain control study
only efﬁciency of the TCs is included in the models using efﬁciency look-up tables

18 Optimal Lifting and Path Proﬁles

309

ξ

κ

1000

500

0

−500

1000

500

0

−500
0

0

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

2

0.2

0.4

0.6

0.8

1.2

1.4

1.6

1.8

2

1
φ

Fig. 18.3 TC characteristic curves ξ and κ deﬁne the operation mode depending on the speed
ratio φ

which are simpler for controller design, [9] and [23]. TC characteristics depend on the
speed ratio φ over the component, and here, functions are ﬁtted to the experimental
data to model the TC. The transferred torque from the TC to the gearbox Ttur bine is
calculated as follows

φ =

ωgb
ωice
Tpump = ξ(φ) (

ωgb = V γ
rw
ωice
1,000

)2 Ttur bine = κ(φ) (

ωice
1,000

)2

(18.15)

(18.16)

where ξ(φ) and κ(φ) are the TC characteristics depicted in Fig. 18.3. The TC is
modeled to operate in two different modes depending on the φ value. Mode I during
traction where the engine torque is transfered to the wheels for vehicle acceleration
(0 ≤ φ ≤ 1), and mode II where the turbine side overruns the pump side (φ > 1).
A rapid drop in the engine speed while the vehicle is moving (ωgb (cid:5)= 0) results in
φ > 1 meaning that the kinetic energy is transferred from the gearbox side to the
engine side of the TC. A constant efﬁciency gearbox transfers the TC output torque
to the wheels.

Tgb = Ttur bine Tw = Tgb ηgb γ

(18.17)

where γ is the gearbox gear ratio. Vehicle longitudinal acceleration is calculated
by neglecting the aerodynamic resistive forces, due to low vehicle velocities, and
considering only the rolling resistance forces while including the wheel inertia as an
equivalent mass in the total mass of the vehicle.

310

V. Nezhadali and L. Eriksson

Fr oll = sign(V ) cr (Mveh + Mbuc) g, Ftrac = Tw − sign(V ) Tb

, Tb = Ub

rw

Mtot = Mveh + Mbuc + 4 Jw
r 2
w

,

d V
dt

= sign(V ) (Ftrac − Fr oll )
Mtot

(18.18)

(18.19)

The sign operator deﬁnes the direction of WL travel in the reversing and forwarding
sections of the short loading cycle. The power required at the input to the TC, Ptrans,
in order to generate the tractive force at wheels is calculated according to

Ptrans = Tpump ωice

(18.20)

18.2.2 Steering and Ground Position

Articulated steering is used in WLs where the two main bodies of the vehicle are
connected by a revolute joint such that the front and rear axles are equidistant to
the articulation point. This type of steering is favorable in WLs as the front and rear
wheels move over the same trajectory easing the movement of vehicle on muddy
surfaces [18]. Figure 18.4 shows the geometry of the WL while turning. From the
system and control points of view, several studies have been performed on path
planning and trajectory optimization, e.g. [2, 12, 17], while many are speciﬁcally
dedicated to WLs path planning and optimization [1, 18, 19, 21]. Here, in the steering
system, WL position and heading angle are modeled using simple vehicle kinematics.
(X , Y ) and heading angle θ during load carrying from the loading point to the load
receiver are determined based on the vehicle speed V and steering angle δ while
the derivative of steering angle Ustr is the control input to the model. The steering
dynamics are then determined by

dθ
dt

= V
R

,

d X
dt

dY
dt

= V cos θ,

= V sin θ

(18.21)

where R is the turning radius and (X, Y, θ) are calculated at point C, see Fig. 18.4,
which remains equidistant from the front and rear axles during the loading cycle. For
control purposes, the steering angle must remain continuous during the operation
which is ensured by selecting the steering angular velocity Ustr as the control input
to the steering system and bounding it within limits.

dδ
dt

= Ustr , Ustr,min < Ustr < Ustr,max

(18.22)

Vehicle turning performance is speciﬁed as a minimum turning radius, Rmin. To
ensure that the model fulﬁlls this, the following connection between R and δ is used

18 Optimal Lifting and Path Proﬁles

Fig. 18.4 The position of WL
during the loading cycle is
determined for point C

311

L/2

V

L/2

C(x,y, )

R

/2

R =

L
2 tan( δ
2

, σ = 1
R

)

(18.23)

where σ is the path curvature.

The hydraulic power required for steering Pstr is modeled as a quadratic function
of steering angular velocity meaning that there is no power demand for steering when
steering angle is unchanged.

Pstr = c pU 2
str

(18.24)

where c p is the tuning parameter.

18.2.3 Lifting System

The lifting speed Vbuc and bucket position Hbuc, both in vertical direction, are de-
termined in the lifting system model. The control input to the model is the vertical
acceleration of the bucket Uab and the required power for lifting Pli f t is calculated
as follows

Fload = Mload (g + Uab), Pli f t = Fload Vbuc

(18.25)

ηli f t

where the load mass Mload is assumed to remain constant.

Lifting speed Vbuc is dependent upon engine speed, as the hydraulic pumps in
the lifting system rotate at the same speed as the engine until the ﬂow in the pumps
becomes saturated at 1,500 rpm. Also, the maximum lifting acceleration is limited
by the maximum allowed pressure in the hydraulic system. In order to derive the
constraints on the lifting speed and acceleration, the boom geometry is analyzed.
While the boom is lifted, the displacement along the lift cylinders (cid:2)L cyl is multiplied

312

V. Nezhadali and L. Eriksson

Lcyl 

Hbuc 

Fig. 18.5 The boom geometry and acting forces during lifting (left), and the multiplication factor
between the lift cylinder and boom end displacement (right)

with a factor k resulting in vertical displacement (cid:2)Hbuc at the end of the boom, see
Fig. 18.5-right. k is calculated as a function of the boom angle θ2 as follows

),

−1( Hbuc − G
r

θ2 = sin
(cid:2)
(cid:4)
r1 cos(θ2) − xc
(cid:2)(r sin(θ2))/(cid:2)θ2
(cid:2)L cyl /(cid:2)θ2

L cyl =

k(θ2) =

−1(r1 cos(θ2) − xc
r1 sin(θ2) − yc
(cid:5)
2

θ1 = tan
(cid:4)
r1 sin(θ2) − yc

(cid:5)

2 +

)

,

r = r1 + r2

(18.26)

(18.27)

(18.28)

where G is the distance between the boom and body joint, point O, from the ground
level and r1, r2, θ1,2, xc and yc are illustrated in Fig. 18.5-left. Lifting is carried out by
means of lift cylinders where two identical hydraulic pumps deliver the ﬂuid to the
system. The maximum displacement speed of the lift cylinders vcyl,max is determined
by the maximum amount of ﬂuid Q pump pumped into them which is calculated as

Acyl = π (r 2

piston

− r 2

r od

), Q pump = min(ωice, 157) × D pump,max ηvolumetric

vcyl,max (ωice) =

Q pump ηcyl,l
Acyl

(18.29)

(18.30)

using the k factor calculated in (18.28) the maximum possible bucket lifting speed
at the end of the boom is determined as a function of the engine speed.

Vli f t,max (ωice) = k(θ2) vcyl,max (ωice)

(18.31)

Forces acting on the boom, during lifting are depicted in Fig. 18.5. In order to calculate
the magnitude of the force exerted on the lifting cylinders, the torque equilibrium
equation is solved around joint O.

18 Optimal Lifting and Path Proﬁles

(cid:3)

Mo = Iboom α ⇒ Fp =

Fw = Mboom (g + Uab)
Iboom Uab
r

+ Fload r cos(θ2) + Fw
r1 sin(θ1 − θ2)

r
2 cos(θ2)

accordingly, the exerted pressure in the lifting system at any boom position and
bucket acceleration is calculated as

Pcyl (Uab, Hbuc) =

Fp(Uab, Hbuc)
A piston

It is noted that the bucket height Hbuc is selected as a system state since it is required in
(18.26), to determine the geometry of the boom θ2, which is needed when calculating
the maximum lifting speed and lift cylinder pressure.

313

(18.32)

(18.33)

(18.34)

18.3 Optimal Control Problem Formulation

The WL model developed in the previous section is utilized to formulate an optimal
control problem which is solved in order to obtain the Min T and Min M f transients
of the WL system. In this section, ﬁrst the loading cycle requirements are described in
terms of boundary conditions of the optimization problem, then the path constraints
are deﬁned and ﬁnally the formulated optimal control problems is presented.

Gear shifts during the loading cycle introduce a discontinuous variable, gear ratio,
into the problem. To avoid discontinuities in the problem and thus avoiding the need
to solve a mixed integer problem, the loading cycle is divided into four separate
phases where the gear ratio of the gearbox remains constant during each phase. The
ﬁrst phase starts when the WL leaves the loading point and reverse gear is selected
to accelerate towards the reversing point, then in the second phase, the gearbox goes
into neutral and service brakes are used to stop the vehicle. This process is repeated
in the third and fourth phases with the difference that the WL moves in forward
direction. The short loading cycle requirements are described in terms of boundary
conditions in Table 18.3 where ˙si are the system states determined by the differential
equations (18.1)–(18.5) and ˙s = 0 at the end of the cycle ensures that the vehicle
reaches the load receiver at stationary condition.

The ﬁnal position of the WL (Xend , Yend ) depends on the conﬁguration of the
construction site. It is assumed that the WL starts reversing from the origin at the
loading point and the load receiver is located down to the left of the origin. The
working range of WL is constrained using the coordinates of the loading point and
load receiver as follows

X ≥ Xend , Y ≤ 0, 0 ≤ θ ≤ 2π

(18.35)

314

V. Nezhadali and L. Eriksson

Table 18.3 The load carrying section of the short loading cycle is deﬁned in terms of boundary
conditions in the optimal control problem

Time 0

γ = 0
Ub (cid:5)= 0
T

Phase 1 reversing Phase 2 reversing Phase 3 forwarding Phase 4 forwarding
γ = 0
γ = −60
Ub (cid:5)= 0
Ub = 0
+
−
+
−
t
t
t
t
2
2
1
1
ωice 1, 500 [rpm] – –
– –
Pim 1.1 Pamb
– –
– –
Hbuc 0.7 [m]
– –
– –
Vbuc 0
– –
– –
V
0 0
– –
0
Ustr 0
– –
– –
δ
– –
– –
0
90◦
θ
– –
– –
X
– –
– –
0
Y
– –
– –
0
˙si
– –
– –
–
The free variables t1, t2 and t3 are the gear shifting times which will be optimized

γ = 60
Ub = 0
+
−
t
t
3
3
– –
– –
– –
– –
– –
– –
– –
– –
– –
– –
– –

–
–
5 [m]
0
0
0
0
–
Xend
Yend
0

In order to avoid exerting uneven forces on the boom structure, the WL must be
perpendicular to the load pile (at t = 0, θ = 90◦) and load receiver at the beginning
and end of the cycle, [18]. At the beginning of the ﬁrst phase, it is assumed that
the bucket is lifted as high as the wheel radius and since the engine has already
been producing power for bucket ﬁlling, the initial engine speed and intake manifold
pressure are set higher than the idling engine speed and ambient pressure respectively.
When the bucket is loaded and raised, the vehicle should not brake harshly in order to
avoid structural damages and this is ensured by adding the constraint on the vehicle
speed derivative. The smoke limiter constraint on φλ and other component limitations
according to the properties stated in [16] are deﬁned as the following path constraints

Pcyl (Uab, Hbuc) ≤ Pcyl,max

(18.36)

0 ≤ φλ
Rmin ≤ R(δ)

ωice,min ≤ ωice ≤ ωice,max

δmin ≤ δ ≤ δmax
Uab,min ≤ Uab ≤ Uab,max
Ustr,min ≤ Ustr ≤ Ustr,max

Vbuc ≤ Vli f t,max (ωice)
Tice ≤ Tice,max (ωice)
|V | ≤ Vmax
−0.18 g ≤ d V
dt
Pamb ≤ Pim

0 ≤ Um f ≤ Um f,max
0 ≤ Ub ≤ Ub,max

In order to ensure the continuity of the states between the successive phases, phase
connectivity constraints are applied to the problem. The bucket acceleration Uab and
steering angular velocity Ustr are kinematic properties which cannot be discontinuous
for the sake of mechanical stability, therefore, the connectivity constraints are applied
on these control inputs as well.

18 Optimal Lifting and Path Proﬁles

315

Uab, Ustr and si at start of phase j + 1 = Uab, Ustr and si at end of phase j(18.37)

i ∈ {1, 2, 3, 4, 5, 6, 7, 8, 9}, j ∈ {1, 2, 3}

The fuel consumption during the WL operation is calculated as

M f =

˙m f dt +

˙m f dt +

˙m f dt +

˙m f dt

(18.38)

(cid:4)

t1

0

(cid:4)

t2

t1

(cid:4)

t3

t2

(cid:4)

T

t3

where ˙m f is obtained by (18.6). The optimal control problems formulated to calculate
the Min T and Min M f system transients and the phase shifting times t1, t2, t3 are

M f or min
u(·)
s.t: ˙s = f (s, u) and constraints in (18.36), (18.37) and Table 18.1

min
u(·)

T

(18.39)

Due to the complexity of the problem and number of states and control inputs,
solving the OCPs with methods such as Dynamic Programming or Pontryagin’s
Maximum Principle would require very large computational effort. Therefore, an
optimal control solver PROPT [20] is used to solve the problem in (18.39). The
solver employs pseudospectral collocation method [4] to solve the OCP where states,
controls and cost function are described in terms of high order polynomials satisfying
the constraints.

18.4 Results

The multi-phase optimal control problem in (18.39) subjected to the path constraints
and boundary conditions in (18.35)–(18.37) and Table 18.3 is solved for thirty differ-
ent load receiver positions (Xend , Yend ) which are evenly spread over a 20 × 20 m2
working area, and the Min M f and Min T transients and optimal trajectory of the
WL are calculated. The effects of imposing an alternative lifting pattern on the tran-
sients is analyzed and power distribution between the different components during
the operation is presented.

18.4.1 Optimal WL Trajectory from Loading Point to the Load

Receiver

The optimal WL trajectory from the loading point to the load receiver is found to
be nearly identical at different points of the working area for Min M f and Min T
transients. The results show that the minimum traveling distance between the loading

316

]

m

[
 

Y

0

−4

−8

−12

−16

−20

V. Nezhadali and L. Eriksson

5

10
Time [s]

15

]

m
/
1
[
 
σ

0.2

0.1

0

−0.1

−0.2

0

0.2

0.1

0

−0.1

−0.2

0

Longest
Shortest

]

m
/
1
[
 

σ

−20

−16

−12

−4

0

4

−8
X [m]

5

10
Time [s]

15

Fig. 18.6 The optimal WL trajectory in the short loading cycle from the loading point to the load
receiver for Min M f and Min T transients are identical and depend only on the load receiver position
(left). The trajectory curvature remains continuous during the operation which is a necessity for
trajectory controller design (right)

point and the load receiver is selected in both Min M f and Min T solutions, although
the Min M f transients are almost twice as long as the Min T transients. Figure 18.6-
left, shows the optimal trajectories of the WL, and ﬁnal heading angles corresponding
to the optimal orientation of the load receiver, at various load receiver positions. The
shortest and the longest trajectories are highlighted and the system transients will
be presented for them in the sequel. In the same ﬁgure, to the right, the trajectory
curvature (σ) is presented for the highlighted cycles where it is seen that it remains
continuous during the cycle. This is a necessity for trajectory controller design, [18,
19, 21], and is the result of using the constrained derivative of the steering angle Ustr
as the control input to the steering system. The curvature is zero at the beginning
where the WL leaves the loading point and also at the end of the cycle when the
vehicle reaches the load receiver.

18.4.2 Min M f and Min T System Transients

Figures 18.7 and 18.8 show the Min T and Min M f transients and the engine op-
erating points for the short and long cycles, highlighted in Fig. 18.6. According to
[15], a typical lift and transport operation consists of around 5 s reversing and 5 s
forwarding (for the same range of distance as in the shorter cycle here), while the
Min T transients are calculated to be only 8 s. The duration of Min M f transients
for the same cycle are nearly two times longer with 36 % lower fuel consumption.
In the Min T case, at the beginning of the ﬁrst phase when the WL starts to move,
the increase in engine output torque is limited by the smoke limiter constraint which
is caused by the turbocharger speed build up effect with insufﬁcient Pim resulting in

18 Optimal Lifting and Path Proﬁles

317

Min T , Short

2

6

5

2

2

5

0 . 4

1

8

5

1

4

5

0

5

6

5 1

Min T , Long

2

6

5

2

2

5

0 . 4

1

8

5

1

4

5

0

5

6

5 1

65

25

500

1000

1500

2000

500

1000

1500

2000

Min M

 , Short
f

2

6

5

2

2

5

0 . 4

1

8

5

1

4

5

0

5

6

5 1

 , Long
Min M
f

2

6

5

2

2

5

0 . 4

1

8

5

1

4

5

0

5

6

5 1

2000

1500

1000

500

0

2000

1500

1000

500

0 . 3 7

0.3

0

0 . 3 7

0.3

0

65

25

 

Ph
1
Ph
2
Ph
3
Ph
4

65

25

0 . 3 7

0.3

0

0 . 3 7

0.3

0

]

m
N

[
 
e
u
q
r
o
T
 
e
n
i
g
n
E

]

m
N

[
 
e
u
q
r
o
T
 
e
n
i
g
n
E

2000

1500

1000

500

0

2000

1500

1000

500

0

65

25

0

 
500

500

1000

1500

2000

Engine speed [rpm]

1000

1500

2000

Engine speed [rpm]

Fig. 18.7 Engine operating points in time and fuel optimal transients with respect to the engine
torque limits for the short and long cycles (constant efﬁciency curves in blue and constant power
[kW] curves in gray)

low ˙ma. The bucket lifting starts a bit later in order to leave all of the engine power for
faster vehicle acceleration and steering at the beginning. The steering angle rapidly
decreases to the lowest allowed value by the minimum curvature radius constraint
and remains unchanged until moments before reversing point where it goes towards
zero.

In the second phase, the engine is decoupled from the wheels when the gear is
shifted into neutral. All the engine power is used for lifting while higher engine speed
at the end of this phase is desirable, since the kinetic energy of the engine is going to
be used for faster vehicle acceleration at the beginning of the next phase via a rapid
drop in the engine speed.

In the Min T transients of the short cycle, half of the ﬁnal bucket height is reached
during reversing and the rest in the forwarding section. In case of the long cy-
cle, the length of the reversing and forwarding sections of the cycle are unequal.
In the reversing section, faster dynamics of the steering angle occur in order to
position the vehicle quickly in the trajectory where less steering power would be
required during forwarding. Most of the engine power is allocated to vehicle ac-
celeration and steering without major load lifting during reversing. In the section
with forward movement, except short intervals at the beginning where vehicle is

Short Distance

Long Distance

V. Nezhadali and L. Eriksson

Min T
Min M
f

318

200

100

f

m

U

0
2

0

−2

40

20

0
1

0

b
a

U

]
3
−
e
1
 
×
[
 

b

U

r
t
s

U

−1

200

100

]
s
p
r
[
 

e
c
i

ω

]
s
/
m

[
 

V

2
0
−2

]

m

[
 

H

]
s
/
m

[
 

V

c
u
b

c
u
b

4

2

1

0

]
a
P
K

[
 

P

m

i

]
g
e
d
[
 
δ

300

200

100

20

0

−20

200

100

0

0.2
0
−0.2

40

20

0
1

0

−1

200

100

2
0
−2

4

2

0.5

0

300

200

100

20

0

−20

0

5

10

15

0

5

10

25

30

35

Time [s]

15
20
Time [s]

Fig. 18.8 The Min T and Min M f transients of the short (left) and long (right) cycle.Vertical lines
are the phase boundaries

accelerated, the WL travels mostly on a straight line (no steering power required)
with a constant speed (small traction power required) where most of the engine power
remains untouched and available for fast load lifting.

In case of the short cycle and for both Min M f and Min T transients, the third phase
has similar dynamics as the ﬁrst one in the sense that ﬁrst the vehicle is accelerated
to high speeds and then the lifting starts.

The Min M f transients are similar for both short and long cycles in the sense that
high engine speeds are avoided and less rapid changes occur in Um f . But still Ustr

18 Optimal Lifting and Path Proﬁles

319

has fast dynamics in order to ensure that the shortest trajectory to the load receiver
is traveled.

18.4.3 Delayed Lifting

Considering the uneven surfaces where WLs operate on, the risk of losing vehicle
stability increases when the loaded bucket is raised during the period that the vehicle
is moving. The results in Fig. 18.8 show that the load lifting begins early in the
reversing phase and the bucket is raised from its initial position during a long period
of the cycle. In this section, the problem formulated in (18.39) is solved with an
additional constraint limiting the bucket lifting to only the last 30 % of the cycle
duration ensuring that the bucket remains mostly on lower height levels. To study the
effects of the lifting pattern on the system transients and power distribution among
different components, the Min T and Min M f
transients and power break down
between various components are analyzed.

18.4.3.1 Effects of Delayed Lifting on Min T and Min M f Transients

The optimal trajectory from the loading point to the load receiver in different po-
sitions remains the same as that of the normal lifting pattern and looks as depicted
in Fig. 18.6. The Min T and Min M f transients of the WL for the short and long
cycles are illustrated in Fig. 18.9 where lifting is delayed. The reversing section re-
mains similar to the previous case with the difference that after accelerating to high
speeds, no power is required for lifting and less engine torque is generated late in the
reversing section. The major difference happens, as expected, late in the forwarding
section where the vehicle is controlled to reach high speed before start of lifting in
order to leave most of the engine power for lifting in the rest of the cycle duration.
The fuel injection level increases to produce larger torque as the lifting starts and the
intake manifold pressure rises to deliver more air to the combustion chamber so that
more fuel can be injected without reaching the smoke limit.

18.4.4 Power Break Down

The power generated by the diesel is consumed for vehicle traction Ptrac, load lifting
Pli f t and vehicle steering Pstr . TC losses Ploss,T C also constitute a major portion
of power consumption and are calculated separately while the power loss due to
the efﬁciency of the lifting system is included in Pli f t . The diesel engine power is
required for traction when the traction force Ftrac is positive.

V. Nezhadali and L. Eriksson

Short Distance

Long Distance

Min T
Min M
f

320

200

f

m

U

100

0

2
0
−2
−4

40

20

b
a

U

]
3
−
e
1
 
×
[
 

b

U

r
t
s

U

0
1

0

−1

200

100

e
c
i

]

m
p
r
[
 

ω

]
s
/

m

[
 

V

c
u
b

]

m

[
 

H

]
s
/

m

[
 

c
u
b

V

−2

2

0

4

2

2

1

0

]
a
P
K

[
 

P

m

i

]
g
e
d
[
 
δ

300

200

100

20

0

−20

200

100

−1

40

20

0
1

0

0
1

0

−1

200

100

−2

2

0

4

2

1

0

0.5

300

200

100

20

0

−20

0

2

4

6

8

10

12

14

16

0

5

10

15

20

25

30

35

Time [s]

Time [s]

Fig. 18.9 The Min T and Min M f transients of the short (left) and long (right) cycle when the
lifting is delayed to the last 30 % of the cycle duration. Vertical lines are the phase boundaries

Ftrac = Mtot

+ Fr oll , Ptrac = Ftrac V when Ftrac > 0

(18.40)

d V
dt

The power loss in the gearbox is calculated as follows

Ploss,G B = 1 − ηgb
ηgb

Ptrac

(18.41)

The loss of power in the TC is calculated as the difference between the input and
output powers of the TC as

18 Optimal Lifting and Path Proﬁles

321

 = 98.7 [gr], T = 8.0 [sec]
Min T , short cycle, M
f

 = 96.8 [gr], T = 8.1 [sec]
Min T , short cycle, delayed lifting, M
f

Lifting    = % 35.9
Traction = % 33.3
Steering  = % 3.7
Eng Acc  = % 6.6
TC loss   = % 20.5

Lifting    = % 48.0
Traction = % 28.2
Steering  = % 2.4
Eng Acc  = % 2.5
TC loss   = % 18.8

Lifting    = % 34.4
Traction = % 34.5
Steering  = % 3.6
Eng Acc  = % 7.3
TC loss   = % 20.1

Lifting    = % 48.0
Traction = % 28.2
Steering  = % 2.4
Eng Acc  = % 2.5
TC loss   = % 18.8

]

W
k
[
 
r
e
w
o
P

500

400

300

200

100

0

0

]

W
k
[
 
r
e
w
o
P

150

100

50

0

0

]

W
k
[
 
r
e
w
o
P

]

W
k
[
 
r
e
w
o
P

500

400

300

200

100

100

80

60

40

20

0

0

1

2

3

4

5

6

7

8

0

1

2

3

4

5

6

7

8

 = 62.4 [gr], T = 16.8 [sec]
 , short cycle, M
Min M
f
f

 = 62.4 [gr], T = 16.9 [sec]
 , short cycle, delayed lifting, M
Min M
f
f

2

4

6

8

10

12

14

16

0

2

4

6

8

10

12

14

16

 = 172.3 [gr], T = 17.2 [sec]
Min T , long cycle, M
f

Lifting    = % 24.5
Traction = % 50.6
Steering  = % 2.3
Eng Acc  = % 3.9
TC loss   = % 18.8

 = 170.1 [gr], T = 17.3 [sec]
Min T , long cycle, delayed lifting, M
f
Lifting    = % 24.5
Traction = % 50.8
Steering  = % 2.0
Eng Acc  = % 3.8
TC loss   = % 18.9

2

10

14

4
8
6
12
 = 118.8 [gr], T = 36.7 [sec]
 , long cycle, M
Min M
f
f
Lifting    = % 28.3
Traction = % 46.6
Steering  = % 1.4
Eng Acc  = % 1.6
TC loss   = % 22.1

16

2
0
6
14
 = 119.2 [gr], T = 37.6 [sec]
 , long cycle, delayed lifting, M
Min M
f
f

16

10

12

8

4

Lifting    = % 28.3
Traction = % 46.7
Steering  = % 1.0
Eng Acc  = % 1.7
TC loss   = % 22.4

15
20
Time [s]

0

0

5

10

15
20
Time [s]

25

30

35

0

5

10

25

30

35

Fig. 18.10 The power brake down for the short and long cycles during the Min M f and Min T
transients for normal operation (left column), and delayed lifting operation (right column). The
vertical lines are the phase boundaries

A part of the engine power is consumed to overcome the engine inertia Peng,acc
during engine acceleration. When the engine decelerates, Peng,acc becomes negative
meaning that the kinetic energy of the engine is delivered back to the system.

Ploss,T C = Tpump ωice − Tgb γ V
rw

Peng,acc = Jice ωice

dωice
dt

(18.42)

(18.43)

Finally, the power balance in the system is described by the following equation

Tice ωice = Pli f t + Ptrac + Pstr + Peng,acc + Ploss,T C + Ploss,G B

(18.44)

322

V. Nezhadali and L. Eriksson

The power distribution in the WL system during the Min T and Min M f transients
of the short and long cycles is illustrated on the left column of Fig. 18.10 where
Ploss,G B is lumped into Ptrac. The right column in the same ﬁgure shows the power
distribution for the case where lifting is delayed. It is interesting to note that by
changing the lifting pattern, the proportion of energy consumption remains almost
unchanged among different consumers and only the course of events gets shifted.
The increase in the cycle duration in case of delayed lifting is negligible, and the fuel
consumption remains nearly unchanged in the Min M f transients while it decreases
by 1.2 and 1.9 % in case of Min T transients of the short and long cycles respectively.
This implies that lifting can be performed closer to the load receiver in the loading
cycle without causing major losses in cycle duration or increase of fuel consumption
while better stability of the vehicle is achieved during the load carrying operation.

18.5 Conclusion

A wheel loader (WL) is modeled as an integration of three sub systems namely
powertrain, lifting and steering where the aim is to describe the main dynamics of the
subsystems with highest power consumption during the WL operation. The trajectory
generation for the WL from loading point to the load receiver is also included in the
model. The diesel engine is modeled including turbocharger limitations while the
number of state variables and control inputs are reduced by modeling the intake
manifold pressure as a function of engine speed and torque. The torque converter
is modeled by static characteristic curves and a constant efﬁciency gearbox is used.
The geometry of the boom is analyzed and the structural constraints during lifting
are modeled in the lifting system.

The loading cycle is divided into four phases with constant gearbox gear ratio
during each phase in order to avoid facing a mixed integer optimal control problem.
The minimum fuel (Min M f ) and minimum time (Min T ) dynamics of the system are
calculated by solving a multi-phase optimal control problem. The optimal trajectory
in the short loading cycle from loading point to the load receiver and the system
dynamics are calculated for several load receiver positions. An alternative load lifting
pattern where the lifting is delayed until the last 30 % of the cycle duration is studied.
The suggested lifting pattern ensures that the WL remains stable during load carrying
as the bucket remains on low height during most of the cycle time.

The optimal trajectory to the load receiver is found to be identical for the Min T
and Min M f transients and remains unchanged in case of the new lifting pattern
implying that the transport path and longitudinal motion can be solved separately.
However there is a coupling between them, as the steering consumes power during
the maneuver. The results of the power break down for the system components show
that when the vehicle starts from stand still in the minimum time transients, most
of the engine power is allocated to vehicle traction in order to enable fast vehicle
acceleration whereas lifting starts later when vehicle has reached high speed and
less power is required for traction. By delaying the lifting operation, the amount of

18 Optimal Lifting and Path Proﬁles

323

distributed engine power among various components remains unchanged while the
course of events gets shifted. Finally, it is shown that when the load lifting is delayed,
the cycle time slightly increases in both Min T and Min M f solutions, however, the
positive side effect is that the fuel consumption decreases in the Min T case.