{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitvenveaefb649f0a843798b4e750392f4e826",
   "display_name": "Python 3.8.5 64-bit ('venv')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "source": [
    "### Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalList(dictionary):\n",
    "    terms = []\n",
    "\n",
    "    focus_term = list(dictionary.keys())[0]\n",
    "    dictionary = dictionary[focus_term]\n",
    "\n",
    "    for term in dictionary.keys():\n",
    "        terms.append(term)\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "source": [
    "### List"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_evalIntrinsic = '/home/hiwi/Dokumente/masterthesis/data/terminology/eval_intrinsic_key.json'\n",
    "path_expert = '/home/hiwi/Dokumente/masterthesis/data/expert/'\n",
    "\n",
    "# Load vocabulary list\n",
    "intrinsic_eval = json.loads(open(path_evalIntrinsic).read())\n",
    "intrinsic_eval = intrinsic_eval[\"eval_list\"]\n",
    "\n",
    "# Expert voting\n",
    "expert = {}\n",
    "\n",
    "for key in intrinsic_eval.keys():\n",
    "    filename = intrinsic_eval[key]\n",
    "    terms = json.loads(open(path_expert+filename).read())\n",
    "    expert[key] = evalList(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_trained = '/home/hiwi/Dokumente/masterthesis/data/trained/'\n",
    "modelName1 = path_trained + '01size0.2_w2v_ngramsTraining_vs500_win10_mc5_sg1_hs1.bin'\n",
    "modelName2 = path_trained + '01size0.3_w2v_ngramsTraining_vs500_win10_mc5_sg1_hs1.bin'\n",
    "modelName3 = path_trained + '01size0.4_w2v_ngramsTraining_vs500_win10_mc5_sg1_hs1.bin'\n",
    "modelName4 = path_trained + '01size0.5_w2v_ngramsTraining_vs500_win10_mc5_sg1_hs1.bin'\n",
    "modelName5 = path_trained + '01size0.6_w2v_ngramsTraining_vs500_win10_mc5_sg1_hs1.bin'\n",
    "modelName6 = path_trained + '01size0.7_w2v_ngramsTraining_vs500_win10_mc5_sg1_hs1.bin'\n",
    "modelName7 = path_trained + '01size0.8_w2v_ngramsTraining_vs500_win10_mc5_sg1_hs1.bin'\n",
    "modelName8 = path_trained + '01size0.9_w2v_ngramsTraining_vs500_win10_mc5_sg1_hs1.bin'\n",
    "modelName9 = path_trained + '01size1.0_w2v_ngramsTraining_vs500_win10_mc5_sg1_hs1.bin'\n",
    "\n",
    "# Load model\n",
    "model1 = Word2Vec.load(modelName1)\n",
    "model2 = Word2Vec.load(modelName2)\n",
    "model3 = Word2Vec.load(modelName3)\n",
    "model4 = Word2Vec.load(modelName4)\n",
    "model5 = Word2Vec.load(modelName5)\n",
    "model6 = Word2Vec.load(modelName6)\n",
    "model7 = Word2Vec.load(modelName7)\n",
    "model8 = Word2Vec.load(modelName8)\n",
    "model9 = Word2Vec.load(modelName9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalPairs = []\n",
    "\n",
    "for key in expert.keys():\n",
    "    for term in expert[key]:\n",
    "        try:\n",
    "            score = model1.wv.similarity(key, term)\n",
    "            score = model2.wv.similarity(key, term)\n",
    "            score = model3.wv.similarity(key, term)\n",
    "            score = model4.wv.similarity(key, term)\n",
    "            score = model5.wv.similarity(key, term)\n",
    "            score = model6.wv.similarity(key, term)\n",
    "            score = model7.wv.similarity(key, term)\n",
    "            score = model8.wv.similarity(key, term)\n",
    "            score = model9.wv.similarity(key, term)\n",
    "\n",
    "            newPair = [key, term]\n",
    "            evalPairs.append(newPair)\n",
    "            \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "len(evalPairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathResults = \"/home/hiwi/Dokumente/masterthesis/masterthesis/evalPairs.csv\"\n",
    "\n",
    "f = open(pathResults, \"a\")\n",
    "for pair in evalPairs:\n",
    "    newLine = \";\".join(pair)\n",
    "    f.write(newLine)\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "source": [
    "### Test file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(pathResults, sep=\";\", names=[\"key\", \"term\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for index, row in test.iterrows():\n",
    "    pair = [row[\"key\"], row[\"term\"]]\n",
    "    pairs.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}